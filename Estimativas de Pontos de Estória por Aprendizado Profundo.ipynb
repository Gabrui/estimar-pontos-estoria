{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimativa de pontos de estória usando aprendizado profundo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilização de aprendizado profundo por redes neurais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import gzip\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import spacy\n",
    "import keras\n",
    "import theano\n",
    "from keras.layers import Input, Embedding, LSTM\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "#nlp = spacy.load('pt', disable=['parser', 'tagger', 'ner'])\n",
    "nlp = spacy.load('en', disable=['parser', 'tagger', 'ner'])\n",
    "#tokenizar = spacy.tokenizer.Tokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext jupyternotify\n",
    "%autonotify -a 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_pickle(data, file_path):\n",
    "    with open(file_path,\"wb\") as file:\n",
    "        pickle.dump(data, file)\n",
    "\n",
    "def load_pickle(file_path):\n",
    "    with open(file_path,\"rb\") as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "def print_log_out(string):\n",
    "    print(string)\n",
    "    with open('logs/main', \"a+\") as file:\n",
    "        file.write(string+'\\n')\n",
    "        \n",
    "def mascara_cubo_hipercubo(dim_entrada, dim_saida):\n",
    "    mascara = np.zeros((dim_entrada, dim_saida))\n",
    "    l2e = int(round(math.log2(dim_entrada)))\n",
    "    qe = dim_entrada//l2e\n",
    "    for i in range(qe): # dim_entrada > dim_saida\n",
    "        mascara[(i*l2e):((i+1)*l2e), (i*l2e):((i+1)*l2e)] = 1\n",
    "        for j in range(qe):\n",
    "            mascara[i*l2e:(i+1)*l2e, l2e*(i^(1<<j)):l2e*((i^(1<<j))+1)] = 1\n",
    "    return mascara\n",
    "\n",
    "class CamadaHipercubo(keras.layers.Layer):\n",
    "    def __init__(self, quant, **kwargs):\n",
    "        self.quant = quant\n",
    "        super(CamadaHipercubo, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, dims_entrada):\n",
    "        #ini = keras.initializers.random_uniform(minval=-0.1, maxval=1)\n",
    "        self.mascara = keras.backend.constant(value=mascara_cubo_hipercubo(dims_entrada[1], self.quant))\n",
    "        self.peso_W = self.add_weight(name='peso_W_hipercubo', shape=(dims_entrada[1], self.quant), initializer='uniform')\n",
    "        self.peso_B = self.add_weight(name='peso_B_hipercubo', shape=(self.quant,), initializer='zeros')\n",
    "        super(CamadaHipercubo, self).build(dims_entrada)\n",
    "\n",
    "    def call(self, x):\n",
    "        return keras.backend.relu(keras.backend.dot(x, self.peso_W * self.mascara) + self.peso_B)\n",
    "\n",
    "    def compute_output_shape(self, dims_entrada):\n",
    "        return (dims_entrada[0], self.quant)\n",
    "\n",
    "class BiggerThanOneReg(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(BiggerThanOneReg, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, dims_entrada):\n",
    "        self.one = keras.backend.constant(value=np.array([1]))\n",
    "        #ini = keras.initializers.RandomUniform(minval=-1, maxval=1)\n",
    "        self.peso_W = self.add_weight(name='peso_W_bto', shape=(dims_entrada[1], 1), initializer='uniform')\n",
    "        self.peso_B = self.add_weight(name='peso_B_bto', shape=(1,), initializer='ones')\n",
    "        super(BiggerThanOneReg, self).build(dims_entrada)\n",
    "\n",
    "    def call(self, x):\n",
    "        return keras.backend.maximum(keras.backend.dot(x, self.peso_W) + self.peso_B, self.one)\n",
    "\n",
    "    def compute_output_shape(self, dims_entrada):\n",
    "        return (dims_entrada[0], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisão do conjunto de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treino, validação e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ler_csv_texto_tokenizado(caminho_arquivo, tokenizador):\n",
    "    tabela_dados = pd.read_csv(caminho_arquivo)\n",
    "    titulos = tabela_dados.values[:, 1].astype('str')\n",
    "    separadores = np.full(len(titulos), '. ')\n",
    "    descricao = tabela_dados.values[:, 2].astype('str')\n",
    "    valores = tabela_dados.values[:, 3].astype('float32')\n",
    "    juntos = [a + b + c for a, b, c in zip(titulos, separadores, descricao)]\n",
    "    tokenizados = [[w.text.strip().lower() for w in tokenizador(frase) if not w.text.isspace()] for frase in juntos]\n",
    "    return tokenizados, valores\n",
    "\n",
    "def gerar_dicionario(lista_tokens, vocabulario_maximo=2000):\n",
    "    contagem = defaultdict(int)\n",
    "    for tokens in lista_tokens:\n",
    "        for token in tokens:\n",
    "            contagem[token] += 1\n",
    "    ordenadas = sorted(contagem.items(), key=lambda x: x[1], reverse=True)\n",
    "    IDs = {'EOF_VALUE': 0, 'UNK_VALUE': 1}\n",
    "    for i in range(min(vocabulario_maximo, len(ordenadas))): # EOF = 0, ID_desconhecido = 1\n",
    "        IDs[ordenadas[i][0]] = i + 2\n",
    "    return IDs\n",
    "\n",
    "def converte_tokens_pretreino(lista_tokens, dic):\n",
    "    dados = [np.array([(dic.get(tk) or 1) for tk in tks], dtype=np.int16) for tks in lista_tokens]\n",
    "    return dados\n",
    "\n",
    "def converte_tokens_treino(lista_tokens, dic, fracao_valida = 0.2, fracao_teste = 0.2, tamanho_frase=256):\n",
    "    dados = np.zeros((len(lista_tokens), tamanho_frase), dtype='int16')\n",
    "    for i, tks in enumerate(lista_tokens):\n",
    "        compri = min(tamanho_frase, len(tks))\n",
    "        dados[i, :compri] = [(dic.get(tks[i]) or 1) for i in range(compri)]\n",
    "    quant_valida = int(fracao_valida * len(lista_tokens))\n",
    "    quant_teste = int(fracao_teste * len(lista_tokens))\n",
    "    return dados[:-quant_valida-quant_teste], dados[-quant_valida-quant_teste:-quant_teste], dados[-quant_teste:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fraction = 0.2\n",
    "val_fraction = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario:  2002 \n",
      "Treino:  5253\n"
     ]
    }
   ],
   "source": [
    "#a = ler_csv_texto_tokenizado('dados/pretreino/ccasj.csv', nlp.tokenizer)\n",
    "unlabelled_words, _ = ler_csv_texto_tokenizado('dados/pretreino/lsscorp_pretreino.csv', nlp.tokenizer)\n",
    "story_words, story_points = ler_csv_texto_tokenizado('dados/treino/datamanagement.csv', nlp.tokenizer)\n",
    "num_test = int(round(len(story_words) * test_fraction))\n",
    "num_val = int(round(len(story_words) * val_fraction))\n",
    "num_train = len(story_words) - num_test - num_val\n",
    "dic = gerar_dicionario(unlabelled_words + story_words[:num_train])\n",
    "\n",
    "#treino, validacao = converte_tokens_pretreino(a, dic)\n",
    "pretrain_tokens = converte_tokens_pretreino(unlabelled_words + story_words[:num_train], dic)\n",
    "print('Vocabulario: ', len(dic), '\\nTreino: ', len(pretrain_tokens))#, '\\n Validação: ', len(validacao))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  2801 \n",
      "Validation:  933 \n",
      "Test:  933\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val, x_test = converte_tokens_treino(story_words, dic)\n",
    "y_train = story_points[:x_train.shape[0]].reshape((-1, 1))\n",
    "y_val = story_points[x_train.shape[0]:x_train.shape[0]+x_val.shape[0]].reshape((-1, 1))\n",
    "y_test = story_points[x_train.shape[0] + x_val.shape[0]:].reshape((-1, 1))\n",
    "print('Train: ', x_train.shape[0], '\\nValidation: ', x_val.shape[0], '\\nTest: ', x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_train>21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.19507"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs(np.median(y_train) - y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mesos': 5.0,\n",
       " 'usergrid': 5.0,\n",
       " 'appceleratorstudio': 8.0,\n",
       " 'aptanastudio': 13.0,\n",
       " 'titanium': 13.0,\n",
       " 'duracloud': 4.0,\n",
       " 'bamboo': 5.0,\n",
       " 'clover': 13.0,\n",
       " 'jirasoftware': 8.0,\n",
       " 'moodle': 40.0,\n",
       " 'datamanagement': 21.0,\n",
       " 'mule': 8.0,\n",
       " 'mulestudio': 13.0,\n",
       " 'springxd': 8.0,\n",
       " 'talenddataquality': 13.0,\n",
       " 'talendesb': 3.0}"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_points_clip = {}\n",
    "for p in project_repos.keys():\n",
    "    f = gzip.open('dados/temp/%s.pkl.gz' % p, 'rb')\n",
    "\n",
    "    train_t, train_d, train_y, \\\n",
    "    valid_t, valid_d, valid_y, \\\n",
    "    test_t, test_d, test_y = pickle.load(f, encoding='latin1')\n",
    "    story_points_clip[p] = max(train_y.max(), valid_y.max(), test_y.max())\n",
    "story_points_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('dados/temp/%s.pkl.gz' % 'datamanagement', 'rb') as f:\n",
    "    train_t, train_d, train_y, \\\n",
    "    valid_t, valid_d, valid_y, \\\n",
    "    test_t, test_d, test_y = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(1, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_words, story_points = ler_csv_texto_tokenizado(train_data_path % 'mesos', nlp.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.,  8.,  8.,  8.,  8.,  8.,  8.,  8., 13., 13.,  8., 13., 40.,\n",
       "        8.,  8.,  8.,  8., 13., 13.,  8.,  8., 13.,  8.,  8.,  8.,  8.,\n",
       "        8., 13., 13.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,\n",
       "        8., 13.,  8., 13.,  8., 13., 13., 13.,  8.,  8., 13.,  8.,  8.,\n",
       "        8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,\n",
       "        8.,  8.,  8., 13., 13.,  8., 13.,  8.,  8.,  8.,  8., 13.,  8.,\n",
       "        6., 13.,  8.,  8., 13.,  8.,  8.,  8., 13., 13.,  8., 13., 13.,\n",
       "       13., 13., 13.,  8.,  8.,  8., 10.], dtype=float32)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_points[:train_y.shape[0]][train_y != story_points[:train_y.shape[0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 5., 5., ..., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretreinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeradorDados(keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, funcoes, tamanho_batch=128, quant_batch=100, janela=7, fracao_positiva=0.5):\n",
    "        self.funcoes = funcoes\n",
    "        self.tamanho_batch = tamanho_batch\n",
    "        self.quant_batch = quant_batch\n",
    "        self.janela = janela\n",
    "        self.fracao_positiva = fracao_positiva\n",
    "        self.quant_funcoes = len(funcoes)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.quant_batch\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        alvo = np.zeros((self.tamanho_batch, 1), dtype='int16')\n",
    "        contexto = np.zeros((self.tamanho_batch, 1), dtype='int16')\n",
    "        verdade = np.zeros((self.tamanho_batch, 1))\n",
    "        for i in range(self.tamanho_batch):\n",
    "            positivo = random.random() < self.fracao_positiva\n",
    "            j = random.randint(0, self.quant_funcoes - 1)\n",
    "            k = random.randint(0, self.funcoes[j].shape[0] - 1)\n",
    "            if positivo:\n",
    "                l = j\n",
    "                m = random.randint(max(0, k-self.janela), min(self.funcoes[j].shape[0] - 1, k+self.janela))\n",
    "            else:\n",
    "                l = random.randint(0, self.quant_funcoes - 1)\n",
    "                m = random.randint(0, self.funcoes[l].shape[0] - 1)\n",
    "            alvo[i] = self.funcoes[j][k]\n",
    "            contexto[i] = self.funcoes[l][m]\n",
    "            verdade[i] = positivo\n",
    "        return [alvo, contexto], verdade\n",
    "\n",
    "def gerar_modelo_keras(vocabulario, dimensao_vetorial=64):\n",
    "    entrada_contexto = keras.layers.Input(shape=(1,), dtype='int16', name='palavra_contexto')\n",
    "    entrada_alvo = keras.layers.Input(shape=(1,), dtype='int16', name='palavra_alvo')\n",
    "    vetorizacao = keras.layers.Embedding(vocabulario, dimensao_vetorial, name='vetorizacao')\n",
    "    contexto = keras.layers.Flatten()(vetorizacao(entrada_contexto))\n",
    "    alvo = keras.layers.Flatten()(vetorizacao(entrada_alvo))\n",
    "    produto_interno = keras.layers.dot([alvo, contexto], axes=-1)\n",
    "    estimativa = keras.layers.Dense(1, activation='sigmoid')(produto_interno)\n",
    "    return keras.models.Model(inputs=[entrada_alvo, entrada_contexto], outputs=estimativa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "palavra_alvo (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "palavra_contexto (InputLayer)   (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vetorizacao (Embedding)         (None, 1, 50)        100100      palavra_contexto[0][0]           \n",
      "                                                                 palavra_alvo[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 50)           0           vetorizacao[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 50)           0           vetorizacao[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1)            0           flatten_2[0][0]                  \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            2           dot_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 100,102\n",
      "Trainable params: 100,102\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gerador_treino = GeradorDados(pretrain_tokens, 128, 512)\n",
    "gerador_valida = GeradorDados(pretrain_tokens, 128, 8)\n",
    "mod_emb = gerar_modelo_keras(len(dic))\n",
    "mod_emb.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_emb.compile(loss='binary_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.Model.fit_generator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6537 - val_loss: 0.6402\n",
      "Epoch 2/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6553 - val_loss: 0.6474\n",
      "Epoch 3/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6528 - val_loss: 0.6450\n",
      "Epoch 4/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6516 - val_loss: 0.6394\n",
      "Epoch 5/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6492 - val_loss: 0.6539\n",
      "Epoch 6/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6501 - val_loss: 0.6464\n",
      "Epoch 7/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6474 - val_loss: 0.6554\n",
      "Epoch 8/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6483 - val_loss: 0.6524\n",
      "Epoch 9/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6472 - val_loss: 0.6383\n",
      "Epoch 10/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6463 - val_loss: 0.6398\n",
      "Epoch 11/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6442 - val_loss: 0.6437\n",
      "Epoch 12/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6436 - val_loss: 0.6449\n",
      "Epoch 13/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6423 - val_loss: 0.6391\n",
      "Epoch 14/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6443 - val_loss: 0.6493\n",
      "Epoch 15/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6426 - val_loss: 0.6351\n",
      "Epoch 16/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6441 - val_loss: 0.6433\n",
      "Epoch 17/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6415 - val_loss: 0.6419\n",
      "Epoch 18/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6435 - val_loss: 0.6317\n",
      "Epoch 19/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6415 - val_loss: 0.6432 ETA\n",
      "Epoch 20/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6423 - val_loss: 0.6480\n",
      "Epoch 21/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6396 - val_loss: 0.6434\n",
      "Epoch 22/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6411 - val_loss: 0.6403\n",
      "Epoch 23/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6397 - val_loss: 0.6473\n",
      "Epoch 24/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6400 - val_loss: 0.6304\n",
      "Epoch 25/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6379 - val_loss: 0.6380\n",
      "Epoch 26/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6371 - val_loss: 0.6417\n",
      "Epoch 27/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6359 - val_loss: 0.6219\n",
      "Epoch 28/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6400 - val_loss: 0.6192\n",
      "Epoch 29/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6379 - val_loss: 0.6161\n",
      "Epoch 30/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6368 - val_loss: 0.6429\n",
      "Epoch 31/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6382 - val_loss: 0.6423\n",
      "Epoch 32/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6374 - val_loss: 0.6225\n",
      "Epoch 33/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6386 - val_loss: 0.6235\n",
      "Epoch 34/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6352 - val_loss: 0.6342\n",
      "Epoch 35/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6357 - val_loss: 0.6433\n",
      "Epoch 36/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6354 - val_loss: 0.6292\n",
      "Epoch 37/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6362 - val_loss: 0.6413\n",
      "Epoch 38/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6361 - val_loss: 0.6280\n",
      "Epoch 39/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6365 - val_loss: 0.6381\n",
      "Epoch 40/500\n",
      "512/512 [==============================] - 3s 6ms/step - loss: 0.6348 - val_loss: 0.6320\n",
      "Epoch 41/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6359 - val_loss: 0.6405\n",
      "Epoch 42/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6366 - val_loss: 0.6445\n",
      "Epoch 43/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6347 - val_loss: 0.6414\n",
      "Epoch 44/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6375 - val_loss: 0.6448\n",
      "Epoch 45/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6350 - val_loss: 0.6397\n",
      "Epoch 46/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6340 - val_loss: 0.6333\n",
      "Epoch 47/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6328 - val_loss: 0.6407\n",
      "Epoch 48/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6344 - val_loss: 0.6407\n",
      "Epoch 49/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6338 - val_loss: 0.6443\n",
      "Epoch 50/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6330 - val_loss: 0.6290\n",
      "Epoch 51/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6339 - val_loss: 0.6220\n",
      "Epoch 52/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6318 - val_loss: 0.6351\n",
      "Epoch 53/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6336 - val_loss: 0.6258\n",
      "Epoch 54/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6341 - val_loss: 0.6194\n",
      "Epoch 55/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6324 - val_loss: 0.6327\n",
      "Epoch 56/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6325 - val_loss: 0.6391\n",
      "Epoch 57/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6314 - val_loss: 0.6390\n",
      "Epoch 58/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6333 - val_loss: 0.6446\n",
      "Epoch 59/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6321 - val_loss: 0.6420\n",
      "Epoch 60/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6319 - val_loss: 0.6277\n",
      "Epoch 61/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6334 - val_loss: 0.6411\n",
      "Epoch 62/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6311 - val_loss: 0.6207\n",
      "Epoch 63/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6313 - val_loss: 0.6349\n",
      "Epoch 64/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6310 - val_loss: 0.6263\n",
      "Epoch 65/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6314 - val_loss: 0.6407\n",
      "Epoch 66/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6328 - val_loss: 0.6301\n",
      "Epoch 67/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6313 - val_loss: 0.6301\n",
      "Epoch 68/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6334 - val_loss: 0.6298\n",
      "Epoch 69/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6309 - val_loss: 0.6469\n",
      "Epoch 70/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6311 - val_loss: 0.6351\n",
      "Epoch 71/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6334 - val_loss: 0.6437\n",
      "Epoch 72/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6300 - val_loss: 0.6304\n",
      "Epoch 73/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6296 - val_loss: 0.6591\n",
      "Epoch 74/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6297 - val_loss: 0.6372\n",
      "Epoch 75/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6307 - val_loss: 0.6171\n",
      "Epoch 76/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6330 - val_loss: 0.6211\n",
      "Epoch 77/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6303 - val_loss: 0.6358\n",
      "Epoch 78/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6290 - val_loss: 0.6398\n",
      "Epoch 79/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6297 - val_loss: 0.6414\n",
      "Epoch 80/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6305 - val_loss: 0.6287\n",
      "Epoch 81/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6291 - val_loss: 0.6166\n",
      "Epoch 82/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6311 - val_loss: 0.6391\n",
      "Epoch 83/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6300 - val_loss: 0.6248\n",
      "Epoch 84/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6308 - val_loss: 0.6205\n",
      "Epoch 85/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6311 - val_loss: 0.6353\n",
      "Epoch 86/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6308 - val_loss: 0.6192\n",
      "Epoch 87/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6296 - val_loss: 0.6349\n",
      "Epoch 88/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6300 - val_loss: 0.6286\n",
      "Epoch 89/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6294 - val_loss: 0.6457\n",
      "Epoch 90/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6300 - val_loss: 0.6207\n",
      "Epoch 91/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6295 - val_loss: 0.6186\n",
      "Epoch 92/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6279 - val_loss: 0.6272\n",
      "Epoch 93/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6287 - val_loss: 0.6226\n",
      "Epoch 94/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6273 - val_loss: 0.6301\n",
      "Epoch 95/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6301 - val_loss: 0.6323\n",
      "Epoch 96/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6283 - val_loss: 0.6291\n",
      "Epoch 97/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6283 - val_loss: 0.6327\n",
      "Epoch 98/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6307 - val_loss: 0.6362\n",
      "Epoch 99/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6302 - val_loss: 0.6282\n",
      "Epoch 100/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6294 - val_loss: 0.6254\n",
      "Epoch 101/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6273 - val_loss: 0.6366\n",
      "Epoch 102/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6290 - val_loss: 0.6200\n",
      "Epoch 103/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6292 - val_loss: 0.6171\n",
      "Epoch 104/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6306 - val_loss: 0.6398\n",
      "Epoch 105/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6289 - val_loss: 0.6436\n",
      "Epoch 106/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6279 - val_loss: 0.6345\n",
      "Epoch 107/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6283 - val_loss: 0.6415\n",
      "Epoch 108/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6291 - val_loss: 0.6423\n",
      "Epoch 109/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6272 - val_loss: 0.6103\n",
      "Epoch 110/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6305 - val_loss: 0.6121\n",
      "Epoch 111/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6283 - val_loss: 0.6447\n",
      "Epoch 112/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6304 - val_loss: 0.6156\n",
      "Epoch 113/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6293 - val_loss: 0.6231\n",
      "Epoch 114/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6280 - val_loss: 0.6410\n",
      "Epoch 115/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6294 - val_loss: 0.6230\n",
      "Epoch 116/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6306 - val_loss: 0.6325\n",
      "Epoch 117/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6297 - val_loss: 0.6244\n",
      "Epoch 118/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6286 - val_loss: 0.6372\n",
      "Epoch 119/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6280 - val_loss: 0.6157\n",
      "Epoch 120/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6293 - val_loss: 0.6127\n",
      "Epoch 121/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6292 - val_loss: 0.6453\n",
      "Epoch 122/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6285 - val_loss: 0.6256\n",
      "Epoch 123/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6285 - val_loss: 0.6113\n",
      "Epoch 124/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6288 - val_loss: 0.6222\n",
      "Epoch 125/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6269 - val_loss: 0.6329\n",
      "Epoch 126/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6283 - val_loss: 0.6410\n",
      "Epoch 127/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6295 - val_loss: 0.6081\n",
      "Epoch 128/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6295 - val_loss: 0.6271\n",
      "Epoch 129/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6267 - val_loss: 0.6251\n",
      "Epoch 130/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6274 - val_loss: 0.6305\n",
      "Epoch 131/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6263 - val_loss: 0.6206\n",
      "Epoch 132/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6266 - val_loss: 0.6425\n",
      "Epoch 133/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6274 - val_loss: 0.6509\n",
      "Epoch 134/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6283 - val_loss: 0.6176\n",
      "Epoch 135/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6265 - val_loss: 0.6134\n",
      "Epoch 136/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6283 - val_loss: 0.6254\n",
      "Epoch 137/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6267 - val_loss: 0.6293\n",
      "Epoch 138/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6267 - val_loss: 0.6385\n",
      "Epoch 139/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6277 - val_loss: 0.6257\n",
      "Epoch 140/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6281 - val_loss: 0.6394\n",
      "Epoch 141/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6284 - val_loss: 0.6115\n",
      "Epoch 142/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6286 - val_loss: 0.6390\n",
      "Epoch 143/500\n",
      "512/512 [==============================] - 3s 6ms/step - loss: 0.6262 - val_loss: 0.6317\n",
      "Epoch 144/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6286 - val_loss: 0.6114\n",
      "Epoch 145/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6261 - val_loss: 0.6159\n",
      "Epoch 146/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6286 - val_loss: 0.6227\n",
      "Epoch 147/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6257 - val_loss: 0.6250\n",
      "Epoch 148/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6278 - val_loss: 0.6286\n",
      "Epoch 149/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6269 - val_loss: 0.6139\n",
      "Epoch 150/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6268 - val_loss: 0.6157\n",
      "Epoch 151/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6288 - val_loss: 0.6439\n",
      "Epoch 152/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6274 - val_loss: 0.6223\n",
      "Epoch 153/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6263 - val_loss: 0.6312\n",
      "Epoch 154/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6259 - val_loss: 0.6177\n",
      "Epoch 155/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6244 - val_loss: 0.6286\n",
      "Epoch 156/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6286 - val_loss: 0.6481\n",
      "Epoch 157/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6242 - val_loss: 0.6430\n",
      "Epoch 158/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6279 - val_loss: 0.6305\n",
      "Epoch 159/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6281 - val_loss: 0.6245\n",
      "Epoch 160/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6271 - val_loss: 0.6156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6279 - val_loss: 0.6295\n",
      "Epoch 162/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6257 - val_loss: 0.6376\n",
      "Epoch 163/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6275 - val_loss: 0.6261\n",
      "Epoch 164/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6267 - val_loss: 0.6366\n",
      "Epoch 165/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6270 - val_loss: 0.6256\n",
      "Epoch 166/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6270 - val_loss: 0.6421\n",
      "Epoch 167/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6277 - val_loss: 0.6308\n",
      "Epoch 168/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6263 - val_loss: 0.6337\n",
      "Epoch 169/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6255 - val_loss: 0.6239\n",
      "Epoch 170/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6277 - val_loss: 0.6382\n",
      "Epoch 171/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6273 - val_loss: 0.6235\n",
      "Epoch 172/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6266 - val_loss: 0.6154\n",
      "Epoch 173/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6260 - val_loss: 0.6321\n",
      "Epoch 174/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6245 - val_loss: 0.6232\n",
      "Epoch 175/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6269 - val_loss: 0.6240\n",
      "Epoch 176/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6290 - val_loss: 0.6054\n",
      "Epoch 177/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6266 - val_loss: 0.6465\n",
      "Epoch 178/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6258 - val_loss: 0.6332\n",
      "Epoch 179/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6259 - val_loss: 0.6183\n",
      "Epoch 180/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6277 - val_loss: 0.6249\n",
      "Epoch 181/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6274 - val_loss: 0.6330\n",
      "Epoch 182/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6252 - val_loss: 0.6402\n",
      "Epoch 183/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6259 - val_loss: 0.6235\n",
      "Epoch 184/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6293 - val_loss: 0.6352\n",
      "Epoch 185/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6240 - val_loss: 0.6376\n",
      "Epoch 186/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6241 - val_loss: 0.6289\n",
      "Epoch 187/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6262 - val_loss: 0.6312\n",
      "Epoch 188/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6241 - val_loss: 0.6305\n",
      "Epoch 189/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6275 - val_loss: 0.6333\n",
      "Epoch 190/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6262 - val_loss: 0.6192\n",
      "Epoch 191/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6266 - val_loss: 0.6245\n",
      "Epoch 192/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6260 - val_loss: 0.6252\n",
      "Epoch 193/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6248 - val_loss: 0.6126\n",
      "Epoch 194/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6242 - val_loss: 0.6401\n",
      "Epoch 195/500\n",
      "512/512 [==============================] - 3s 6ms/step - loss: 0.6271 - val_loss: 0.6125\n",
      "Epoch 196/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6258 - val_loss: 0.6112\n",
      "Epoch 197/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6250 - val_loss: 0.6201\n",
      "Epoch 198/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6270 - val_loss: 0.6323\n",
      "Epoch 199/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6255 - val_loss: 0.6278\n",
      "Epoch 200/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6266 - val_loss: 0.6112\n",
      "Epoch 201/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6260 - val_loss: 0.6127\n",
      "Epoch 202/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6274 - val_loss: 0.6178\n",
      "Epoch 203/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6254 - val_loss: 0.6197\n",
      "Epoch 204/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6248 - val_loss: 0.6173\n",
      "Epoch 205/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6261 - val_loss: 0.6307\n",
      "Epoch 206/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6285 - val_loss: 0.6091\n",
      "Epoch 207/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6271 - val_loss: 0.6254\n",
      "Epoch 208/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6237 - val_loss: 0.6357\n",
      "Epoch 209/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6275 - val_loss: 0.6225\n",
      "Epoch 210/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6264 - val_loss: 0.6233\n",
      "Epoch 211/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6266 - val_loss: 0.6249\n",
      "Epoch 212/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6219 - val_loss: 0.6427\n",
      "Epoch 213/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6275 - val_loss: 0.6301\n",
      "Epoch 214/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6246 - val_loss: 0.6247\n",
      "Epoch 215/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6256 - val_loss: 0.6146\n",
      "Epoch 216/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6259 - val_loss: 0.6345\n",
      "Epoch 217/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6267 - val_loss: 0.6131\n",
      "Epoch 218/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6257 - val_loss: 0.6349\n",
      "Epoch 219/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6238 - val_loss: 0.6177\n",
      "Epoch 220/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6235 - val_loss: 0.6210\n",
      "Epoch 221/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6245 - val_loss: 0.6162\n",
      "Epoch 222/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6264 - val_loss: 0.6262\n",
      "Epoch 223/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6252 - val_loss: 0.6185\n",
      "Epoch 224/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6282 - val_loss: 0.6338\n",
      "Epoch 225/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6270 - val_loss: 0.6285\n",
      "Epoch 226/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6261 - val_loss: 0.6208\n",
      "Epoch 227/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6251 - val_loss: 0.6231\n",
      "Epoch 228/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6254 - val_loss: 0.6420\n",
      "Epoch 229/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6254 - val_loss: 0.6326\n",
      "Epoch 230/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6228 - val_loss: 0.6434\n",
      "Epoch 231/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6243 - val_loss: 0.6388\n",
      "Epoch 232/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6252 - val_loss: 0.6225\n",
      "Epoch 233/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6255 - val_loss: 0.6332\n",
      "Epoch 234/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6266 - val_loss: 0.6079\n",
      "Epoch 235/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6268 - val_loss: 0.6311\n",
      "Epoch 236/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6245 - val_loss: 0.6195\n",
      "Epoch 237/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6231 - val_loss: 0.6260\n",
      "Epoch 238/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6245 - val_loss: 0.6278\n",
      "Epoch 239/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6238 - val_loss: 0.6242\n",
      "Epoch 240/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6219 - val_loss: 0.6234\n",
      "Epoch 241/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6243 - val_loss: 0.6355\n",
      "Epoch 242/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6259 - val_loss: 0.6129\n",
      "Epoch 243/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6230 - val_loss: 0.6193\n",
      "Epoch 244/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6243 - val_loss: 0.6256\n",
      "Epoch 245/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6259 - val_loss: 0.6400\n",
      "Epoch 246/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6240 - val_loss: 0.6177\n",
      "Epoch 247/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6254 - val_loss: 0.6324\n",
      "Epoch 248/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6254 - val_loss: 0.6206\n",
      "Epoch 249/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6254 - val_loss: 0.6122\n",
      "Epoch 250/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6268 - val_loss: 0.6452\n",
      "Epoch 251/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6232 - val_loss: 0.6255\n",
      "Epoch 252/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6258 - val_loss: 0.6200\n",
      "Epoch 253/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6254 - val_loss: 0.6329\n",
      "Epoch 254/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6239 - val_loss: 0.6220\n",
      "Epoch 255/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6272 - val_loss: 0.6162\n",
      "Epoch 256/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6251 - val_loss: 0.6255\n",
      "Epoch 257/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6253 - val_loss: 0.6271\n",
      "Epoch 258/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6243 - val_loss: 0.6496\n",
      "Epoch 259/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6238 - val_loss: 0.6125\n",
      "Epoch 260/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6232 - val_loss: 0.6374\n",
      "Epoch 261/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6246 - val_loss: 0.6069\n",
      "Epoch 262/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6236 - val_loss: 0.6267\n",
      "Epoch 263/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6239 - val_loss: 0.6150\n",
      "Epoch 264/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6244 - val_loss: 0.6321\n",
      "Epoch 265/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6242 - val_loss: 0.6253\n",
      "Epoch 266/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6234 - val_loss: 0.6221\n",
      "Epoch 267/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6260 - val_loss: 0.6173\n",
      "Epoch 268/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6250 - val_loss: 0.6272\n",
      "Epoch 269/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6249 - val_loss: 0.6128\n",
      "Epoch 270/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6257 - val_loss: 0.6192\n",
      "Epoch 271/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6241 - val_loss: 0.6235\n",
      "Epoch 272/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6244 - val_loss: 0.6258\n",
      "Epoch 273/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6233 - val_loss: 0.6357\n",
      "Epoch 274/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6262 - val_loss: 0.6067\n",
      "Epoch 275/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6240 - val_loss: 0.6175\n",
      "Epoch 276/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6240 - val_loss: 0.6260\n",
      "Epoch 277/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6256 - val_loss: 0.6318\n",
      "Epoch 278/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6267 - val_loss: 0.6061\n",
      "Epoch 279/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6249 - val_loss: 0.6356\n",
      "Epoch 280/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6250 - val_loss: 0.6324\n",
      "Epoch 281/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6257 - val_loss: 0.6211\n",
      "Epoch 282/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6226 - val_loss: 0.6202\n",
      "Epoch 283/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6267 - val_loss: 0.6323\n",
      "Epoch 284/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6220 - val_loss: 0.6312\n",
      "Epoch 285/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6237 - val_loss: 0.6313\n",
      "Epoch 286/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6238 - val_loss: 0.6064\n",
      "Epoch 287/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6270 - val_loss: 0.6328\n",
      "Epoch 288/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6241 - val_loss: 0.6227\n",
      "Epoch 289/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6248 - val_loss: 0.6177\n",
      "Epoch 290/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6231 - val_loss: 0.6289\n",
      "Epoch 291/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6249 - val_loss: 0.6217\n",
      "Epoch 292/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6243 - val_loss: 0.6305\n",
      "Epoch 293/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6225 - val_loss: 0.6214\n",
      "Epoch 294/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6233 - val_loss: 0.6343\n",
      "Epoch 295/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6252 - val_loss: 0.6218\n",
      "Epoch 296/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6233 - val_loss: 0.6355\n",
      "Epoch 297/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6235 - val_loss: 0.6174\n",
      "Epoch 298/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6246 - val_loss: 0.6292\n",
      "Epoch 299/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6252 - val_loss: 0.6315\n",
      "Epoch 300/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6242 - val_loss: 0.6233\n",
      "Epoch 301/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6242 - val_loss: 0.6435\n",
      "Epoch 302/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6222 - val_loss: 0.6255\n",
      "Epoch 303/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6239 - val_loss: 0.6206\n",
      "Epoch 304/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6259 - val_loss: 0.6033\n",
      "Epoch 305/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6249 - val_loss: 0.6275\n",
      "Epoch 306/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6256 - val_loss: 0.6260\n",
      "Epoch 307/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6231 - val_loss: 0.6260\n",
      "Epoch 308/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6235 - val_loss: 0.6213\n",
      "Epoch 309/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6243 - val_loss: 0.6238\n",
      "Epoch 310/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6225 - val_loss: 0.6411\n",
      "Epoch 311/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6226 - val_loss: 0.6182\n",
      "Epoch 312/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6240 - val_loss: 0.6134\n",
      "Epoch 313/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6249 - val_loss: 0.6244\n",
      "Epoch 314/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6237 - val_loss: 0.6175\n",
      "Epoch 315/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6245 - val_loss: 0.6150\n",
      "Epoch 316/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6229 - val_loss: 0.6227\n",
      "Epoch 317/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6216 - val_loss: 0.6304\n",
      "Epoch 318/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6237 - val_loss: 0.6288\n",
      "Epoch 319/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6237 - val_loss: 0.6314\n",
      "Epoch 320/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6230 - val_loss: 0.6396\n",
      "Epoch 321/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6254 - val_loss: 0.6436\n",
      "Epoch 322/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6231 - val_loss: 0.6274\n",
      "Epoch 323/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6220 - val_loss: 0.6354\n",
      "Epoch 324/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6229 - val_loss: 0.6097\n",
      "Epoch 325/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6231 - val_loss: 0.6167\n",
      "Epoch 326/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6239 - val_loss: 0.6224\n",
      "Epoch 327/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6244 - val_loss: 0.6226\n",
      "Epoch 328/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6222 - val_loss: 0.6067\n",
      "Epoch 329/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6230 - val_loss: 0.6085\n",
      "Epoch 330/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6234 - val_loss: 0.6264\n",
      "Epoch 331/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6252 - val_loss: 0.6201\n",
      "Epoch 332/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6225 - val_loss: 0.6341\n",
      "Epoch 333/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6237 - val_loss: 0.6048\n",
      "Epoch 334/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6235 - val_loss: 0.6361\n",
      "Epoch 335/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6242 - val_loss: 0.6356\n",
      "Epoch 336/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6211 - val_loss: 0.5933\n",
      "Epoch 337/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6228 - val_loss: 0.6339\n",
      "Epoch 338/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6235 - val_loss: 0.6347\n",
      "Epoch 339/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6224 - val_loss: 0.6216\n",
      "Epoch 340/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6238 - val_loss: 0.6288\n",
      "Epoch 341/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6244 - val_loss: 0.6016\n",
      "Epoch 342/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6219 - val_loss: 0.6350\n",
      "Epoch 343/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6254 - val_loss: 0.6409\n",
      "Epoch 344/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6258 - val_loss: 0.6273\n",
      "Epoch 345/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6237 - val_loss: 0.6268\n",
      "Epoch 346/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6236 - val_loss: 0.6273\n",
      "Epoch 347/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6244 - val_loss: 0.6429\n",
      "Epoch 348/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6224 - val_loss: 0.6299\n",
      "Epoch 349/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6249 - val_loss: 0.6299\n",
      "Epoch 350/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6234 - val_loss: 0.6172\n",
      "Epoch 351/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6238 - val_loss: 0.6247\n",
      "Epoch 352/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6228 - val_loss: 0.6164\n",
      "Epoch 353/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6211 - val_loss: 0.6261\n",
      "Epoch 354/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6217 - val_loss: 0.6078\n",
      "Epoch 355/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6243 - val_loss: 0.6193\n",
      "Epoch 356/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6240 - val_loss: 0.6170\n",
      "Epoch 357/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6209 - val_loss: 0.6332\n",
      "Epoch 358/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6238 - val_loss: 0.6250\n",
      "Epoch 359/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6246 - val_loss: 0.6368\n",
      "Epoch 360/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6234 - val_loss: 0.6181\n",
      "Epoch 361/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6227 - val_loss: 0.6274\n",
      "Epoch 362/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6255 - val_loss: 0.6154\n",
      "Epoch 363/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6237 - val_loss: 0.6215\n",
      "Epoch 364/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6236 - val_loss: 0.6170\n",
      "Epoch 365/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6224 - val_loss: 0.6220\n",
      "Epoch 366/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6236 - val_loss: 0.6246\n",
      "Epoch 367/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6206 - val_loss: 0.6359\n",
      "Epoch 368/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6240 - val_loss: 0.6389\n",
      "Epoch 369/500\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.6214 - val_loss: 0.6283\n",
      "Epoch 370/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6232 - val_loss: 0.6189\n",
      "Epoch 371/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6226 - val_loss: 0.6127\n",
      "Epoch 372/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6223 - val_loss: 0.6259\n",
      "Epoch 373/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6229 - val_loss: 0.6136\n",
      "Epoch 374/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6195 - val_loss: 0.6073\n",
      "Epoch 375/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6216 - val_loss: 0.6164\n",
      "Epoch 376/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6236 - val_loss: 0.6222\n",
      "Epoch 377/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6238 - val_loss: 0.6222\n",
      "Epoch 378/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6226 - val_loss: 0.6163\n",
      "Epoch 379/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6239 - val_loss: 0.6354\n",
      "Epoch 380/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6233 - val_loss: 0.6123\n",
      "Epoch 381/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6219 - val_loss: 0.6189\n",
      "Epoch 382/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6230 - val_loss: 0.6139\n",
      "Epoch 383/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6234 - val_loss: 0.6158\n",
      "Epoch 384/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6243 - val_loss: 0.6230\n",
      "Epoch 385/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6233 - val_loss: 0.6184\n",
      "Epoch 386/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6242 - val_loss: 0.6189\n",
      "Epoch 387/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6239 - val_loss: 0.6203\n",
      "Epoch 388/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6228 - val_loss: 0.6118\n",
      "Epoch 389/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6215 - val_loss: 0.6119\n",
      "Epoch 390/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6233 - val_loss: 0.6298\n",
      "Epoch 391/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6230 - val_loss: 0.6211\n",
      "Epoch 392/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6240 - val_loss: 0.6186\n",
      "Epoch 393/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6222 - val_loss: 0.6275\n",
      "Epoch 394/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6224 - val_loss: 0.6118\n",
      "Epoch 395/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6230 - val_loss: 0.6193\n",
      "Epoch 396/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6237 - val_loss: 0.5943\n",
      "Epoch 397/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6272 - val_loss: 0.6258\n",
      "Epoch 398/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6233 - val_loss: 0.6397\n",
      "Epoch 399/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6208 - val_loss: 0.6272\n",
      "Epoch 400/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6205 - val_loss: 0.6264\n",
      "Epoch 401/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6229 - val_loss: 0.6361\n",
      "Epoch 402/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6243 - val_loss: 0.6305\n",
      "Epoch 403/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6192 - val_loss: 0.6141\n",
      "Epoch 404/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6226 - val_loss: 0.6386\n",
      "Epoch 405/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6217 - val_loss: 0.6234\n",
      "Epoch 406/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6236 - val_loss: 0.6448\n",
      "Epoch 407/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6244 - val_loss: 0.6218\n",
      "Epoch 408/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6233 - val_loss: 0.6493\n",
      "Epoch 409/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6223 - val_loss: 0.6345\n",
      "Epoch 410/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6225 - val_loss: 0.6275\n",
      "Epoch 411/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6228 - val_loss: 0.6093\n",
      "Epoch 412/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6245 - val_loss: 0.6190\n",
      "Epoch 413/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6221 - val_loss: 0.6182\n",
      "Epoch 414/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6219 - val_loss: 0.6226\n",
      "Epoch 415/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6221 - val_loss: 0.6099\n",
      "Epoch 416/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6232 - val_loss: 0.6090\n",
      "Epoch 417/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6218 - val_loss: 0.6033\n",
      "Epoch 418/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6253 - val_loss: 0.6257\n",
      "Epoch 419/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6238 - val_loss: 0.6196\n",
      "Epoch 420/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6235 - val_loss: 0.6117\n",
      "Epoch 421/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6225 - val_loss: 0.6380\n",
      "Epoch 422/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6231 - val_loss: 0.6278\n",
      "Epoch 423/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6237 - val_loss: 0.6226\n",
      "Epoch 424/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6217 - val_loss: 0.5995\n",
      "Epoch 425/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6225 - val_loss: 0.6339\n",
      "Epoch 426/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6221 - val_loss: 0.6257\n",
      "Epoch 427/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6232 - val_loss: 0.6139\n",
      "Epoch 428/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6232 - val_loss: 0.6169\n",
      "Epoch 429/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6223 - val_loss: 0.6216\n",
      "Epoch 430/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6227 - val_loss: 0.6291\n",
      "Epoch 431/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6216 - val_loss: 0.6317\n",
      "Epoch 432/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6220 - val_loss: 0.6368\n",
      "Epoch 433/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6232 - val_loss: 0.6185\n",
      "Epoch 434/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6230 - val_loss: 0.6167\n",
      "Epoch 435/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6230 - val_loss: 0.6245\n",
      "Epoch 436/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6222 - val_loss: 0.5969\n",
      "Epoch 437/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6246 - val_loss: 0.6257\n",
      "Epoch 438/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6222 - val_loss: 0.6227\n",
      "Epoch 439/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6257 - val_loss: 0.6146\n",
      "Epoch 440/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6234 - val_loss: 0.6141\n",
      "Epoch 441/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6221 - val_loss: 0.6378\n",
      "Epoch 442/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6204 - val_loss: 0.6398\n",
      "Epoch 443/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6213 - val_loss: 0.6256\n",
      "Epoch 444/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6220 - val_loss: 0.6130\n",
      "Epoch 445/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6203 - val_loss: 0.6172\n",
      "Epoch 446/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6234 - val_loss: 0.6345\n",
      "Epoch 447/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6221 - val_loss: 0.6222\n",
      "Epoch 448/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6232 - val_loss: 0.6207\n",
      "Epoch 449/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6214 - val_loss: 0.6086\n",
      "Epoch 450/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6221 - val_loss: 0.6230\n",
      "Epoch 451/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6208 - val_loss: 0.6210\n",
      "Epoch 452/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6252 - val_loss: 0.6204\n",
      "Epoch 453/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6232 - val_loss: 0.6175\n",
      "Epoch 454/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6201 - val_loss: 0.6087\n",
      "Epoch 455/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6212 - val_loss: 0.5977\n",
      "Epoch 456/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6226 - val_loss: 0.6103\n",
      "Epoch 457/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6242 - val_loss: 0.6068\n",
      "Epoch 458/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6219 - val_loss: 0.6183\n",
      "Epoch 459/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6220 - val_loss: 0.6220\n",
      "Epoch 460/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6225 - val_loss: 0.5919\n",
      "Epoch 461/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6242 - val_loss: 0.6375\n",
      "Epoch 462/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6211 - val_loss: 0.6066\n",
      "Epoch 463/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6245 - val_loss: 0.6167\n",
      "Epoch 464/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6207 - val_loss: 0.6175\n",
      "Epoch 465/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6234 - val_loss: 0.6424\n",
      "Epoch 466/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6235 - val_loss: 0.6290\n",
      "Epoch 467/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6229 - val_loss: 0.6598\n",
      "Epoch 468/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6226 - val_loss: 0.6262\n",
      "Epoch 469/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6218 - val_loss: 0.6255\n",
      "Epoch 470/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6202 - val_loss: 0.6104\n",
      "Epoch 471/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6238 - val_loss: 0.6515\n",
      "Epoch 472/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6223 - val_loss: 0.6177\n",
      "Epoch 473/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6232 - val_loss: 0.6390\n",
      "Epoch 474/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6234 - val_loss: 0.6127\n",
      "Epoch 475/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6216 - val_loss: 0.6179\n",
      "Epoch 476/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6230 - val_loss: 0.6185\n",
      "Epoch 477/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6242 - val_loss: 0.6153\n",
      "Epoch 478/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6200 - val_loss: 0.6272\n",
      "Epoch 479/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6243 - val_loss: 0.6336\n",
      "Epoch 480/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6217 - val_loss: 0.6416\n",
      "Epoch 481/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6244 - val_loss: 0.6414\n",
      "Epoch 482/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6238 - val_loss: 0.6211\n",
      "Epoch 483/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6226 - val_loss: 0.6120\n",
      "Epoch 484/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6208 - val_loss: 0.6374\n",
      "Epoch 485/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6223 - val_loss: 0.5999\n",
      "Epoch 486/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6199 - val_loss: 0.6198\n",
      "Epoch 487/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6223 - val_loss: 0.6206\n",
      "Epoch 488/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6231 - val_loss: 0.6221\n",
      "Epoch 489/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6223 - val_loss: 0.6213\n",
      "Epoch 490/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6206 - val_loss: 0.6250\n",
      "Epoch 491/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6235 - val_loss: 0.6136\n",
      "Epoch 492/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6233 - val_loss: 0.6275\n",
      "Epoch 493/500\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.6210 - val_loss: 0.6199\n",
      "Epoch 494/500\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.6229 - val_loss: 0.6414\n",
      "Epoch 495/500\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.6235 - val_loss: 0.5903\n",
      "Epoch 496/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6197 - val_loss: 0.6217\n",
      "Epoch 497/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6256 - val_loss: 0.5998\n",
      "Epoch 498/500\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.6222 - val_loss: 0.6196\n",
      "Epoch 499/500\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6205 - val_loss: 0.6125\n",
      "Epoch 500/500\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.6214 - val_loss: 0.6179\n"
     ]
    }
   ],
   "source": [
    "csv_logger = keras.callbacks.CSVLogger('logs/pretrain.log')\n",
    "#parar_mlp = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=500, min_delta=0)\n",
    "save_best = keras.callbacks.ModelCheckpoint('models/pretrain.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
    "\n",
    "historico3 = mod_emb.fit_generator(generator=gerador_treino, epochs=500, use_multiprocessing=True, shuffle=False, workers=32, max_queue_size=1024, validation_data=gerador_valida, callbacks=[csv_logger,save_best])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(historico3.history['loss'])\n",
    "plt.plot(historico3.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = mod_emb.get_layer('vetorizacao')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18268, 50)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_train.get_layer('emb_layer').set_weights(mod_emb.get_layer('vetorizacao').get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211.46341"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.sum(np.square(mod_emb.get_layer('vetorizacao').get_weights()[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.45888"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.sum(np.square(mod_emb.get_layer('vetorizacao').get_weights()[0]-mod_train.get_layer('emb_layer').get_weights()[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_model(vocab_size, story_max_len = 256, emb_dim=64, num_lstm=64, num_relu1=32, num_relu2=16, num_relu3=8):\n",
    "    input_layer = keras.layers.Input(shape=(story_max_len,), name='input_layer')\n",
    "    X = keras.layers.Embedding(vocab_size, emb_dim, mask_zero=True, name='emb_layer')(input_layer)\n",
    "    X = keras.layers.LSTM(num_lstm)(X)\n",
    "    X = keras.layers.Dropout(0.3)(X)\n",
    "    X = CamadaHipercubo(num_relu1)(X)\n",
    "    X = keras.layers.Dropout(0.15)(X)\n",
    "    X = CamadaHipercubo(num_relu2)(X)\n",
    "    X = CamadaHipercubo(num_relu3)(X)\n",
    "    X = CamadaHipercubo(4)(X)\n",
    "    output_layer = BiggerThanOneReg()(X)\n",
    "    return keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "def initialize_train_model(model, emb_weights, bias=2):\n",
    "    model.compile(loss='mae',optimizer='adam')\n",
    "    model.get_layer('emb_layer').set_weights(emb_weights)\n",
    "    #model.layers[-1].set_weights([mod_train.layers[-1].get_weights()[0], np.array([bias])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_train = create_train_model(len(dic))\n",
    "initialize_train_model(mod_train, mod_emb.get_layer('vetorizacao').get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.callbacks.ModelCheckpoint?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aasdfb\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2801 samples, validate on 933 samples\n",
      "Epoch 1/20\n",
      "2801/2801 [==============================] - 21s 7ms/step - loss: 5.4544 - val_loss: 4.1005\n",
      "Epoch 2/20\n",
      "2801/2801 [==============================] - 20s 7ms/step - loss: 4.8522 - val_loss: 4.0385\n",
      "Epoch 3/20\n",
      "2801/2801 [==============================] - 20s 7ms/step - loss: 4.8460 - val_loss: 4.0358\n",
      "Epoch 4/20\n",
      "2801/2801 [==============================] - 21s 8ms/step - loss: 4.8548 - val_loss: 4.0358\n",
      "Epoch 5/20\n",
      "2801/2801 [==============================] - 21s 8ms/step - loss: 4.7948 - val_loss: 4.0095\n",
      "Epoch 6/20\n",
      "2801/2801 [==============================] - 22s 8ms/step - loss: 4.6346 - val_loss: 3.8592\n",
      "Epoch 7/20\n",
      "2801/2801 [==============================] - 22s 8ms/step - loss: 4.3234 - val_loss: 3.9890\n",
      "Epoch 8/20\n",
      "2801/2801 [==============================] - 22s 8ms/step - loss: 4.1086 - val_loss: 3.7309\n",
      "Epoch 9/20\n",
      "2801/2801 [==============================] - 21s 8ms/step - loss: 3.6655 - val_loss: 3.7230\n",
      "Epoch 10/20\n",
      "2801/2801 [==============================] - 21s 8ms/step - loss: 3.3903 - val_loss: 3.5719\n",
      "Epoch 11/20\n",
      "2801/2801 [==============================] - 21s 8ms/step - loss: 3.1962 - val_loss: 3.5495\n",
      "Epoch 12/20\n",
      "2801/2801 [==============================] - 21s 8ms/step - loss: 3.0337 - val_loss: 3.5550\n",
      "Epoch 13/20\n",
      "2801/2801 [==============================] - 21s 8ms/step - loss: 2.9207 - val_loss: 3.6776\n",
      "Epoch 14/20\n",
      "2801/2801 [==============================] - 21s 8ms/step - loss: 2.8228 - val_loss: 3.6069\n",
      "Epoch 15/20\n",
      "2801/2801 [==============================] - 21s 8ms/step - loss: 2.7271 - val_loss: 3.5492\n",
      "Epoch 16/20\n",
      "2801/2801 [==============================] - 21s 8ms/step - loss: 2.6285 - val_loss: 3.5921\n",
      "Epoch 17/20\n",
      "2801/2801 [==============================] - 21s 8ms/step - loss: 2.6843 - val_loss: 3.5665\n",
      "Epoch 18/20\n",
      "2801/2801 [==============================] - 21s 8ms/step - loss: 2.4564 - val_loss: 3.6066\n",
      "Epoch 19/20\n",
      "2801/2801 [==============================] - 21s 8ms/step - loss: 2.4469 - val_loss: 3.6583\n",
      "Epoch 20/20\n",
      "2801/2801 [==============================] - 21s 8ms/step - loss: 2.3184 - val_loss: 3.6212\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-59fd58c76837>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlog_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCSVLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'logs/en/%s.log'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mhist_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msave_best\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_csv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msave_to_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'logs/en/%s.pkl'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-115-10b429676805>\u001b[0m in \u001b[0;36msave_to_pickle\u001b[0;34m(data, file_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_to_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmascara_cubo_hipercubo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim_entrada\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_saida\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: write() argument must be str, not bytes"
     ]
    }
   ],
   "source": [
    "save_best = keras.callbacks.ModelCheckpoint('models/en/%s.h5' % 'train', monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)\n",
    "log_csv = keras.callbacks.CSVLogger('logs/en/%s.log' % 'train')\n",
    "hist_train = mod_train.fit(x_train, np.clip(y_train, 1, 21), epochs=20, validation_data=(x_val, np.clip(y_val, 1, 21)), callbacks=[save_best, log_csv])\n",
    "save_to_pickle(hist_train, 'logs/en/%s.pkl' % 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_pickle(hist_train, 'logs/en/%s.pkl' % 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "933/933 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "212.65664538539875"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_train.evaluate(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_train = keras.models.load_model('models/train.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "predito = mod_train.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predito<1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.9249587"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs(predito-y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(train_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.668086"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs(np.mean(y_train)-y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist_train.history['loss'])\n",
    "plt.plot(hist_train.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_repos = {\n",
    "    'mesos': 'apache',\n",
    "    'usergrid': 'apache',\n",
    "    'appceleratorstudio': 'appcelerator',\n",
    "    'aptanastudio': 'appcelerator',\n",
    "    'titanium': 'appcelerator',\n",
    "    'duracloud': 'duraspace',\n",
    "    'bamboo': 'jira',\n",
    "    'clover': 'jira',\n",
    "    'jirasoftware': 'jira',\n",
    "    'moodle': 'moodle',\n",
    "    'datamanagement': 'lsstcorp',\n",
    "    'mule': 'mulesoft',\n",
    "    'mulestudio': 'mulesoft',\n",
    "    'springxd': 'spring',\n",
    "    'talenddataquality': 'talendforge',\n",
    "    'talendesb': 'talendforge'\n",
    "}\n",
    "story_points_clip = {\n",
    "    'mesos': 5.0,\n",
    "    'usergrid': 5.0,\n",
    "    'appceleratorstudio': 8.0,\n",
    "    'aptanastudio': 13.0,\n",
    "    'titanium': 13.0,\n",
    "    'duracloud': 4.0,\n",
    "    'bamboo': 5.0,\n",
    "    'clover': 13.0,\n",
    "    'jirasoftware': 8.0,\n",
    "    'moodle': 40.0,\n",
    "    'datamanagement': 21.0,\n",
    "    'mule': 8.0,\n",
    "    'mulestudio': 13.0,\n",
    "    'springxd': 8.0,\n",
    "    'talenddataquality': 13.0,\n",
    "    'talendesb': 3.0\n",
    "}\n",
    "deepse_baseline = {\n",
    "    'mesos': 1.02,\n",
    "    'usergrid': 1.03,\n",
    "    'appceleratorstudio': 1.36,\n",
    "    'aptanastudio': 2.71,\n",
    "    'titanium': 1.97,\n",
    "    'duracloud': 0.68,\n",
    "    'bamboo': 0.74,\n",
    "    'clover': 2.11,\n",
    "    'jirasoftware': 1.38,\n",
    "    'moodle': 5.97,\n",
    "    'datamanagement': 3.77,\n",
    "    'mule': 2.18,\n",
    "    'mulestudio': 3.23,\n",
    "    'springxd': 1.63,\n",
    "    'talenddataquality': 2.97,\n",
    "    'talendesb': 0.64\n",
    "}\n",
    "project_name = {\n",
    "    'mesos': 'Mesos',\n",
    "    'usergrid': 'Usergrid',\n",
    "    'appceleratorstudio': 'Appcelerator Studio',\n",
    "    'aptanastudio': 'Aptana Studio',\n",
    "    'titanium': 'Titanium SDK/CLI',\n",
    "    'duracloud': 'DuraCloud',\n",
    "    'bamboo': 'Bamboo',\n",
    "    'clover': 'Clover',\n",
    "    'jirasoftware': 'Jira Software',\n",
    "    'moodle': 'Moodle',\n",
    "    'datamanagement': 'Data Management',\n",
    "    'mule': 'Mule',\n",
    "    'mulestudio': 'Mule Studio',\n",
    "    'springxd': 'Spring XD',\n",
    "    'talenddataquality': 'Talend Data Quality',\n",
    "    'talendesb': 'Talend ESB'\n",
    "}\n",
    "repo_name = {\n",
    "    'apache': 'Apache',\n",
    "    'appcelerator': 'Appcelerator',\n",
    "    'duraspace': 'DuraSpace',\n",
    "    'jira': 'Atlassian',\n",
    "    'moodle': 'Moodle',\n",
    "    'lsstcorp': 'LSST Corporation',\n",
    "    'mulesoft': 'MuleSoft',\n",
    "    'spring': 'Spring',\n",
    "    'talendforge': 'TalendForge'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain(repo, pretrain_data_path, train_data_path, tokenizer, project_repos, dic_data_path, log_pre_data_path, model_data_path, hist_pre_data_path):\n",
    "    unlabelled_words, _ = ler_csv_texto_tokenizado(pretrain_data_path % repo, tokenizer)\n",
    "    for project in [k for k, v in project_repos.items() if v == repo]:\n",
    "        story_words, _ = ler_csv_texto_tokenizado(train_data_path % project, tokenizer)\n",
    "        num_test = int(round(len(story_words) * test_fraction))\n",
    "        num_val = int(round(len(story_words) * val_fraction))\n",
    "        num_train = len(story_words) - num_test - num_val\n",
    "        unlabelled_words.extend(story_words[:num_train])\n",
    "    dic = gerar_dicionario(unlabelled_words)\n",
    "    save_to_pickle(dic, dic_data_path % repo)\n",
    "    pretrain_tokens = converte_tokens_pretreino(unlabelled_words, dic)\n",
    "    \n",
    "    print_log_out(\"%s, %d\" % (repo, len(pretrain_tokens)))\n",
    "\n",
    "    gerador_treino = GeradorDados(pretrain_tokens, 128, 2048)\n",
    "    gerador_valida = GeradorDados(pretrain_tokens, 128, 64)\n",
    "    mod_emb = gerar_modelo_keras(len(dic))\n",
    "\n",
    "    mod_emb.compile(loss='binary_crossentropy',optimizer='adam')\n",
    "\n",
    "    log_csv = keras.callbacks.CSVLogger(log_pre_data_path % repo)\n",
    "    save_best = keras.callbacks.ModelCheckpoint(model_pre_data_path % repo, monitor='val_loss', mode='min', save_best_only=True)\n",
    "    hist_pretrain = mod_emb.fit_generator(generator=gerador_treino, epochs=500, use_multiprocessing=False, shuffle=False, max_queue_size=4096, validation_data=gerador_valida, callbacks=[save_best, log_csv])\n",
    "    save_to_pickle(hist_pretrain.history, hist_pre_data_path % repo)\n",
    "    \n",
    "    return mod_emb\n",
    "\n",
    "def train(train_data_path, dic_data_path, tokenizer, project_repos, log_data_path, model_data_path, hist_data_path):\n",
    "    story_words, story_points = ler_csv_texto_tokenizado(train_data_path % project, tokenizer)\n",
    "    dic = load_pickle(dic_data_path % project_repos[project])\n",
    "    x_train, x_val, x_test = converte_tokens_treino(story_words, dic)\n",
    "    y_train = story_points[:x_train.shape[0]].reshape((-1, 1))\n",
    "    y_val = story_points[x_train.shape[0]:x_train.shape[0]+x_val.shape[0]].reshape((-1, 1))\n",
    "    y_test = story_points[x_train.shape[0] + x_val.shape[0]:].reshape((-1, 1))\n",
    "    \n",
    "    print_log_out(\"%s, %d, %d\" % (project, x_train.shape[0], x_val.shape[0]))\n",
    "\n",
    "    mod_train = create_train_model(len(dic))\n",
    "    mod_emb.load_weights(model_pre_data_path % project_repos[project])\n",
    "    initialize_train_model(mod_train, mod_emb.get_layer('vetorizacao').get_weights())\n",
    "\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=12, min_delta=0)\n",
    "    save_best = keras.callbacks.ModelCheckpoint(model_data_path % project, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)\n",
    "    log_csv = keras.callbacks.CSVLogger(log_data_path % project)\n",
    "    hist_train = mod_train.fit(x_train, np.clip(y_train, 1, story_points_clip[project]), epochs=40, validation_data=(x_val, np.clip(y_val, 1, story_points_clip[project])), callbacks=[save_best, log_csv, early_stopping])\n",
    "    save_to_pickle(hist_train.history, hist_data_path % project)\n",
    "    \n",
    "    return mod_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ccasj, 17224\n",
      "Epoch 1/500\n",
      "2048/2048 [==============================] - 7s 4ms/step - loss: 0.6820 - val_loss: 0.6630\n",
      "Epoch 2/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6533 - val_loss: 0.6512\n",
      "Epoch 3/500\n",
      "2048/2048 [==============================] - 7s 4ms/step - loss: 0.6437 - val_loss: 0.6391\n",
      "Epoch 4/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6375 - val_loss: 0.6376\n",
      "Epoch 5/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6343 - val_loss: 0.6344\n",
      "Epoch 6/500\n",
      " 129/2048 [>.............................] - ETA: 55s - loss: 0.6351 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.109325). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 7s 4ms/step - loss: 0.6331 - val_loss: 0.6348\n",
      "Epoch 7/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6317 - val_loss: 0.6331\n",
      "Epoch 8/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6292 - val_loss: 0.6260\n",
      "Epoch 9/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6285 - val_loss: 0.6253\n",
      "Epoch 10/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6287 - val_loss: 0.6315\n",
      "Epoch 11/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6267 - val_loss: 0.6248\n",
      "Epoch 12/500\n",
      "2048/2048 [==============================] - 9s 5ms/step - loss: 0.6263 - val_loss: 0.6289\n",
      "Epoch 13/500\n",
      "  89/2048 [>.............................] - ETA: 1:16 - loss: 0.6245"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.101384). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6255 - val_loss: 0.6350\n",
      "Epoch 14/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6248 - val_loss: 0.6298\n",
      "Epoch 15/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6246 - val_loss: 0.6233\n",
      "Epoch 16/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6237 - val_loss: 0.6251\n",
      "Epoch 17/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6236 - val_loss: 0.6214\n",
      "Epoch 18/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6224 - val_loss: 0.6281\n",
      "Epoch 19/500\n",
      "  13/2048 [..............................] - ETA: 6:09 - loss: 0.6123"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.102637). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.100640). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.106133). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  60/2048 [..............................] - ETA: 1:45 - loss: 0.6201"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.108706). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.108312). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6228 - val_loss: 0.6158\n",
      "Epoch 20/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6225 - val_loss: 0.6227\n",
      "Epoch 21/500\n",
      "2048/2048 [==============================] - 9s 5ms/step - loss: 0.6218 - val_loss: 0.6222\n",
      "Epoch 22/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6216 - val_loss: 0.6175\n",
      "Epoch 23/500\n",
      "2048/2048 [==============================] - 11s 5ms/step - loss: 0.6213 - val_loss: 0.6216\n",
      "Epoch 24/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6204 - val_loss: 0.6227\n",
      "Epoch 25/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6217 - val_loss: 0.6201\n",
      "Epoch 26/500\n",
      "2048/2048 [==============================] - 7s 4ms/step - loss: 0.6217 - val_loss: 0.6228\n",
      "Epoch 27/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6194 - val_loss: 0.6206\n",
      "Epoch 28/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6211 - val_loss: 0.6209\n",
      "Epoch 29/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6184 - val_loss: 0.6277\n",
      "Epoch 30/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6195 - val_loss: 0.6234\n",
      "Epoch 31/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6210 - val_loss: 0.6230\n",
      "Epoch 32/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6192 - val_loss: 0.6235\n",
      "Epoch 33/500\n",
      "2048/2048 [==============================] - 9s 5ms/step - loss: 0.6183 - val_loss: 0.6199\n",
      "Epoch 34/500\n",
      "2048/2048 [==============================] - 7s 4ms/step - loss: 0.6195 - val_loss: 0.6226\n",
      "Epoch 35/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6196 - val_loss: 0.6221\n",
      "Epoch 36/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6187 - val_loss: 0.6202\n",
      "Epoch 37/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6202 - val_loss: 0.6138\n",
      "Epoch 38/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6199 - val_loss: 0.6177\n",
      "Epoch 39/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6185 - val_loss: 0.6194\n",
      "Epoch 40/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6170 - val_loss: 0.6166\n",
      "Epoch 41/500\n",
      "  17/2048 [..............................] - ETA: 4:39 - loss: 0.6332"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.116906). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.135468). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  87/2048 [>.............................] - ETA: 1:16 - loss: 0.6183"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.127561). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 7s 4ms/step - loss: 0.6173 - val_loss: 0.6187\n",
      "Epoch 42/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6171 - val_loss: 0.6254\n",
      "Epoch 43/500\n",
      "2048/2048 [==============================] - 9s 5ms/step - loss: 0.6178 - val_loss: 0.6141\n",
      "Epoch 44/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6175 - val_loss: 0.6210\n",
      "Epoch 45/500\n",
      "2048/2048 [==============================] - 9s 5ms/step - loss: 0.6194 - val_loss: 0.6119\n",
      "Epoch 46/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6169 - val_loss: 0.6146\n",
      "Epoch 47/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6170 - val_loss: 0.6215\n",
      "Epoch 48/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6169 - val_loss: 0.6179\n",
      "Epoch 49/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6170 - val_loss: 0.6145\n",
      "Epoch 50/500\n",
      "   8/2048 [..............................] - ETA: 2:05 - loss: 0.6266"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.111193). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6171 - val_loss: 0.6137\n",
      "Epoch 51/500\n",
      "   7/2048 [..............................] - ETA: 2:12 - loss: 0.6056"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.109736). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.104735). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6168 - val_loss: 0.6142\n",
      "Epoch 52/500\n",
      "  56/2048 [..............................] - ETA: 2:21 - loss: 0.6192"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.100080). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6174 - val_loss: 0.6217\n",
      "Epoch 53/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6179 - val_loss: 0.6141\n",
      "Epoch 54/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6165 - val_loss: 0.6198\n",
      "Epoch 55/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6151 - val_loss: 0.6148\n",
      "Epoch 56/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6166 - val_loss: 0.6187\n",
      "Epoch 57/500\n",
      "  23/2048 [..............................] - ETA: 5:01 - loss: 0.6306"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.102588). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6166 - val_loss: 0.6140\n",
      "Epoch 58/500\n",
      "2048/2048 [==============================] - 7s 4ms/step - loss: 0.6155 - val_loss: 0.6129\n",
      "Epoch 59/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6162 - val_loss: 0.6219\n",
      "Epoch 60/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6170 - val_loss: 0.6131\n",
      "Epoch 61/500\n",
      "2048/2048 [==============================] - 12s 6ms/step - loss: 0.6163 - val_loss: 0.6138\n",
      "Epoch 62/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6169 - val_loss: 0.6141\n",
      "Epoch 63/500\n",
      "  39/2048 [..............................] - ETA: 3:15 - loss: 0.6164"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.114574). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.121607). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 110/2048 [>.............................] - ETA: 1:10 - loss: 0.6148"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.110313). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6155 - val_loss: 0.6152\n",
      "Epoch 64/500\n",
      "2048/2048 [==============================] - 4s 2ms/step - loss: 0.6170 - val_loss: 0.6160\n",
      "Epoch 65/500\n",
      "2048/2048 [==============================] - 9s 5ms/step - loss: 0.6146 - val_loss: 0.6230\n",
      "Epoch 66/500\n",
      "2048/2048 [==============================] - 12s 6ms/step - loss: 0.6171 - val_loss: 0.6111\n",
      "Epoch 67/500\n",
      "2048/2048 [==============================] - 4s 2ms/step - loss: 0.6156 - val_loss: 0.6162\n",
      "Epoch 68/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6164 - val_loss: 0.6124\n",
      "Epoch 69/500\n",
      "2048/2048 [==============================] - 7s 4ms/step - loss: 0.6155 - val_loss: 0.6182\n",
      "Epoch 70/500\n",
      "  23/2048 [..............................] - ETA: 2:00 - loss: 0.6151"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.110078). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6155 - val_loss: 0.6206\n",
      "Epoch 71/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6153 - val_loss: 0.6137\n",
      "Epoch 72/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6155 - val_loss: 0.6084\n",
      "Epoch 73/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6149 - val_loss: 0.6178\n",
      "Epoch 74/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6158 - val_loss: 0.6174\n",
      "Epoch 75/500\n",
      "2048/2048 [==============================] - 9s 5ms/step - loss: 0.6153 - val_loss: 0.6217\n",
      "Epoch 76/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6159 - val_loss: 0.6151\n",
      "Epoch 77/500\n",
      " 111/2048 [>.............................] - ETA: 1:14 - loss: 0.6148"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.135344). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6155 - val_loss: 0.6090\n",
      "Epoch 78/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6155 - val_loss: 0.6131\n",
      "Epoch 79/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6151 - val_loss: 0.6139\n",
      "Epoch 80/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6153 - val_loss: 0.6145\n",
      "Epoch 81/500\n",
      " 191/2048 [=>............................] - ETA: 42s - loss: 0.6116"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.100096). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6151 - val_loss: 0.6172\n",
      "Epoch 82/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6153 - val_loss: 0.6114\n",
      "Epoch 83/500\n",
      "  20/2048 [..............................] - ETA: 4:30 - loss: 0.6049"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.104566). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  88/2048 [>.............................] - ETA: 1:17 - loss: 0.6102"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.104228). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 7s 4ms/step - loss: 0.6155 - val_loss: 0.6191\n",
      "Epoch 84/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6151 - val_loss: 0.6095\n",
      "Epoch 85/500\n",
      "2048/2048 [==============================] - 11s 5ms/step - loss: 0.6141 - val_loss: 0.6139\n",
      "Epoch 86/500\n",
      "2048/2048 [==============================] - 9s 5ms/step - loss: 0.6148 - val_loss: 0.6106\n",
      "Epoch 87/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6154 - val_loss: 0.6212\n",
      "Epoch 88/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6144 - val_loss: 0.6232\n",
      "Epoch 89/500\n",
      "2048/2048 [==============================] - ETA: 0s - loss: 0.614 - 10s 5ms/step - loss: 0.6148 - val_loss: 0.6211\n",
      "Epoch 90/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6141 - val_loss: 0.6052\n",
      "Epoch 91/500\n",
      "2048/2048 [==============================] - 9s 5ms/step - loss: 0.6138 - val_loss: 0.6171\n",
      "Epoch 92/500\n",
      "2048/2048 [==============================] - 7s 4ms/step - loss: 0.6151 - val_loss: 0.6081\n",
      "Epoch 93/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6145 - val_loss: 0.6123\n",
      "Epoch 94/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6145 - val_loss: 0.6128\n",
      "Epoch 95/500\n",
      "  63/2048 [..............................] - ETA: 1:50 - loss: 0.6198"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.102904). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 7s 4ms/step - loss: 0.6140 - val_loss: 0.6098\n",
      "Epoch 96/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6134 - val_loss: 0.6156\n",
      "Epoch 97/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6147 - val_loss: 0.6140\n",
      "Epoch 98/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6149 - val_loss: 0.6090\n",
      "Epoch 99/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6135 - val_loss: 0.6146\n",
      "Epoch 100/500\n",
      "2048/2048 [==============================] - 7s 4ms/step - loss: 0.6146 - val_loss: 0.6168\n",
      "Epoch 101/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6138 - val_loss: 0.6188\n",
      "Epoch 102/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6141 - val_loss: 0.6136\n",
      "Epoch 103/500\n",
      "  31/2048 [..............................] - ETA: 2:42 - loss: 0.6085"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.100879). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 7s 4ms/step - loss: 0.6151 - val_loss: 0.6208\n",
      "Epoch 104/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6134 - val_loss: 0.6076\n",
      "Epoch 105/500\n",
      "2048/2048 [==============================] - 7s 4ms/step - loss: 0.6125 - val_loss: 0.6148\n",
      "Epoch 106/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6148 - val_loss: 0.6093\n",
      "Epoch 107/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6150 - val_loss: 0.6139\n",
      "Epoch 108/500\n",
      "  10/2048 [..............................] - ETA: 8:06 - loss: 0.6090"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.110692). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  58/2048 [..............................] - ETA: 1:42 - loss: 0.6108"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.111929). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.108266). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 7s 3ms/step - loss: 0.6141 - val_loss: 0.6073\n",
      "Epoch 109/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6149 - val_loss: 0.6153\n",
      "Epoch 110/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6146 - val_loss: 0.6134\n",
      "Epoch 111/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6137 - val_loss: 0.6088\n",
      "Epoch 112/500\n",
      "2048/2048 [==============================] - 9s 5ms/step - loss: 0.6143 - val_loss: 0.6174\n",
      "Epoch 113/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6136 - val_loss: 0.6176\n",
      "Epoch 114/500\n",
      "2048/2048 [==============================] - 9s 5ms/step - loss: 0.6131 - val_loss: 0.6181\n",
      "Epoch 115/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6132 - val_loss: 0.6216\n",
      "Epoch 116/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6142 - val_loss: 0.6149\n",
      "Epoch 117/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6133 - val_loss: 0.6169\n",
      "Epoch 118/500\n",
      " 140/2048 [=>............................] - ETA: 44s - loss: 0.6144"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.113690). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 141/2048 [=>............................] - ETA: 48s - loss: 0.6143"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.125619). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.144974). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 187/2048 [=>............................] - ETA: 42s - loss: 0.6145"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.123931). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.100830). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6145 - val_loss: 0.6169\n",
      "Epoch 119/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6129 - val_loss: 0.6188\n",
      "Epoch 120/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6141 - val_loss: 0.6141\n",
      "Epoch 121/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6121 - val_loss: 0.6097\n",
      "Epoch 122/500\n",
      "  23/2048 [..............................] - ETA: 3:39 - loss: 0.6152"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.102686). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.104573). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  42/2048 [..............................] - ETA: 2:52 - loss: 0.6168"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.101251). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6144 - val_loss: 0.6114\n",
      "Epoch 123/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6131 - val_loss: 0.6127\n",
      "Epoch 124/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6138 - val_loss: 0.6139\n",
      "Epoch 125/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6129 - val_loss: 0.6223\n",
      "Epoch 126/500\n",
      "2048/2048 [==============================] - 11s 5ms/step - loss: 0.6134 - val_loss: 0.6121\n",
      "Epoch 127/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6131 - val_loss: 0.6097\n",
      "Epoch 128/500\n",
      "  66/2048 [..............................] - ETA: 1:45 - loss: 0.6101"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.102555). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6120 - val_loss: 0.6150\n",
      "Epoch 129/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6138 - val_loss: 0.6155\n",
      "Epoch 130/500\n",
      "2048/2048 [==============================] - 9s 5ms/step - loss: 0.6129 - val_loss: 0.6192\n",
      "Epoch 131/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6122 - val_loss: 0.6129\n",
      "Epoch 132/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6137 - val_loss: 0.6126\n",
      "Epoch 133/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6144 - val_loss: 0.6141\n",
      "Epoch 134/500\n",
      " 178/2048 [=>............................] - ETA: 48s - loss: 0.6081"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.107599). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.109004). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6122 - val_loss: 0.6183\n",
      "Epoch 135/500\n",
      "2048/2048 [==============================] - 11s 5ms/step - loss: 0.6131 - val_loss: 0.6170\n",
      "Epoch 136/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6131 - val_loss: 0.6143\n",
      "Epoch 137/500\n",
      "2048/2048 [==============================] - 11s 5ms/step - loss: 0.6128 - val_loss: 0.6185\n",
      "Epoch 138/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6135 - val_loss: 0.6093\n",
      "Epoch 139/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6126 - val_loss: 0.6082\n",
      "Epoch 140/500\n",
      "  68/2048 [..............................] - ETA: 1:40 - loss: 0.6140"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.105462). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6127 - val_loss: 0.6162\n",
      "Epoch 141/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6133 - val_loss: 0.6090\n",
      "Epoch 142/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6121 - val_loss: 0.6100\n",
      "Epoch 143/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6128 - val_loss: 0.6169\n",
      "Epoch 144/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6123 - val_loss: 0.6185\n",
      "Epoch 145/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6127 - val_loss: 0.6177\n",
      "Epoch 146/500\n",
      "   3/2048 [..............................] - ETA: 3:42 - loss: 0.6898"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.114491). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6136 - val_loss: 0.6199\n",
      "Epoch 147/500\n",
      "2048/2048 [==============================] - 11s 5ms/step - loss: 0.6132 - val_loss: 0.6092\n",
      "Epoch 148/500\n",
      "  76/2048 [>.............................] - ETA: 1:33 - loss: 0.6136"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.105454). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.104010). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6125 - val_loss: 0.6123\n",
      "Epoch 149/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6115 - val_loss: 0.6203\n",
      "Epoch 150/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6117 - val_loss: 0.6108\n",
      "Epoch 151/500\n",
      "  26/2048 [..............................] - ETA: 4:46 - loss: 0.6118"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.104938). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  72/2048 [>.............................] - ETA: 1:50 - loss: 0.6086"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.106555). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6126 - val_loss: 0.6146\n",
      "Epoch 152/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6131 - val_loss: 0.6124\n",
      "Epoch 153/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6124 - val_loss: 0.6128\n",
      "Epoch 154/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6122 - val_loss: 0.6161\n",
      "Epoch 155/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6117 - val_loss: 0.6164\n",
      "Epoch 156/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6124 - val_loss: 0.6105\n",
      "Epoch 157/500\n",
      "2048/2048 [==============================] - 11s 5ms/step - loss: 0.6127 - val_loss: 0.6068\n",
      "Epoch 158/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6131 - val_loss: 0.6074\n",
      "Epoch 159/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6128 - val_loss: 0.6092\n",
      "Epoch 160/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6127 - val_loss: 0.6157\n",
      "Epoch 161/500\n",
      "  15/2048 [..............................] - ETA: 5:12 - loss: 0.6048"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.101998). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  62/2048 [..............................] - ETA: 1:45 - loss: 0.6102"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.111625). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 7s 4ms/step - loss: 0.6120 - val_loss: 0.6189\n",
      "Epoch 162/500\n",
      "  15/2048 [..............................] - ETA: 6:04 - loss: 0.6097"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.105687). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  52/2048 [..............................] - ETA: 2:01 - loss: 0.6141"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.107587). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.103767). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 7s 4ms/step - loss: 0.6138 - val_loss: 0.6174\n",
      "Epoch 163/500\n",
      "2048/2048 [==============================] - 12s 6ms/step - loss: 0.6129 - val_loss: 0.6147\n",
      "Epoch 164/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6123 - val_loss: 0.6135\n",
      "Epoch 165/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6116 - val_loss: 0.6147\n",
      "Epoch 166/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6128 - val_loss: 0.6190\n",
      "Epoch 167/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6131 - val_loss: 0.6088\n",
      "Epoch 168/500\n",
      "   7/2048 [..............................] - ETA: 6:30 - loss: 0.6127"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.137062). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.155058). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  59/2048 [..............................] - ETA: 1:45 - loss: 0.6119"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.173054). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.187202). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6132 - val_loss: 0.6095\n",
      "Epoch 169/500\n",
      "2048/2048 [==============================] - 6s 3ms/step - loss: 0.6128 - val_loss: 0.6106\n",
      "Epoch 170/500\n",
      "2048/2048 [==============================] - 9s 5ms/step - loss: 0.6124 - val_loss: 0.6122\n",
      "Epoch 171/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6122 - val_loss: 0.6079\n",
      "Epoch 172/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6129 - val_loss: 0.6155\n",
      "Epoch 173/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6117 - val_loss: 0.6195\n",
      "Epoch 174/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6127 - val_loss: 0.6142\n",
      "Epoch 175/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6120 - val_loss: 0.6164\n",
      "Epoch 176/500\n",
      "2048/2048 [==============================] - 9s 5ms/step - loss: 0.6129 - val_loss: 0.6066\n",
      "Epoch 177/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6121 - val_loss: 0.6076\n",
      "Epoch 178/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6121 - val_loss: 0.6099\n",
      "Epoch 179/500\n",
      "  24/2048 [..............................] - ETA: 3:16 - loss: 0.6169"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.101918). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.104545). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  55/2048 [..............................] - ETA: 2:10 - loss: 0.6161"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.107428). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.102585). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6137 - val_loss: 0.6126\n",
      "Epoch 180/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6119 - val_loss: 0.6168\n",
      "Epoch 181/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6125 - val_loss: 0.6134\n",
      "Epoch 182/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6128 - val_loss: 0.6126\n",
      "Epoch 183/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6117 - val_loss: 0.6049\n",
      "Epoch 184/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6112 - val_loss: 0.6134\n",
      "Epoch 185/500\n",
      "2048/2048 [==============================] - 12s 6ms/step - loss: 0.6134 - val_loss: 0.6158\n",
      "Epoch 186/500\n",
      "2048/2048 [==============================] - 5s 3ms/step - loss: 0.6129 - val_loss: 0.6092\n",
      "Epoch 187/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6120 - val_loss: 0.6145\n",
      "Epoch 188/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6120 - val_loss: 0.6114\n",
      "Epoch 189/500\n",
      "2048/2048 [==============================] - 11s 5ms/step - loss: 0.6129 - val_loss: 0.6111\n",
      "Epoch 190/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6119 - val_loss: 0.6175\n",
      "Epoch 191/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6114 - val_loss: 0.6134\n",
      "Epoch 192/500\n",
      "   4/2048 [..............................] - ETA: 15:49 - loss: 0.5942"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (1.644069). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.834160). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 9s 5ms/step - loss: 0.6125 - val_loss: 0.6163\n",
      "Epoch 193/500\n",
      "2048/2048 [==============================] - 7s 3ms/step - loss: 0.6124 - val_loss: 0.6103\n",
      "Epoch 194/500\n",
      "2048/2048 [==============================] - 11s 5ms/step - loss: 0.6113 - val_loss: 0.6145\n",
      "Epoch 195/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6129 - val_loss: 0.6103\n",
      "Epoch 196/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6122 - val_loss: 0.6087\n",
      "Epoch 197/500\n",
      "2048/2048 [==============================] - 9s 5ms/step - loss: 0.6128 - val_loss: 0.6190\n",
      "Epoch 198/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6113 - val_loss: 0.6080\n",
      "Epoch 199/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6119 - val_loss: 0.6117\n",
      "Epoch 200/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6114 - val_loss: 0.6113\n",
      "Epoch 201/500\n",
      "  77/2048 [>.............................] - ETA: 1:28 - loss: 0.6121"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.107530). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 7s 4ms/step - loss: 0.6122 - val_loss: 0.6160\n",
      "Epoch 202/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6110 - val_loss: 0.6130\n",
      "Epoch 203/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6104 - val_loss: 0.6080\n",
      "Epoch 204/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6113 - val_loss: 0.6132\n",
      "Epoch 205/500\n",
      "  12/2048 [..............................] - ETA: 5:42 - loss: 0.6200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.105380). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  14/2048 [..............................] - ETA: 6:57 - loss: 0.6145"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.116733). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  76/2048 [>.............................] - ETA: 1:25 - loss: 0.6103"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.110744). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.102623). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 7s 4ms/step - loss: 0.6122 - val_loss: 0.6157\n",
      "Epoch 206/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6126 - val_loss: 0.6124\n",
      "Epoch 207/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6118 - val_loss: 0.6113\n",
      "Epoch 208/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6125 - val_loss: 0.6114\n",
      "Epoch 209/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6127 - val_loss: 0.6151\n",
      "Epoch 210/500\n",
      "  19/2048 [..............................] - ETA: 4:51 - loss: 0.6239"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.113414). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  21/2048 [..............................] - ETA: 5:06 - loss: 0.6248"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.103483). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6103 - val_loss: 0.6108\n",
      "Epoch 211/500\n",
      "2048/2048 [==============================] - 9s 5ms/step - loss: 0.6128 - val_loss: 0.6154\n",
      "Epoch 212/500\n",
      "2048/2048 [==============================] - 11s 5ms/step - loss: 0.6121 - val_loss: 0.6127\n",
      "Epoch 213/500\n",
      "  17/2048 [..............................] - ETA: 5:05 - loss: 0.6180"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.187376). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  68/2048 [..............................] - ETA: 1:32 - loss: 0.6118"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.147471). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.101628). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 7s 3ms/step - loss: 0.6115 - val_loss: 0.6090\n",
      "Epoch 214/500\n",
      "  39/2048 [..............................] - ETA: 3:01 - loss: 0.6129"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.102511). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.104518). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6113 - val_loss: 0.6185\n",
      "Epoch 215/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6119 - val_loss: 0.6167\n",
      "Epoch 216/500\n",
      "2048/2048 [==============================] - 9s 5ms/step - loss: 0.6109 - val_loss: 0.6109\n",
      "Epoch 217/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6115 - val_loss: 0.6084\n",
      "Epoch 218/500\n",
      "2048/2048 [==============================] - 9s 5ms/step - loss: 0.6107 - val_loss: 0.6058\n",
      "Epoch 219/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6118 - val_loss: 0.6115\n",
      "Epoch 220/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6108 - val_loss: 0.6125\n",
      "Epoch 221/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6109 - val_loss: 0.6123\n",
      "Epoch 222/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6119 - val_loss: 0.6131\n",
      "Epoch 223/500\n",
      "2048/2048 [==============================] - 9s 5ms/step - loss: 0.6108 - val_loss: 0.6157\n",
      "Epoch 224/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6109 - val_loss: 0.6123\n",
      "Epoch 225/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6108 - val_loss: 0.6131\n",
      "Epoch 226/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6120 - val_loss: 0.6108\n",
      "Epoch 227/500\n",
      "2048/2048 [==============================] - 12s 6ms/step - loss: 0.6112 - val_loss: 0.6106\n",
      "Epoch 228/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6113 - val_loss: 0.6151\n",
      "Epoch 229/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6111 - val_loss: 0.6135\n",
      "Epoch 230/500\n",
      "  67/2048 [..............................] - ETA: 1:41 - loss: 0.6085"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.100303). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6123 - val_loss: 0.6157\n",
      "Epoch 231/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6117 - val_loss: 0.6092\n",
      "Epoch 232/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6140 - val_loss: 0.6065\n",
      "Epoch 233/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6120 - val_loss: 0.6070\n",
      "Epoch 234/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6110 - val_loss: 0.6142\n",
      "Epoch 235/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6110 - val_loss: 0.6107\n",
      "Epoch 236/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6123 - val_loss: 0.6195\n",
      "Epoch 237/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6113 - val_loss: 0.6102\n",
      "Epoch 238/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6123 - val_loss: 0.6083\n",
      "Epoch 239/500\n",
      "2048/2048 [==============================] - 11s 5ms/step - loss: 0.6123 - val_loss: 0.6058\n",
      "Epoch 240/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6112 - val_loss: 0.6097\n",
      "Epoch 241/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6108 - val_loss: 0.6094\n",
      "Epoch 242/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6135 - val_loss: 0.6171\n",
      "Epoch 243/500\n",
      "2048/2048 [==============================] - 9s 5ms/step - loss: 0.6106 - val_loss: 0.6112\n",
      "Epoch 244/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6112 - val_loss: 0.6119\n",
      "Epoch 245/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6106 - val_loss: 0.6109\n",
      "Epoch 246/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6121 - val_loss: 0.6150\n",
      "Epoch 247/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6107 - val_loss: 0.6080\n",
      "Epoch 248/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6104 - val_loss: 0.6115\n",
      "Epoch 249/500\n",
      "2048/2048 [==============================] - 9s 5ms/step - loss: 0.6104 - val_loss: 0.6092\n",
      "Epoch 250/500\n",
      "  11/2048 [..............................] - ETA: 6:05 - loss: 0.6257- ETA: 5:43 - loss: 0.62"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.100341). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.104384). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  13/2048 [..............................] - ETA: 5:55 - loss: 0.6231"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.108264). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.101560). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6122 - val_loss: 0.6217\n",
      "Epoch 251/500\n",
      "2048/2048 [==============================] - 6s 3ms/step - loss: 0.6122 - val_loss: 0.6114\n",
      "Epoch 252/500\n",
      "2048/2048 [==============================] - 11s 5ms/step - loss: 0.6102 - val_loss: 0.6143\n",
      "Epoch 253/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6115 - val_loss: 0.6122\n",
      "Epoch 254/500\n",
      "  24/2048 [..............................] - ETA: 4:03 - loss: 0.6096"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.102883). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6123 - val_loss: 0.6122\n",
      "Epoch 255/500\n",
      "2048/2048 [==============================] - 9s 5ms/step - loss: 0.6121 - val_loss: 0.6179\n",
      "Epoch 256/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6117 - val_loss: 0.6129\n",
      "Epoch 257/500\n",
      "2048/2048 [==============================] - 9s 5ms/step - loss: 0.6109 - val_loss: 0.6126\n",
      "Epoch 258/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6116 - val_loss: 0.6110\n",
      "Epoch 259/500\n",
      "2048/2048 [==============================] - 7s 4ms/step - loss: 0.6116 - val_loss: 0.6108\n",
      "Epoch 260/500\n",
      "  69/2048 [>.............................] - ETA: 2:19 - loss: 0.6119"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.104138). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6111 - val_loss: 0.6156\n",
      "Epoch 261/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6111 - val_loss: 0.6148\n",
      "Epoch 262/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6123 - val_loss: 0.6032\n",
      "Epoch 263/500\n",
      "  25/2048 [..............................] - ETA: 4:08 - loss: 0.6060- ETA: 2:06 - l"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.135224). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  56/2048 [..............................] - ETA: 2:10 - loss: 0.6096"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.106378). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6111 - val_loss: 0.6136\n",
      "Epoch 264/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6107 - val_loss: 0.6123\n",
      "Epoch 265/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6107 - val_loss: 0.6111\n",
      "Epoch 266/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6114 - val_loss: 0.6128\n",
      "Epoch 267/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6119 - val_loss: 0.6188\n",
      "Epoch 268/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6114 - val_loss: 0.6057\n",
      "Epoch 269/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6110 - val_loss: 0.6136\n",
      "Epoch 270/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6118 - val_loss: 0.6128\n",
      "Epoch 271/500\n",
      " 202/2048 [=>............................] - ETA: 40s - loss: 0.6106"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.104954). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6104 - val_loss: 0.6146\n",
      "Epoch 272/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6126 - val_loss: 0.6159\n",
      "Epoch 273/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6109 - val_loss: 0.6024\n",
      "Epoch 274/500\n",
      "2048/2048 [==============================] - 12s 6ms/step - loss: 0.6123 - val_loss: 0.6109\n",
      "Epoch 275/500\n",
      "  50/2048 [..............................] - ETA: 11s - loss: 0.6099"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.117579). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 4s 2ms/step - loss: 0.6115 - val_loss: 0.6141\n",
      "Epoch 276/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6118 - val_loss: 0.6143\n",
      "Epoch 277/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6118 - val_loss: 0.6129\n",
      "Epoch 278/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6114 - val_loss: 0.6105\n",
      "Epoch 279/500\n",
      "2048/2048 [==============================] - 11s 5ms/step - loss: 0.6112 - val_loss: 0.6117\n",
      "Epoch 280/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6114 - val_loss: 0.6096\n",
      "Epoch 281/500\n",
      "2048/2048 [==============================] - 7s 3ms/step - loss: 0.6110 - val_loss: 0.6112\n",
      "Epoch 282/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6101 - val_loss: 0.6082\n",
      "Epoch 283/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6110 - val_loss: 0.6080\n",
      "Epoch 284/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6112 - val_loss: 0.6101\n",
      "Epoch 285/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6117 - val_loss: 0.6109\n",
      "Epoch 286/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6115 - val_loss: 0.6088\n",
      "Epoch 287/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6121 - val_loss: 0.6082\n",
      "Epoch 288/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6115 - val_loss: 0.6200\n",
      "Epoch 289/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6119 - val_loss: 0.6087\n",
      "Epoch 290/500\n",
      "  13/2048 [..............................] - ETA: 5:42 - loss: 0.6108"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.109591). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  16/2048 [..............................] - ETA: 5:42 - loss: 0.6218"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.119356). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.114692). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.108273). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  70/2048 [>.............................] - ETA: 1:36 - loss: 0.6173"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.115463). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 7s 4ms/step - loss: 0.6118 - val_loss: 0.6076\n",
      "Epoch 291/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6104 - val_loss: 0.6089\n",
      "Epoch 292/500\n",
      "2048/2048 [==============================] - 11s 5ms/step - loss: 0.6103 - val_loss: 0.6106\n",
      "Epoch 293/500\n",
      "2048/2048 [==============================] - 9s 5ms/step - loss: 0.6104 - val_loss: 0.6096\n",
      "Epoch 294/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6107 - val_loss: 0.6109\n",
      "Epoch 295/500\n",
      "  18/2048 [..............................] - ETA: 4:56 - loss: 0.6072"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.103115). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  67/2048 [..............................] - ETA: 1:38 - loss: 0.6120"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.116235). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6115 - val_loss: 0.6098\n",
      "Epoch 296/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6115 - val_loss: 0.6113\n",
      "Epoch 297/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6114 - val_loss: 0.6135\n",
      "Epoch 298/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6095 - val_loss: 0.6150\n",
      "Epoch 299/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6119 - val_loss: 0.6193\n",
      "Epoch 300/500\n",
      "  46/2048 [..............................] - ETA: 2:18 - loss: 0.6122"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.111637). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 7s 3ms/step - loss: 0.6106 - val_loss: 0.6127\n",
      "Epoch 301/500\n",
      "2048/2048 [==============================] - 9s 5ms/step - loss: 0.6111 - val_loss: 0.6054\n",
      "Epoch 302/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6124 - val_loss: 0.6044\n",
      "Epoch 303/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6113 - val_loss: 0.6160\n",
      "Epoch 304/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6099 - val_loss: 0.6081\n",
      "Epoch 305/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6109 - val_loss: 0.6086\n",
      "Epoch 306/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6120 - val_loss: 0.6080\n",
      "Epoch 307/500\n",
      "2048/2048 [==============================] - 9s 5ms/step - loss: 0.6107 - val_loss: 0.6059\n",
      "Epoch 308/500\n",
      "2048/2048 [==============================] - 11s 5ms/step - loss: 0.6122 - val_loss: 0.6043\n",
      "Epoch 309/500\n",
      "2048/2048 [==============================] - 11s 5ms/step - loss: 0.6115 - val_loss: 0.6072\n",
      "Epoch 310/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6108 - val_loss: 0.6178\n",
      "Epoch 311/500\n",
      "   4/2048 [..............................] - ETA: 4:19 - loss: 0.5917"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.177051). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6112 - val_loss: 0.6056\n",
      "Epoch 312/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6130 - val_loss: 0.6140\n",
      "Epoch 313/500\n",
      "2048/2048 [==============================] - 11s 5ms/step - loss: 0.6107 - val_loss: 0.6146\n",
      "Epoch 314/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6112 - val_loss: 0.6204\n",
      "Epoch 315/500\n",
      "2048/2048 [==============================] - 11s 5ms/step - loss: 0.6100 - val_loss: 0.6064\n",
      "Epoch 316/500\n",
      "2048/2048 [==============================] - 7s 4ms/step - loss: 0.6117 - val_loss: 0.6100\n",
      "Epoch 317/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6115 - val_loss: 0.6067\n",
      "Epoch 318/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6119 - val_loss: 0.6098\n",
      "Epoch 319/500\n",
      "2048/2048 [==============================] - 9s 5ms/step - loss: 0.6111 - val_loss: 0.6075\n",
      "Epoch 320/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6111 - val_loss: 0.6134\n",
      "Epoch 321/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6104 - val_loss: 0.6050\n",
      "Epoch 322/500\n",
      "  92/2048 [>.............................] - ETA: 1:03 - loss: 0.6144"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.102571). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6108 - val_loss: 0.6065\n",
      "Epoch 323/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6120 - val_loss: 0.6066\n",
      "Epoch 324/500\n",
      "2048/2048 [==============================] - 11s 5ms/step - loss: 0.6109 - val_loss: 0.6074\n",
      "Epoch 325/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6115 - val_loss: 0.6135\n",
      "Epoch 326/500\n",
      "2048/2048 [==============================] - 11s 5ms/step - loss: 0.6111 - val_loss: 0.6140\n",
      "Epoch 327/500\n",
      "2048/2048 [==============================] - 7s 3ms/step - loss: 0.6110 - val_loss: 0.6124\n",
      "Epoch 328/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6119 - val_loss: 0.6082\n",
      "Epoch 329/500\n",
      "  84/2048 [>.............................] - ETA: 1:23 - loss: 0.6144"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.102223). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 7s 4ms/step - loss: 0.6100 - val_loss: 0.6154\n",
      "Epoch 330/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6103 - val_loss: 0.6108\n",
      "Epoch 331/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6114 - val_loss: 0.6139\n",
      "Epoch 332/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6109 - val_loss: 0.6095\n",
      "Epoch 333/500\n",
      "2048/2048 [==============================] - 11s 5ms/step - loss: 0.6098 - val_loss: 0.6156\n",
      "Epoch 334/500\n",
      "2048/2048 [==============================] - 5s 2ms/step - loss: 0.6100 - val_loss: 0.6099\n",
      "Epoch 335/500\n",
      "2048/2048 [==============================] - 7s 4ms/step - loss: 0.6115 - val_loss: 0.6078\n",
      "Epoch 336/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6100 - val_loss: 0.6041\n",
      "Epoch 337/500\n",
      " 262/2048 [==>...........................] - ETA: 34s - loss: 0.6117"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.102909). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6127 - val_loss: 0.6088\n",
      "Epoch 338/500\n",
      "   7/2048 [..............................] - ETA: 3:09 - loss: 0.6181"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.240620). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.138267). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6120 - val_loss: 0.6093\n",
      "Epoch 339/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6108 - val_loss: 0.6090\n",
      "Epoch 340/500\n",
      "   6/2048 [..............................] - ETA: 3:19 - loss: 0.6339"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.131265). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6104 - val_loss: 0.6008\n",
      "Epoch 341/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6110 - val_loss: 0.6090\n",
      "Epoch 342/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6121 - val_loss: 0.6108\n",
      "Epoch 343/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6113 - val_loss: 0.6025\n",
      "Epoch 344/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6107 - val_loss: 0.6118\n",
      "Epoch 345/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6106 - val_loss: 0.6102\n",
      "Epoch 346/500\n",
      "2048/2048 [==============================] - 9s 5ms/step - loss: 0.6101 - val_loss: 0.6139\n",
      "Epoch 347/500\n",
      "2048/2048 [==============================] - 9s 5ms/step - loss: 0.6120 - val_loss: 0.6103\n",
      "Epoch 348/500\n",
      "  56/2048 [..............................] - ETA: 2:02 - loss: 0.6160"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.136362). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 7s 4ms/step - loss: 0.6099 - val_loss: 0.6117\n",
      "Epoch 349/500\n",
      "  44/2048 [..............................] - ETA: 2:36 - loss: 0.6141"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.100380). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6104 - val_loss: 0.6044\n",
      "Epoch 350/500\n",
      " 141/2048 [=>............................] - ETA: 59s - loss: 0.6100 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.106831). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6110 - val_loss: 0.6082\n",
      "Epoch 351/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6115 - val_loss: 0.6134\n",
      "Epoch 352/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6112 - val_loss: 0.6028\n",
      "Epoch 353/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6115 - val_loss: 0.6120\n",
      "Epoch 354/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6111 - val_loss: 0.6170\n",
      "Epoch 355/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6094 - val_loss: 0.6086\n",
      "Epoch 356/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6103 - val_loss: 0.6090\n",
      "Epoch 357/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6104 - val_loss: 0.6107\n",
      "Epoch 358/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6103 - val_loss: 0.6104\n",
      "Epoch 359/500\n",
      "2048/2048 [==============================] - 9s 5ms/step - loss: 0.6103 - val_loss: 0.6102\n",
      "Epoch 360/500\n",
      "2048/2048 [==============================] - 7s 4ms/step - loss: 0.6118 - val_loss: 0.6105\n",
      "Epoch 361/500\n",
      "2048/2048 [==============================] - 11s 5ms/step - loss: 0.6110 - val_loss: 0.6102\n",
      "Epoch 362/500\n",
      "  52/2048 [..............................] - ETA: 2:07 - loss: 0.604 - ETA: 2:12 - loss: 0.604\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.104149). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6103 - val_loss: 0.6106\n",
      "Epoch 363/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6120 - val_loss: 0.6119\n",
      "Epoch 364/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6116 - val_loss: 0.6139\n",
      "Epoch 365/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6101 - val_loss: 0.6098\n",
      "Epoch 366/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6109 - val_loss: 0.6091\n",
      "Epoch 367/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6106 - val_loss: 0.6048\n",
      "Epoch 368/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6107 - val_loss: 0.6081\n",
      "Epoch 369/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6107 - val_loss: 0.6085\n",
      "Epoch 370/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6100 - val_loss: 0.6099\n",
      "Epoch 371/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6113 - val_loss: 0.6114\n",
      "Epoch 372/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6109 - val_loss: 0.6085\n",
      "Epoch 373/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6116 - val_loss: 0.6083\n",
      "Epoch 374/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6108 - val_loss: 0.6131\n",
      "Epoch 375/500\n",
      " 168/2048 [=>............................] - ETA: 45s - loss: 0.6150"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.102759). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.104302). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 213/2048 [==>...........................] - ETA: 38s - loss: 0.6149"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.108868). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.103608). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6113 - val_loss: 0.6065\n",
      "Epoch 376/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6107 - val_loss: 0.6077\n",
      "Epoch 377/500\n",
      "2048/2048 [==============================] - 7s 3ms/step - loss: 0.6102 - val_loss: 0.6125\n",
      "Epoch 378/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6094 - val_loss: 0.6072\n",
      "Epoch 379/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6107 - val_loss: 0.6111\n",
      "Epoch 380/500\n",
      "2048/2048 [==============================] - 11s 6ms/step - loss: 0.6095 - val_loss: 0.6176\n",
      "Epoch 381/500\n",
      "2048/2048 [==============================] - 7s 3ms/step - loss: 0.6113 - val_loss: 0.6054\n",
      "Epoch 382/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6102 - val_loss: 0.6133\n",
      "Epoch 383/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6109 - val_loss: 0.6085\n",
      "Epoch 384/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6103 - val_loss: 0.6063\n",
      "Epoch 385/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6101 - val_loss: 0.6128\n",
      "Epoch 386/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6116 - val_loss: 0.6069\n",
      "Epoch 387/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6119 - val_loss: 0.6089\n",
      "Epoch 388/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6107 - val_loss: 0.6092\n",
      "Epoch 389/500\n",
      "  93/2048 [>.............................] - ETA: 1:19 - loss: 0.6053"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.105298). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6106 - val_loss: 0.6088\n",
      "Epoch 390/500\n",
      " 117/2048 [>.............................] - ETA: 1:13 - loss: 0.6100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.104829). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6093 - val_loss: 0.6173\n",
      "Epoch 391/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6119 - val_loss: 0.6119\n",
      "Epoch 392/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6096 - val_loss: 0.6146\n",
      "Epoch 393/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6095 - val_loss: 0.6076\n",
      "Epoch 394/500\n",
      "2048/2048 [==============================] - 11s 5ms/step - loss: 0.6109 - val_loss: 0.6089\n",
      "Epoch 395/500\n",
      "2048/2048 [==============================] - 11s 5ms/step - loss: 0.6120 - val_loss: 0.6045\n",
      "Epoch 396/500\n",
      "2048/2048 [==============================] - 7s 4ms/step - loss: 0.6110 - val_loss: 0.6143\n",
      "Epoch 397/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6120 - val_loss: 0.6101\n",
      "Epoch 398/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6114 - val_loss: 0.6143\n",
      "Epoch 399/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6110 - val_loss: 0.6083\n",
      "Epoch 400/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6110 - val_loss: 0.6098\n",
      "Epoch 401/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6108 - val_loss: 0.6208\n",
      "Epoch 402/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6092 - val_loss: 0.6123\n",
      "Epoch 403/500\n",
      "2048/2048 [==============================] - 11s 5ms/step - loss: 0.6113 - val_loss: 0.6106\n",
      "Epoch 404/500\n",
      "  36/2048 [..............................] - ETA: 1:36 - loss: 0.6066"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.192058). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.122386). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 6s 3ms/step - loss: 0.6112 - val_loss: 0.6039\n",
      "Epoch 405/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6101 - val_loss: 0.6194\n",
      "Epoch 406/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6107 - val_loss: 0.6120\n",
      "Epoch 407/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6104 - val_loss: 0.6055\n",
      "Epoch 408/500\n",
      "   7/2048 [..............................] - ETA: 2:37 - loss: 0.6064"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.102150). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6105 - val_loss: 0.6148\n",
      "Epoch 409/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6104 - val_loss: 0.6094\n",
      "Epoch 410/500\n",
      "2048/2048 [==============================] - 7s 4ms/step - loss: 0.6101 - val_loss: 0.6108\n",
      "Epoch 411/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6101 - val_loss: 0.6045\n",
      "Epoch 412/500\n",
      "  78/2048 [>.............................] - ETA: 1:28 - loss: 0.6075"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.115263). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 7s 4ms/step - loss: 0.6101 - val_loss: 0.6110\n",
      "Epoch 413/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6101 - val_loss: 0.6162\n",
      "Epoch 414/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6109 - val_loss: 0.6039\n",
      "Epoch 415/500\n",
      "2048/2048 [==============================] - 7s 4ms/step - loss: 0.6103 - val_loss: 0.6151\n",
      "Epoch 416/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6108 - val_loss: 0.6062\n",
      "Epoch 417/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6100 - val_loss: 0.6076\n",
      "Epoch 418/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6107 - val_loss: 0.6179\n",
      "Epoch 419/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6105 - val_loss: 0.6160\n",
      "Epoch 420/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6097 - val_loss: 0.6148\n",
      "Epoch 421/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6099 - val_loss: 0.6117\n",
      "Epoch 422/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6107 - val_loss: 0.6072\n",
      "Epoch 423/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6117 - val_loss: 0.6137\n",
      "Epoch 424/500\n",
      "2048/2048 [==============================] - 7s 4ms/step - loss: 0.6105 - val_loss: 0.6037\n",
      "Epoch 425/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6099 - val_loss: 0.6037\n",
      "Epoch 426/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6110 - val_loss: 0.6123\n",
      "Epoch 427/500\n",
      "2048/2048 [==============================] - 11s 6ms/step - loss: 0.6107 - val_loss: 0.6166\n",
      "Epoch 428/500\n",
      "  26/2048 [..............................] - ETA: 3:51 - loss: 0.6079- ETA: 2:00 - loss:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.113799). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6115 - val_loss: 0.6096\n",
      "Epoch 429/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6113 - val_loss: 0.6106\n",
      "Epoch 430/500\n",
      "2048/2048 [==============================] - 7s 4ms/step - loss: 0.6103 - val_loss: 0.6081\n",
      "Epoch 431/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6097 - val_loss: 0.6144\n",
      "Epoch 432/500\n",
      "2048/2048 [==============================] - 9s 5ms/step - loss: 0.6115 - val_loss: 0.6084\n",
      "Epoch 433/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6110 - val_loss: 0.6085\n",
      "Epoch 434/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6104 - val_loss: 0.6119\n",
      "Epoch 435/500\n",
      "2048/2048 [==============================] - 11s 5ms/step - loss: 0.6105 - val_loss: 0.6042\n",
      "Epoch 436/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6095 - val_loss: 0.6138\n",
      "Epoch 437/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6097 - val_loss: 0.6056\n",
      "Epoch 438/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6110 - val_loss: 0.6111\n",
      "Epoch 439/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6105 - val_loss: 0.6163\n",
      "Epoch 440/500\n",
      "  13/2048 [..............................] - ETA: 6:59 - loss: 0.6107"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.110058). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  79/2048 [>.............................] - ETA: 1:21 - loss: 0.6193"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.104065). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.100629). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 7s 4ms/step - loss: 0.6112 - val_loss: 0.6052\n",
      "Epoch 441/500\n",
      " 210/2048 [==>...........................] - ETA: 42s - loss: 0.6128"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.137658). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.119427). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6101 - val_loss: 0.6056\n",
      "Epoch 442/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6109 - val_loss: 0.6048\n",
      "Epoch 443/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6097 - val_loss: 0.6064\n",
      "Epoch 444/500\n",
      "2048/2048 [==============================] - 9s 5ms/step - loss: 0.6109 - val_loss: 0.6135\n",
      "Epoch 445/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6113 - val_loss: 0.6120\n",
      "Epoch 446/500\n",
      "2048/2048 [==============================] - 9s 5ms/step - loss: 0.6112 - val_loss: 0.6097\n",
      "Epoch 447/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6116 - val_loss: 0.6123\n",
      "Epoch 448/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6099 - val_loss: 0.6093\n",
      "Epoch 449/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6097 - val_loss: 0.6159\n",
      "Epoch 450/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6100 - val_loss: 0.6066\n",
      "Epoch 451/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6111 - val_loss: 0.6041\n",
      "Epoch 452/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6110 - val_loss: 0.6114\n",
      "Epoch 453/500\n",
      "2048/2048 [==============================] - 11s 5ms/step - loss: 0.6123 - val_loss: 0.6110\n",
      "Epoch 454/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6099 - val_loss: 0.6052\n",
      "Epoch 455/500\n",
      "  67/2048 [..............................] - ETA: 1:46 - loss: 0.6055"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.132689). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.106956). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6098 - val_loss: 0.6144\n",
      "Epoch 456/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6107 - val_loss: 0.6090\n",
      "Epoch 457/500\n",
      "2048/2048 [==============================] - 11s 5ms/step - loss: 0.6112 - val_loss: 0.6136\n",
      "Epoch 458/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6104 - val_loss: 0.6106\n",
      "Epoch 459/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6108 - val_loss: 0.6105\n",
      "Epoch 460/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6108 - val_loss: 0.6076\n",
      "Epoch 461/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6106 - val_loss: 0.6058\n",
      "Epoch 462/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6098 - val_loss: 0.6120\n",
      "Epoch 463/500\n",
      "  11/2048 [..............................] - ETA: 6:52 - loss: 0.6119"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.105567). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.151633). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  16/2048 [..............................] - ETA: 6:47 - loss: 0.6164"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.163988). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.143319). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  85/2048 [>.............................] - ETA: 1:18 - loss: 0.6145"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.120650). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.104656). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 7s 4ms/step - loss: 0.6109 - val_loss: 0.6036\n",
      "Epoch 464/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6112 - val_loss: 0.6081\n",
      "Epoch 465/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6112 - val_loss: 0.6084\n",
      "Epoch 466/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6110 - val_loss: 0.6106\n",
      "Epoch 467/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6101 - val_loss: 0.6037\n",
      "Epoch 468/500\n",
      "2048/2048 [==============================] - 9s 5ms/step - loss: 0.6102 - val_loss: 0.6144\n",
      "Epoch 469/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6105 - val_loss: 0.6060\n",
      "Epoch 470/500\n",
      "2048/2048 [==============================] - 12s 6ms/step - loss: 0.6110 - val_loss: 0.6078\n",
      "Epoch 471/500\n",
      "2048/2048 [==============================] - 4s 2ms/step - loss: 0.6114 - val_loss: 0.6093\n",
      "Epoch 472/500\n",
      "2048/2048 [==============================] - 9s 5ms/step - loss: 0.6103 - val_loss: 0.6052\n",
      "Epoch 473/500\n",
      "   6/2048 [..............................] - ETA: 8:12 - loss: 0.6072"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.118257). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   8/2048 [..............................] - ETA: 10:43 - loss: 0.6072"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.123430). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.128603). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  16/2048 [..............................] - ETA: 6:49 - loss: 0.6050"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.115808). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.109909). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6096 - val_loss: 0.6104\n",
      "Epoch 474/500\n",
      "2048/2048 [==============================] - 12s 6ms/step - loss: 0.6089 - val_loss: 0.6145\n",
      "Epoch 475/500\n",
      "2048/2048 [==============================] - 4s 2ms/step - loss: 0.6095 - val_loss: 0.6122\n",
      "Epoch 476/500\n",
      "  71/2048 [>.............................] - ETA: 1:36 - loss: 0.6003"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.137603). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6103 - val_loss: 0.6078\n",
      "Epoch 477/500\n",
      "   7/2048 [..............................] - ETA: 8:17 - loss: 0.6068"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.114151). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.113934). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.113717). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  10/2048 [..............................] - ETA: 7:55 - loss: 0.6038"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.111266). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  80/2048 [>.............................] - ETA: 1:26 - loss: 0.6056"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.107690). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.101778). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6101 - val_loss: 0.6118\n",
      "Epoch 478/500\n",
      "  72/2048 [>.............................] - ETA: 1:29 - loss: 0.6074"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.105918). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6109 - val_loss: 0.6043\n",
      "Epoch 479/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6095 - val_loss: 0.6133\n",
      "Epoch 480/500\n",
      "2048/2048 [==============================] - 11s 5ms/step - loss: 0.6100 - val_loss: 0.6099\n",
      "Epoch 481/500\n",
      "  18/2048 [..............................] - ETA: 51s - loss: 0.6055 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.224169). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.112876). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 5s 2ms/step - loss: 0.6101 - val_loss: 0.6107\n",
      "Epoch 482/500\n",
      "   3/2048 [..............................] - ETA: 3:48 - loss: 0.6543"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.107860). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6106 - val_loss: 0.6158\n",
      "Epoch 483/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6113 - val_loss: 0.6029\n",
      "Epoch 484/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6097 - val_loss: 0.6128\n",
      "Epoch 485/500\n",
      "   6/2048 [..............................] - ETA: 2:50 - loss: 0.6113"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.124382). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  15/2048 [..............................] - ETA: 6:05 - loss: 0.6173"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.103622). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  61/2048 [..............................] - ETA: 1:44 - loss: 0.6063"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.107479). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.107197). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.104596). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 7s 4ms/step - loss: 0.6118 - val_loss: 0.6187\n",
      "Epoch 486/500\n",
      "2048/2048 [==============================] - 7s 4ms/step - loss: 0.6117 - val_loss: 0.6127\n",
      "Epoch 487/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6099 - val_loss: 0.6131\n",
      "Epoch 488/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6103 - val_loss: 0.6063\n",
      "Epoch 489/500\n",
      "2048/2048 [==============================] - 11s 6ms/step - loss: 0.6105 - val_loss: 0.6104\n",
      "Epoch 490/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6117 - val_loss: 0.6079\n",
      "Epoch 491/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6113 - val_loss: 0.6105\n",
      "Epoch 492/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6101 - val_loss: 0.6146\n",
      "Epoch 493/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6109 - val_loss: 0.6138\n",
      "Epoch 494/500\n",
      "2048/2048 [==============================] - 9s 4ms/step - loss: 0.6098 - val_loss: 0.6092\n",
      "Epoch 495/500\n",
      "2048/2048 [==============================] - 9s 5ms/step - loss: 0.6093 - val_loss: 0.6100\n",
      "Epoch 496/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6096 - val_loss: 0.6132\n",
      "Epoch 497/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6096 - val_loss: 0.6148\n",
      "Epoch 498/500\n",
      "2048/2048 [==============================] - 10s 5ms/step - loss: 0.6113 - val_loss: 0.6106\n",
      "Epoch 499/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6096 - val_loss: 0.6148\n",
      "Epoch 500/500\n",
      "2048/2048 [==============================] - 8s 4ms/step - loss: 0.6097 - val_loss: 0.6135\n",
      "ccasj, 1890, 629\n",
      "Train on 1890 samples, validate on 629 samples\n",
      "Epoch 1/40\n",
      "1890/1890 [==============================] - 16s 9ms/step - loss: 2.7880 - val_loss: 3.4534\n",
      "Epoch 2/40\n",
      "1890/1890 [==============================] - 16s 9ms/step - loss: 2.7868 - val_loss: 3.4450\n",
      "Epoch 3/40\n",
      "1890/1890 [==============================] - 17s 9ms/step - loss: 2.7815 - val_loss: 3.4178\n",
      "Epoch 4/40\n",
      "1890/1890 [==============================] - 17s 9ms/step - loss: 2.6623 - val_loss: 3.2868\n",
      "Epoch 5/40\n",
      "1890/1890 [==============================] - 17s 9ms/step - loss: 2.4412 - val_loss: 3.4018\n",
      "Epoch 6/40\n",
      "1890/1890 [==============================] - 17s 9ms/step - loss: 2.4319 - val_loss: 3.6146\n",
      "Epoch 7/40\n",
      "1890/1890 [==============================] - 17s 9ms/step - loss: 2.3931 - val_loss: 3.7928\n",
      "Epoch 8/40\n",
      "1890/1890 [==============================] - 17s 9ms/step - loss: 2.6541 - val_loss: 3.2361\n",
      "Epoch 9/40\n",
      "1890/1890 [==============================] - 17s 9ms/step - loss: 2.4618 - val_loss: 3.3084\n",
      "Epoch 10/40\n",
      "1890/1890 [==============================] - 17s 9ms/step - loss: 2.3468 - val_loss: 3.4789\n",
      "Epoch 11/40\n",
      "1890/1890 [==============================] - 17s 9ms/step - loss: 2.2838 - val_loss: 3.5809\n",
      "Epoch 12/40\n",
      "1890/1890 [==============================] - 17s 9ms/step - loss: 2.2161 - val_loss: 3.5346\n",
      "Epoch 13/40\n",
      "1890/1890 [==============================] - 17s 9ms/step - loss: 2.2169 - val_loss: 3.6655\n",
      "Epoch 14/40\n",
      "1890/1890 [==============================] - 17s 9ms/step - loss: 2.1633 - val_loss: 3.5647\n",
      "Epoch 15/40\n",
      "1890/1890 [==============================] - 17s 9ms/step - loss: 2.1409 - val_loss: 3.7389\n",
      "Epoch 16/40\n",
      "1890/1890 [==============================] - 17s 9ms/step - loss: 2.0823 - val_loss: 3.6114\n",
      "Epoch 17/40\n",
      "1890/1890 [==============================] - 17s 9ms/step - loss: 2.0497 - val_loss: 3.8364\n",
      "Epoch 18/40\n",
      "1890/1890 [==============================] - 17s 9ms/step - loss: 2.0407 - val_loss: 3.5764\n",
      "Epoch 19/40\n",
      "1890/1890 [==============================] - 17s 9ms/step - loss: 1.9865 - val_loss: 3.6875\n",
      "Epoch 20/40\n",
      "1890/1890 [==============================] - 17s 9ms/step - loss: 1.9984 - val_loss: 3.6466\n",
      "Epoch 00020: early stopping\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"030013d7-b30d-4529-97e6-0353ff938844\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"030013d7-b30d-4529-97e6-0353ff938844\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell Execution Has Finished!!\", \"autonotify_after\": \"10\", \"autonotify_output\": false};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pretrain_data_path = 'data/pretrain/%s_pretrain.csv'\n",
    "train_data_path = 'data/train/%s.csv'\n",
    "dic_data_path = 'models/en/dic/%s.dic.pkl'\n",
    "log_pre_data_path = 'logs/en/pretrain/%s.csv'\n",
    "hist_pre_data_path = 'logs/en/pretrain/%s.pkl'\n",
    "model_pre_data_path = 'models/en/pretrain/%s.h5'\n",
    "log_data_path = 'logs/en/train/%s.csv'\n",
    "hist_data_path = 'logs/en/train/%s.pkl'\n",
    "model_data_path = 'models/en/train/%s.h5'\n",
    "\n",
    "for repo in set(project_repos.values()):\n",
    "    unlabelled_words, _ = ler_csv_texto_tokenizado(pretrain_data_path % repo, nlp.tokenizer)\n",
    "    for project in [k for k, v in project_repos.items() if v == repo]:\n",
    "        story_words, _ = ler_csv_texto_tokenizado(train_data_path % project, nlp.tokenizer)\n",
    "        num_test = int(round(len(story_words) * test_fraction))\n",
    "        num_val = int(round(len(story_words) * val_fraction))\n",
    "        num_train = len(story_words) - num_test - num_val\n",
    "        unlabelled_words.extend(story_words[:num_train])\n",
    "    dic = gerar_dicionario(unlabelled_words)\n",
    "    save_to_pickle(dic, dic_data_path % repo)\n",
    "    pretrain_tokens = converte_tokens_pretreino(unlabelled_words, dic)\n",
    "    \n",
    "    print_log_out(\"%s, %d\" % (repo, len(pretrain_tokens)))\n",
    "\n",
    "    gerador_treino = GeradorDados(pretrain_tokens, 128, 2048)\n",
    "    gerador_valida = GeradorDados(pretrain_tokens, 128, 64)\n",
    "    mod_emb = gerar_modelo_keras(len(dic))\n",
    "\n",
    "    mod_emb.compile(loss='binary_crossentropy',optimizer='adam')\n",
    "\n",
    "    log_csv = keras.callbacks.CSVLogger(log_pre_data_path % repo)\n",
    "    save_best = keras.callbacks.ModelCheckpoint(model_pre_data_path % repo, monitor='val_loss', mode='min', save_best_only=True)\n",
    "    hist_pretrain = mod_emb.fit_generator(generator=gerador_treino, epochs=500, use_multiprocessing=False, shuffle=False, max_queue_size=4096, validation_data=gerador_valida, callbacks=[save_best, log_csv])\n",
    "    save_to_pickle(hist_pretrain.history, hist_pre_data_path % repo)\n",
    "\n",
    "    \n",
    "for project in project_repos.keys():\n",
    "    story_words, story_points = ler_csv_texto_tokenizado(train_data_path % project, nlp.tokenizer)\n",
    "    dic = load_pickle(dic_data_path % project_repos[project])\n",
    "    x_train, x_val, x_test = converte_tokens_treino(story_words, dic)\n",
    "    y_train = story_points[:x_train.shape[0]].reshape((-1, 1))\n",
    "    y_val = story_points[x_train.shape[0]:x_train.shape[0]+x_val.shape[0]].reshape((-1, 1))\n",
    "    y_test = story_points[x_train.shape[0] + x_val.shape[0]:].reshape((-1, 1))\n",
    "    \n",
    "    print_log_out(\"%s, %d, %d\" % (project, x_train.shape[0], x_val.shape[0]))\n",
    "\n",
    "    mod_train = create_train_model(len(dic))\n",
    "    mod_emb.load_weights(model_pre_data_path % project_repos[project])\n",
    "    initialize_train_model(mod_train, mod_emb.get_layer('vetorizacao').get_weights())\n",
    "\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=12, min_delta=0)\n",
    "    save_best = keras.callbacks.ModelCheckpoint(model_data_path % project, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)\n",
    "    log_csv = keras.callbacks.CSVLogger(log_data_path % project)\n",
    "    hist_train = mod_train.fit(x_train, np.clip(y_train, 1, story_points_clip[project]), epochs=40, validation_data=(x_val, np.clip(y_val, 1, story_points_clip[project])), callbacks=[save_best, log_csv, early_stopping])\n",
    "    save_to_pickle(hist_train.history, hist_data_path % project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "talendesb, 522, 173\n",
      "Train on 522 samples, validate on 173 samples\n",
      "Epoch 1/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.9358 - val_loss: 0.8244\n",
      "Epoch 2/40\n",
      "522/522 [==============================] - 4s 9ms/step - loss: 0.9328 - val_loss: 0.8226\n",
      "Epoch 3/40\n",
      "522/522 [==============================] - 4s 9ms/step - loss: 0.9303 - val_loss: 0.8203\n",
      "Epoch 4/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.9274 - val_loss: 0.8181\n",
      "Epoch 5/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.9239 - val_loss: 0.8144\n",
      "Epoch 6/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.9175 - val_loss: 0.8040\n",
      "Epoch 7/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.8922 - val_loss: 0.7750\n",
      "Epoch 8/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.7977 - val_loss: 0.6402\n",
      "Epoch 9/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.6707 - val_loss: 0.6792\n",
      "Epoch 10/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.6430 - val_loss: 0.6891\n",
      "Epoch 11/40\n",
      "522/522 [==============================] - 5s 10ms/step - loss: 0.6356 - val_loss: 0.7339\n",
      "Epoch 12/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.6079 - val_loss: 0.6716\n",
      "Epoch 13/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.5968 - val_loss: 0.7198\n",
      "Epoch 14/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.5436 - val_loss: 0.6732\n",
      "Epoch 15/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.4966 - val_loss: 0.6336\n",
      "Epoch 16/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.5289 - val_loss: 0.7268\n",
      "Epoch 17/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.4707 - val_loss: 0.6888\n",
      "Epoch 18/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.4723 - val_loss: 0.7149\n",
      "Epoch 19/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.5669 - val_loss: 0.6448\n",
      "Epoch 20/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.4770 - val_loss: 0.6938\n",
      "Epoch 21/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.4342 - val_loss: 0.6655\n",
      "Epoch 22/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.4396 - val_loss: 0.6653\n",
      "Epoch 23/40\n",
      "522/522 [==============================] - 5s 10ms/step - loss: 0.3972 - val_loss: 0.6534\n",
      "Epoch 24/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.3798 - val_loss: 0.7385\n",
      "Epoch 25/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.3864 - val_loss: 0.6643\n",
      "Epoch 26/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.3624 - val_loss: 0.6544\n",
      "Epoch 27/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.3799 - val_loss: 0.6420\n",
      "Epoch 00027: early stopping\n",
      "springxd, 2116, 705\n",
      "Train on 2116 samples, validate on 705 samples\n",
      "Epoch 1/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 2.4902 - val_loss: 2.5566\n",
      "Epoch 2/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 2.1803 - val_loss: 1.9148\n",
      "Epoch 3/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.8373 - val_loss: 1.8184\n",
      "Epoch 4/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.8238 - val_loss: 1.8181\n",
      "Epoch 5/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.8130 - val_loss: 1.8198\n",
      "Epoch 6/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.7639 - val_loss: 1.7685\n",
      "Epoch 7/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.7253 - val_loss: 1.7856\n",
      "Epoch 8/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.6804 - val_loss: 1.8446\n",
      "Epoch 9/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.6327 - val_loss: 1.8065\n",
      "Epoch 10/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.5717 - val_loss: 1.7084\n",
      "Epoch 11/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.5252 - val_loss: 1.7268\n",
      "Epoch 12/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.4432 - val_loss: 1.7273\n",
      "Epoch 13/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.4014 - val_loss: 1.7146\n",
      "Epoch 14/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.3789 - val_loss: 1.6825\n",
      "Epoch 15/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.2757 - val_loss: 1.7902\n",
      "Epoch 16/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.2171 - val_loss: 1.7186\n",
      "Epoch 17/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.1861 - val_loss: 1.7482\n",
      "Epoch 18/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.1271 - val_loss: 1.7650\n",
      "Epoch 19/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.0519 - val_loss: 1.7680\n",
      "Epoch 20/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.0007 - val_loss: 1.7939\n",
      "Epoch 21/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.9678 - val_loss: 1.8185\n",
      "Epoch 22/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.9291 - val_loss: 1.8065\n",
      "Epoch 23/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.8595 - val_loss: 1.7683\n",
      "Epoch 24/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.8358 - val_loss: 1.8656\n",
      "Epoch 25/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.8197 - val_loss: 1.7857\n",
      "Epoch 26/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.7781 - val_loss: 1.9247\n",
      "Epoch 00026: early stopping\n",
      "mulestudio, 440, 146\n",
      "Train on 440 samples, validate on 146 samples\n",
      "Epoch 1/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.3762 - val_loss: 5.6508\n",
      "Epoch 2/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.3625 - val_loss: 5.6355\n",
      "Epoch 3/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.3469 - val_loss: 5.6161\n",
      "Epoch 4/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.3230 - val_loss: 5.5793\n",
      "Epoch 5/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.2598 - val_loss: 5.4590\n",
      "Epoch 6/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.0569 - val_loss: 5.0841\n",
      "Epoch 7/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 3.4871 - val_loss: 4.1617\n",
      "Epoch 8/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.7556 - val_loss: 3.2542\n",
      "Epoch 9/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5894 - val_loss: 3.2681\n",
      "Epoch 10/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.6331 - val_loss: 3.4516\n",
      "Epoch 11/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5076 - val_loss: 3.2648\n",
      "Epoch 12/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5027 - val_loss: 3.3859\n",
      "Epoch 13/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5294 - val_loss: 3.2934\n",
      "Epoch 14/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4581 - val_loss: 3.2978\n",
      "Epoch 15/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4833 - val_loss: 3.2825\n",
      "Epoch 16/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4487 - val_loss: 3.2890\n",
      "Epoch 17/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4846 - val_loss: 3.2759\n",
      "Epoch 18/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4474 - val_loss: 3.3663\n",
      "Epoch 19/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4799 - val_loss: 3.3411\n",
      "Epoch 20/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4455 - val_loss: 3.2767\n",
      "Epoch 00020: early stopping\n",
      "mule, 535, 177\n",
      "Train on 535 samples, validate on 177 samples\n",
      "Epoch 1/40\n",
      "535/535 [==============================] - 5s 9ms/step - loss: 3.7922 - val_loss: 3.6604\n",
      "Epoch 2/40\n",
      "535/535 [==============================] - 5s 9ms/step - loss: 3.7786 - val_loss: 3.6464\n",
      "Epoch 3/40\n",
      "535/535 [==============================] - 5s 9ms/step - loss: 3.7603 - val_loss: 3.6217\n",
      "Epoch 4/40\n",
      "535/535 [==============================] - 5s 9ms/step - loss: 3.7087 - val_loss: 3.5253\n",
      "Epoch 5/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "535/535 [==============================] - 5s 9ms/step - loss: 3.4989 - val_loss: 3.1794\n",
      "Epoch 6/40\n",
      "535/535 [==============================] - 4s 8ms/step - loss: 2.9023 - val_loss: 2.3628\n",
      "Epoch 7/40\n",
      "535/535 [==============================] - 4s 8ms/step - loss: 2.3445 - val_loss: 2.1199\n",
      "Epoch 8/40\n",
      "535/535 [==============================] - 4s 8ms/step - loss: 2.3980 - val_loss: 2.1222\n",
      "Epoch 9/40\n",
      "535/535 [==============================] - 4s 8ms/step - loss: 2.3553 - val_loss: 2.0789\n",
      "Epoch 10/40\n",
      "535/535 [==============================] - 4s 8ms/step - loss: 2.3461 - val_loss: 2.0979\n",
      "Epoch 11/40\n",
      "535/535 [==============================] - 4s 8ms/step - loss: 2.3357 - val_loss: 2.0820\n",
      "Epoch 12/40\n",
      "535/535 [==============================] - 5s 9ms/step - loss: 2.3281 - val_loss: 2.1027\n",
      "Epoch 13/40\n",
      "535/535 [==============================] - 4s 8ms/step - loss: 2.3318 - val_loss: 2.0818\n",
      "Epoch 14/40\n",
      "535/535 [==============================] - 4s 8ms/step - loss: 2.2998 - val_loss: 2.0945\n",
      "Epoch 15/40\n",
      "535/535 [==============================] - 5s 8ms/step - loss: 2.3249 - val_loss: 2.1171\n",
      "Epoch 16/40\n",
      "535/535 [==============================] - 4s 8ms/step - loss: 2.2922 - val_loss: 2.1042\n",
      "Epoch 17/40\n",
      "535/535 [==============================] - 5s 9ms/step - loss: 2.2884 - val_loss: 2.1290\n",
      "Epoch 18/40\n",
      "535/535 [==============================] - 5s 9ms/step - loss: 2.2678 - val_loss: 2.0889\n",
      "Epoch 19/40\n",
      "535/535 [==============================] - 5s 8ms/step - loss: 2.1783 - val_loss: 2.1027\n",
      "Epoch 20/40\n",
      "535/535 [==============================] - 5s 8ms/step - loss: 2.2139 - val_loss: 2.0921\n",
      "Epoch 21/40\n",
      "535/535 [==============================] - 5s 8ms/step - loss: 2.1688 - val_loss: 2.0938\n",
      "Epoch 00021: early stopping\n",
      "moodle, 700, 233\n",
      "Train on 700 samples, validate on 233 samples\n",
      "Epoch 1/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.8454 - val_loss: 13.9679\n",
      "Epoch 2/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.8217 - val_loss: 13.9404\n",
      "Epoch 3/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.7892 - val_loss: 13.8865\n",
      "Epoch 4/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.6638 - val_loss: 13.5951\n",
      "Epoch 5/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.0489 - val_loss: 12.3475\n",
      "Epoch 6/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 10.5947 - val_loss: 10.3191\n",
      "Epoch 7/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 9.5868 - val_loss: 9.9165\n",
      "Epoch 8/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 9.5797 - val_loss: 9.8783\n",
      "Epoch 9/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.4994 - val_loss: 9.8758\n",
      "Epoch 10/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.4986 - val_loss: 9.8767\n",
      "Epoch 11/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.3744 - val_loss: 9.8747\n",
      "Epoch 12/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.2412 - val_loss: 9.8359\n",
      "Epoch 13/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.9472 - val_loss: 9.6616\n",
      "Epoch 14/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.5565 - val_loss: 9.6143\n",
      "Epoch 15/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.0082 - val_loss: 9.2865\n",
      "Epoch 16/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 7.6659 - val_loss: 10.3777\n",
      "Epoch 17/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 7.7199 - val_loss: 9.5969\n",
      "Epoch 18/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 7.2140 - val_loss: 9.0679\n",
      "Epoch 19/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 6.4997 - val_loss: 9.2673\n",
      "Epoch 20/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 6.5880 - val_loss: 9.2010\n",
      "Epoch 21/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 5.8916 - val_loss: 9.0337\n",
      "Epoch 22/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 5.7581 - val_loss: 9.6558\n",
      "Epoch 23/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 5.5580 - val_loss: 9.7772\n",
      "Epoch 24/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 5.5064 - val_loss: 9.1338\n",
      "Epoch 25/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 5.2765 - val_loss: 9.3845\n",
      "Epoch 26/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 4.6639 - val_loss: 9.0957\n",
      "Epoch 27/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 4.2420 - val_loss: 9.0827\n",
      "Epoch 28/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 4.2514 - val_loss: 9.4383\n",
      "Epoch 29/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 3.9480 - val_loss: 9.2094\n",
      "Epoch 30/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 3.7684 - val_loss: 9.5388\n",
      "Epoch 31/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 3.7082 - val_loss: 9.6507\n",
      "Epoch 32/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 3.4228 - val_loss: 9.3654\n",
      "Epoch 33/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 3.3587 - val_loss: 9.2571\n",
      "Epoch 00033: early stopping\n",
      "jirasoftware, 212, 70\n",
      "Train on 212 samples, validate on 70 samples\n",
      "Epoch 1/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4694 - val_loss: 2.0958\n",
      "Epoch 2/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.4636 - val_loss: 2.0915\n",
      "Epoch 3/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.4578 - val_loss: 2.0870\n",
      "Epoch 4/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4512 - val_loss: 2.0823\n",
      "Epoch 5/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.4447 - val_loss: 2.0773\n",
      "Epoch 6/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.4376 - val_loss: 2.0717\n",
      "Epoch 7/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.4293 - val_loss: 2.0653\n",
      "Epoch 8/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4195 - val_loss: 2.0561\n",
      "Epoch 9/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4035 - val_loss: 2.0408\n",
      "Epoch 10/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.3762 - val_loss: 2.0115\n",
      "Epoch 11/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.3243 - val_loss: 1.9586\n",
      "Epoch 12/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.2331 - val_loss: 1.8671\n",
      "Epoch 13/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.0707 - val_loss: 1.7115\n",
      "Epoch 14/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.8119 - val_loss: 1.5180\n",
      "Epoch 15/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.5445 - val_loss: 1.4636\n",
      "Epoch 16/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.3109 - val_loss: 1.6424\n",
      "Epoch 17/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1986 - val_loss: 1.9318\n",
      "Epoch 18/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.2087 - val_loss: 2.1468\n",
      "Epoch 19/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1625 - val_loss: 2.0592\n",
      "Epoch 20/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1629 - val_loss: 1.9916\n",
      "Epoch 21/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1655 - val_loss: 1.9663\n",
      "Epoch 22/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1316 - val_loss: 2.0337\n",
      "Epoch 23/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1463 - val_loss: 2.1198\n",
      "Epoch 24/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1708 - val_loss: 2.1126\n",
      "Epoch 25/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1029 - val_loss: 1.9727\n",
      "Epoch 26/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1207 - val_loss: 1.9249\n",
      "Epoch 27/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.0921 - val_loss: 1.9628\n",
      "Epoch 00027: early stopping\n",
      "duracloud, 400, 133\n",
      "Train on 400 samples, validate on 133 samples\n",
      "Epoch 1/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 3/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 4/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 5/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 6/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 7/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 8/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 9/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 10/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 11/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 12/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 13/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 00013: early stopping\n",
      "titanium, 1351, 450\n",
      "Train on 1351 samples, validate on 450 samples\n",
      "Epoch 1/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 5.0878 - val_loss: 4.4994\n",
      "Epoch 2/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.9484 - val_loss: 3.9850\n",
      "Epoch 3/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.6310 - val_loss: 2.2960\n",
      "Epoch 4/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1304 - val_loss: 2.3350\n",
      "Epoch 5/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1201 - val_loss: 2.3766\n",
      "Epoch 6/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1284 - val_loss: 2.3434\n",
      "Epoch 7/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1113 - val_loss: 2.2957\n",
      "Epoch 8/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.0990 - val_loss: 2.3024\n",
      "Epoch 9/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1101 - val_loss: 2.3034\n",
      "Epoch 10/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.0937 - val_loss: 2.3430\n",
      "Epoch 11/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.0850 - val_loss: 2.2995\n",
      "Epoch 12/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.0345 - val_loss: 2.3142\n",
      "Epoch 13/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.9465 - val_loss: 2.3670\n",
      "Epoch 14/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.8451 - val_loss: 2.3575\n",
      "Epoch 15/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.7772 - val_loss: 2.4240\n",
      "Epoch 16/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.6016 - val_loss: 2.4606\n",
      "Epoch 17/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.4832 - val_loss: 2.5588\n",
      "Epoch 18/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.3847 - val_loss: 2.5528\n",
      "Epoch 19/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.3020 - val_loss: 2.5466\n",
      "Epoch 00019: early stopping\n",
      "aptanastudio, 499, 165\n",
      "Train on 499 samples, validate on 165 samples\n",
      "Epoch 1/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.1486 - val_loss: 7.3701\n",
      "Epoch 2/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.1354 - val_loss: 7.3494\n",
      "Epoch 3/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.1162 - val_loss: 7.3057\n",
      "Epoch 4/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.0490 - val_loss: 7.0944\n",
      "Epoch 5/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 5.7562 - val_loss: 6.2951\n",
      "Epoch 6/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 4.8960 - val_loss: 4.1451\n",
      "Epoch 7/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 3.8137 - val_loss: 2.7081\n",
      "Epoch 8/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 3.6590 - val_loss: 2.9441\n",
      "Epoch 9/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 3.5130 - val_loss: 2.8230\n",
      "Epoch 10/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.4425 - val_loss: 2.9649\n",
      "Epoch 11/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.3429 - val_loss: 2.8619\n",
      "Epoch 12/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.3055 - val_loss: 2.8555\n",
      "Epoch 13/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.2909 - val_loss: 2.7565\n",
      "Epoch 14/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.2513 - val_loss: 2.7136\n",
      "Epoch 15/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.2147 - val_loss: 2.7677\n",
      "Epoch 16/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.1892 - val_loss: 2.9487\n",
      "Epoch 17/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.2596 - val_loss: 2.8428\n",
      "Epoch 18/40\n",
      "499/499 [==============================] - 5s 9ms/step - loss: 3.1754 - val_loss: 2.7788\n",
      "Epoch 19/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.1848 - val_loss: 2.9037\n",
      "Epoch 00019: early stopping\n",
      "appceleratorstudio, 1753, 583\n",
      "Train on 1753 samples, validate on 583 samples\n",
      "Epoch 1/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 4.4094 - val_loss: 3.7265\n",
      "Epoch 2/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 3.6990 - val_loss: 1.3708\n",
      "Epoch 3/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 2.0948 - val_loss: 1.4715\n",
      "Epoch 4/40\n",
      "1753/1753 [==============================] - 17s 9ms/step - loss: 2.1079 - val_loss: 1.5432\n",
      "Epoch 5/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 2.0608 - val_loss: 1.4473\n",
      "Epoch 6/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 2.0490 - val_loss: 1.5045\n",
      "Epoch 7/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 2.0422 - val_loss: 1.6769\n",
      "Epoch 8/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0438 - val_loss: 1.5308\n",
      "Epoch 9/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0280 - val_loss: 1.4813\n",
      "Epoch 10/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0250 - val_loss: 1.4804\n",
      "Epoch 11/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0126 - val_loss: 1.5596\n",
      "Epoch 12/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0475 - val_loss: 1.3754\n",
      "Epoch 13/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0064 - val_loss: 1.4819\n",
      "Epoch 14/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.9908 - val_loss: 1.6210\n",
      "Epoch 00014: early stopping\n",
      "mesos, 1008, 336\n",
      "Train on 1008 samples, validate on 336 samples\n",
      "Epoch 1/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.8419 - val_loss: 1.5567\n",
      "Epoch 2/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.8223 - val_loss: 1.5338\n",
      "Epoch 3/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.7500 - val_loss: 1.3711\n",
      "Epoch 4/40\n",
      "1008/1008 [==============================] - 9s 8ms/step - loss: 1.3471 - val_loss: 1.1756\n",
      "Epoch 5/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.2357 - val_loss: 1.1520\n",
      "Epoch 6/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.2131 - val_loss: 1.1345\n",
      "Epoch 7/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1867 - val_loss: 1.1346\n",
      "Epoch 8/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1802 - val_loss: 1.1277\n",
      "Epoch 9/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1518 - val_loss: 1.0970\n",
      "Epoch 10/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1623 - val_loss: 1.1207\n",
      "Epoch 11/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1338 - val_loss: 1.1158\n",
      "Epoch 12/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.0959 - val_loss: 1.1305\n",
      "Epoch 13/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.0694 - val_loss: 1.1212\n",
      "Epoch 14/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.0273 - val_loss: 1.1340\n",
      "Epoch 15/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.0010 - val_loss: 1.1110\n",
      "Epoch 16/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.9825 - val_loss: 1.2305\n",
      "Epoch 17/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.9779 - val_loss: 1.2546\n",
      "Epoch 18/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.9118 - val_loss: 1.1502\n",
      "Epoch 19/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.8542 - val_loss: 1.2633\n",
      "Epoch 20/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.7946 - val_loss: 1.3070\n",
      "Epoch 21/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.7725 - val_loss: 1.2227\n",
      "Epoch 00021: early stopping\n",
      "talendesb, 522, 173\n",
      "Train on 522 samples, validate on 173 samples\n",
      "Epoch 1/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.9358 - val_loss: 0.8247\n",
      "Epoch 2/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.9330 - val_loss: 0.8223\n",
      "Epoch 3/40\n",
      "522/522 [==============================] - 4s 9ms/step - loss: 0.9302 - val_loss: 0.8203\n",
      "Epoch 4/40\n",
      "522/522 [==============================] - 4s 9ms/step - loss: 0.9276 - val_loss: 0.8179\n",
      "Epoch 5/40\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.9243 - val_loss: 0.8156\n",
      "Epoch 6/40\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.9211 - val_loss: 0.8130\n",
      "Epoch 7/40\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.9179 - val_loss: 0.8101\n",
      "Epoch 8/40\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.9143 - val_loss: 0.8075\n",
      "Epoch 9/40\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.9108 - val_loss: 0.8044\n",
      "Epoch 10/40\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.9069 - val_loss: 0.8013\n",
      "Epoch 11/40\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.9030 - val_loss: 0.7982\n",
      "Epoch 12/40\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.8990 - val_loss: 0.7948\n",
      "Epoch 13/40\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.8947 - val_loss: 0.7916\n",
      "Epoch 14/40\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.8907 - val_loss: 0.7886\n",
      "Epoch 15/40\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.8867 - val_loss: 0.7849\n",
      "Epoch 16/40\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.8817 - val_loss: 0.7809\n",
      "Epoch 17/40\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.8769 - val_loss: 0.7771\n",
      "Epoch 18/40\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.8718 - val_loss: 0.7736\n",
      "Epoch 19/40\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.8670 - val_loss: 0.7697\n",
      "Epoch 20/40\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.8621 - val_loss: 0.7655\n",
      "Epoch 21/40\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.8564 - val_loss: 0.7614\n",
      "Epoch 22/40\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.8511 - val_loss: 0.7567\n",
      "Epoch 23/40\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.8454 - val_loss: 0.7522\n",
      "Epoch 24/40\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.8400 - val_loss: 0.7479\n",
      "Epoch 25/40\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.8344 - val_loss: 0.7437\n",
      "Epoch 26/40\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.8289 - val_loss: 0.7394\n",
      "Epoch 27/40\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.8232 - val_loss: 0.7346\n",
      "Epoch 28/40\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.8176 - val_loss: 0.7294\n",
      "Epoch 29/40\n",
      "522/522 [==============================] - 4s 9ms/step - loss: 0.8106 - val_loss: 0.7248\n",
      "Epoch 30/40\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.8047 - val_loss: 0.7193\n",
      "Epoch 31/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.7973 - val_loss: 0.7142\n",
      "Epoch 32/40\n",
      "522/522 [==============================] - 4s 9ms/step - loss: 0.7906 - val_loss: 0.7088\n",
      "Epoch 33/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.7838 - val_loss: 0.7033\n",
      "Epoch 34/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.7770 - val_loss: 0.6973\n",
      "Epoch 35/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.7696 - val_loss: 0.6917\n",
      "Epoch 36/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.7622 - val_loss: 0.6861\n",
      "Epoch 37/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.7552 - val_loss: 0.6845\n",
      "Epoch 38/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.7536 - val_loss: 0.6826\n",
      "Epoch 39/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.7533 - val_loss: 0.6826\n",
      "Epoch 40/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.7533 - val_loss: 0.6826\n",
      "springxd, 2116, 705\n",
      "Train on 2116 samples, validate on 705 samples\n",
      "Epoch 1/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 2.4872 - val_loss: 2.5438\n",
      "Epoch 2/40\n",
      "2116/2116 [==============================] - 20s 9ms/step - loss: 2.1179 - val_loss: 1.8381\n",
      "Epoch 3/40\n",
      "2116/2116 [==============================] - 20s 9ms/step - loss: 1.7980 - val_loss: 1.7813\n",
      "Epoch 4/40\n",
      "2116/2116 [==============================] - 21s 10ms/step - loss: 1.7827 - val_loss: 1.7778\n",
      "Epoch 5/40\n",
      "2116/2116 [==============================] - 20s 10ms/step - loss: 1.7684 - val_loss: 1.7781\n",
      "Epoch 6/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.7618 - val_loss: 1.7832\n",
      "Epoch 7/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.7391 - val_loss: 1.7942\n",
      "Epoch 8/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.7003 - val_loss: 1.7569\n",
      "Epoch 9/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.6629 - val_loss: 1.7606\n",
      "Epoch 10/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.5928 - val_loss: 1.7635\n",
      "Epoch 11/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.5149 - val_loss: 1.7911\n",
      "Epoch 12/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.4524 - val_loss: 1.7509\n",
      "Epoch 13/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.3920 - val_loss: 1.7335\n",
      "Epoch 14/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.3851 - val_loss: 1.7770\n",
      "Epoch 15/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.2698 - val_loss: 1.7685\n",
      "Epoch 16/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.2249 - val_loss: 1.8488\n",
      "Epoch 17/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.2123 - val_loss: 1.7720\n",
      "Epoch 18/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.1109 - val_loss: 1.7776\n",
      "Epoch 19/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.0411 - val_loss: 1.7492\n",
      "Epoch 20/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.0291 - val_loss: 1.8092\n",
      "Epoch 21/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 0.9993 - val_loss: 1.8138\n",
      "Epoch 22/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 0.9112 - val_loss: 1.7610\n",
      "Epoch 23/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 0.9078 - val_loss: 1.8126\n",
      "Epoch 24/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 0.8661 - val_loss: 1.7985\n",
      "Epoch 25/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 0.8355 - val_loss: 1.8392\n",
      "Epoch 00025: early stopping\n",
      "mulestudio, 440, 146\n",
      "Train on 440 samples, validate on 146 samples\n",
      "Epoch 1/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.3758 - val_loss: 5.6506\n",
      "Epoch 2/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.3624 - val_loss: 5.6354\n",
      "Epoch 3/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.3467 - val_loss: 5.6153\n",
      "Epoch 4/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.3200 - val_loss: 5.5705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.2475 - val_loss: 5.4416\n",
      "Epoch 6/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.0467 - val_loss: 5.0928\n",
      "Epoch 7/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 3.5643 - val_loss: 4.3324\n",
      "Epoch 8/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.8612 - val_loss: 3.5164\n",
      "Epoch 9/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5418 - val_loss: 3.2849\n",
      "Epoch 10/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4794 - val_loss: 3.3395\n",
      "Epoch 11/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4994 - val_loss: 3.3314\n",
      "Epoch 12/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4824 - val_loss: 3.3289\n",
      "Epoch 13/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4965 - val_loss: 3.2944\n",
      "Epoch 14/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4564 - val_loss: 3.2933\n",
      "Epoch 15/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4724 - val_loss: 3.3314\n",
      "Epoch 16/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4694 - val_loss: 3.2894\n",
      "Epoch 17/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4195 - val_loss: 3.3079\n",
      "Epoch 18/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4229 - val_loss: 3.3029\n",
      "Epoch 19/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.3832 - val_loss: 3.3339\n",
      "Epoch 20/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.3961 - val_loss: 3.2414\n",
      "Epoch 21/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4177 - val_loss: 3.2417\n",
      "Epoch 22/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.3601 - val_loss: 3.2261\n",
      "Epoch 23/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.3177 - val_loss: 3.2046\n",
      "Epoch 24/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.2712 - val_loss: 3.2697\n",
      "Epoch 25/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.2827 - val_loss: 3.2933\n",
      "Epoch 26/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.2264 - val_loss: 3.2298\n",
      "Epoch 27/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.1806 - val_loss: 3.2463\n",
      "Epoch 28/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.1376 - val_loss: 3.2437\n",
      "Epoch 29/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.0081 - val_loss: 3.3160\n",
      "Epoch 30/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.9888 - val_loss: 3.3143\n",
      "Epoch 31/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.8642 - val_loss: 3.3942\n",
      "Epoch 32/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.8637 - val_loss: 3.3853\n",
      "Epoch 33/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.6718 - val_loss: 3.3394\n",
      "Epoch 34/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.5528 - val_loss: 3.6010\n",
      "Epoch 35/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.5879 - val_loss: 3.5108\n",
      "Epoch 00035: early stopping\n",
      "mule, 535, 177\n",
      "Train on 535 samples, validate on 177 samples\n",
      "Epoch 1/40\n",
      "535/535 [==============================] - 5s 9ms/step - loss: 3.7928 - val_loss: 3.6614\n",
      "Epoch 2/40\n",
      "535/535 [==============================] - 4s 8ms/step - loss: 3.7808 - val_loss: 3.6494\n",
      "Epoch 3/40\n",
      "535/535 [==============================] - 4s 8ms/step - loss: 3.7671 - val_loss: 3.6355\n",
      "Epoch 4/40\n",
      "535/535 [==============================] - 5s 9ms/step - loss: 3.7487 - val_loss: 3.6114\n",
      "Epoch 5/40\n",
      "535/535 [==============================] - 5s 8ms/step - loss: 3.6934 - val_loss: 3.5086\n",
      "Epoch 6/40\n",
      "535/535 [==============================] - 4s 8ms/step - loss: 3.4591 - val_loss: 3.0651\n",
      "Epoch 7/40\n",
      "535/535 [==============================] - 4s 8ms/step - loss: 2.7705 - val_loss: 2.2454\n",
      "Epoch 8/40\n",
      "535/535 [==============================] - 4s 8ms/step - loss: 2.3677 - val_loss: 2.0602\n",
      "Epoch 9/40\n",
      "535/535 [==============================] - 4s 8ms/step - loss: 2.3783 - val_loss: 2.1569\n",
      "Epoch 10/40\n",
      "535/535 [==============================] - 4s 8ms/step - loss: 2.3372 - val_loss: 2.0981\n",
      "Epoch 11/40\n",
      "535/535 [==============================] - 4s 8ms/step - loss: 2.3520 - val_loss: 2.0864\n",
      "Epoch 12/40\n",
      "535/535 [==============================] - 5s 9ms/step - loss: 2.3349 - val_loss: 2.0954\n",
      "Epoch 13/40\n",
      "535/535 [==============================] - 5s 9ms/step - loss: 2.3161 - val_loss: 2.1305\n",
      "Epoch 14/40\n",
      "535/535 [==============================] - 4s 8ms/step - loss: 2.3720 - val_loss: 2.0799\n",
      "Epoch 15/40\n",
      "535/535 [==============================] - 4s 8ms/step - loss: 2.3246 - val_loss: 2.1345\n",
      "Epoch 16/40\n",
      "535/535 [==============================] - 4s 8ms/step - loss: 2.3351 - val_loss: 2.1369\n",
      "Epoch 17/40\n",
      "535/535 [==============================] - 4s 8ms/step - loss: 2.3102 - val_loss: 2.1107\n",
      "Epoch 18/40\n",
      "535/535 [==============================] - 4s 8ms/step - loss: 2.2797 - val_loss: 2.0938\n",
      "Epoch 19/40\n",
      "535/535 [==============================] - 4s 8ms/step - loss: 2.2685 - val_loss: 2.1344\n",
      "Epoch 20/40\n",
      "535/535 [==============================] - 4s 8ms/step - loss: 2.2699 - val_loss: 2.1034\n",
      "Epoch 00020: early stopping\n",
      "moodle, 700, 233\n",
      "Train on 700 samples, validate on 233 samples\n",
      "Epoch 1/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.8450 - val_loss: 13.9665\n",
      "Epoch 2/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.8185 - val_loss: 13.9323\n",
      "Epoch 3/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.7602 - val_loss: 13.7983\n",
      "Epoch 4/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.4118 - val_loss: 12.9660\n",
      "Epoch 5/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 11.0575 - val_loss: 10.5772\n",
      "Epoch 6/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 9.7237 - val_loss: 9.9152\n",
      "Epoch 7/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.5371 - val_loss: 9.8796\n",
      "Epoch 8/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.5517 - val_loss: 9.9544\n",
      "Epoch 9/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.4237 - val_loss: 10.0272\n",
      "Epoch 10/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.3672 - val_loss: 10.8816\n",
      "Epoch 11/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.5214 - val_loss: 10.0686\n",
      "Epoch 12/40\n",
      "700/700 [==============================] - 7s 9ms/step - loss: 9.3633 - val_loss: 9.9772\n",
      "Epoch 13/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.2107 - val_loss: 9.8600\n",
      "Epoch 14/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.0461 - val_loss: 9.9746\n",
      "Epoch 15/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.8447 - val_loss: 9.8885\n",
      "Epoch 16/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.4530 - val_loss: 9.5947\n",
      "Epoch 17/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.2442 - val_loss: 9.2163\n",
      "Epoch 18/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.1389 - val_loss: 9.5809\n",
      "Epoch 19/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 7.5606 - val_loss: 9.1283\n",
      "Epoch 20/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 7.2417 - val_loss: 9.1279\n",
      "Epoch 21/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 7.1214 - val_loss: 8.8786\n",
      "Epoch 22/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 6.6511 - val_loss: 8.7956\n",
      "Epoch 23/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 6.4181 - val_loss: 9.3289\n",
      "Epoch 24/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 6.4395 - val_loss: 8.7817\n",
      "Epoch 25/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 6.0740 - val_loss: 8.8109\n",
      "Epoch 26/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 5.8154 - val_loss: 8.7208\n",
      "Epoch 27/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 5.5639 - val_loss: 8.6349\n",
      "Epoch 28/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 4.9998 - val_loss: 8.9484\n",
      "Epoch 29/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 6s 9ms/step - loss: 4.8394 - val_loss: 9.1607\n",
      "Epoch 30/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 4.5773 - val_loss: 9.4262\n",
      "Epoch 31/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 4.2367 - val_loss: 9.3103\n",
      "Epoch 32/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 3.8944 - val_loss: 9.1511\n",
      "Epoch 33/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 3.7934 - val_loss: 9.2842\n",
      "Epoch 34/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 3.5618 - val_loss: 9.1211\n",
      "Epoch 35/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 3.4839 - val_loss: 9.3600\n",
      "Epoch 36/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 3.3533 - val_loss: 9.4135\n",
      "Epoch 37/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 3.2070 - val_loss: 9.2647\n",
      "Epoch 38/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 3.1231 - val_loss: 9.4200\n",
      "Epoch 39/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 3.0824 - val_loss: 9.0772\n",
      "Epoch 00039: early stopping\n",
      "jirasoftware, 212, 70\n",
      "Train on 212 samples, validate on 70 samples\n",
      "Epoch 1/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.4695 - val_loss: 2.0959\n",
      "Epoch 2/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.4638 - val_loss: 2.0916\n",
      "Epoch 3/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.4579 - val_loss: 2.0873\n",
      "Epoch 4/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4518 - val_loss: 2.0827\n",
      "Epoch 5/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.4454 - val_loss: 2.0779\n",
      "Epoch 6/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4386 - val_loss: 2.0726\n",
      "Epoch 7/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4306 - val_loss: 2.0659\n",
      "Epoch 8/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4201 - val_loss: 2.0560\n",
      "Epoch 9/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4033 - val_loss: 2.0398\n",
      "Epoch 10/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.3760 - val_loss: 2.0130\n",
      "Epoch 11/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.3309 - val_loss: 1.9703\n",
      "Epoch 12/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.2597 - val_loss: 1.9016\n",
      "Epoch 13/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.1420 - val_loss: 1.7928\n",
      "Epoch 14/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.9567 - val_loss: 1.6242\n",
      "Epoch 15/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.7085 - val_loss: 1.5056\n",
      "Epoch 16/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.5064 - val_loss: 1.4572\n",
      "Epoch 17/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.3036 - val_loss: 1.6234\n",
      "Epoch 18/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.2563 - val_loss: 1.7996\n",
      "Epoch 19/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1980 - val_loss: 1.9729\n",
      "Epoch 20/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.2089 - val_loss: 2.0675\n",
      "Epoch 21/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1948 - val_loss: 2.0879\n",
      "Epoch 22/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1355 - val_loss: 2.0368\n",
      "Epoch 23/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1403 - val_loss: 1.9182\n",
      "Epoch 24/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1673 - val_loss: 1.8961\n",
      "Epoch 25/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1597 - val_loss: 1.7596\n",
      "Epoch 26/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.0105 - val_loss: 1.7614\n",
      "Epoch 27/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 1.9493 - val_loss: 1.8016\n",
      "Epoch 28/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 1.9542 - val_loss: 1.9517\n",
      "Epoch 00028: early stopping\n",
      "duracloud, 400, 133\n",
      "Train on 400 samples, validate on 133 samples\n",
      "Epoch 1/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9276 - val_loss: 0.6992\n",
      "Epoch 2/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 3/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 4/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 5/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 6/40\n",
      "400/400 [==============================] - 3s 9ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 7/40\n",
      "400/400 [==============================] - 3s 9ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 8/40\n",
      "400/400 [==============================] - 3s 9ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 9/40\n",
      "400/400 [==============================] - 3s 9ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 10/40\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 11/40\n",
      "400/400 [==============================] - 3s 9ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 12/40\n",
      "400/400 [==============================] - 3s 9ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 13/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 00013: early stopping\n",
      "titanium, 1351, 450\n",
      "Train on 1351 samples, validate on 450 samples\n",
      "Epoch 1/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 5.0885 - val_loss: 4.5018\n",
      "Epoch 2/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 4.9797 - val_loss: 4.1308\n",
      "Epoch 3/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.7270 - val_loss: 2.6007\n",
      "Epoch 4/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1459 - val_loss: 2.3588\n",
      "Epoch 5/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1442 - val_loss: 2.4789\n",
      "Epoch 6/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1424 - val_loss: 2.3449\n",
      "Epoch 7/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1149 - val_loss: 2.3579\n",
      "Epoch 8/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1276 - val_loss: 2.3101\n",
      "Epoch 9/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1114 - val_loss: 2.3770\n",
      "Epoch 10/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1210 - val_loss: 2.3337\n",
      "Epoch 11/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.0743 - val_loss: 2.4094\n",
      "Epoch 12/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.0841 - val_loss: 2.3250\n",
      "Epoch 13/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.0906 - val_loss: 2.3513\n",
      "Epoch 14/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.0245 - val_loss: 2.3215\n",
      "Epoch 15/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.9491 - val_loss: 2.4116\n",
      "Epoch 16/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.8365 - val_loss: 2.3702\n",
      "Epoch 17/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.7554 - val_loss: 2.3682\n",
      "Epoch 18/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.5689 - val_loss: 2.5867\n",
      "Epoch 19/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.4348 - val_loss: 2.5695\n",
      "Epoch 20/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.3776 - val_loss: 2.5820\n",
      "Epoch 00020: early stopping\n",
      "aptanastudio, 499, 165\n",
      "Train on 499 samples, validate on 165 samples\n",
      "Epoch 1/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 6.1529 - val_loss: 7.3797\n",
      "Epoch 2/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.1428 - val_loss: 7.3618\n",
      "Epoch 3/40\n",
      "499/499 [==============================] - 5s 9ms/step - loss: 6.1293 - val_loss: 7.3415\n",
      "Epoch 4/40\n",
      "499/499 [==============================] - 5s 9ms/step - loss: 6.1125 - val_loss: 7.3047\n",
      "Epoch 5/40\n",
      "499/499 [==============================] - 5s 9ms/step - loss: 6.0646 - val_loss: 7.1833\n",
      "Epoch 6/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499/499 [==============================] - 4s 8ms/step - loss: 5.9083 - val_loss: 6.8003\n",
      "Epoch 7/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 5.4795 - val_loss: 5.7845\n",
      "Epoch 8/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 4.6461 - val_loss: 3.8608\n",
      "Epoch 9/40\n",
      "499/499 [==============================] - 5s 10ms/step - loss: 3.7695 - val_loss: 2.8122\n",
      "Epoch 10/40\n",
      "499/499 [==============================] - 5s 10ms/step - loss: 3.3170 - val_loss: 3.0218\n",
      "Epoch 11/40\n",
      "499/499 [==============================] - 5s 10ms/step - loss: 3.3193 - val_loss: 2.7924\n",
      "Epoch 12/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 3.2697 - val_loss: 2.9332\n",
      "Epoch 13/40\n",
      "499/499 [==============================] - 5s 9ms/step - loss: 3.2197 - val_loss: 3.1479\n",
      "Epoch 14/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.2621 - val_loss: 3.0105\n",
      "Epoch 15/40\n",
      "499/499 [==============================] - 5s 9ms/step - loss: 3.1490 - val_loss: 3.0370\n",
      "Epoch 16/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.1831 - val_loss: 3.1142\n",
      "Epoch 17/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.0010 - val_loss: 3.2620\n",
      "Epoch 18/40\n",
      "499/499 [==============================] - 5s 9ms/step - loss: 2.9671 - val_loss: 3.2221\n",
      "Epoch 19/40\n",
      "499/499 [==============================] - 5s 10ms/step - loss: 2.8843 - val_loss: 3.1522\n",
      "Epoch 20/40\n",
      "499/499 [==============================] - 5s 9ms/step - loss: 2.7278 - val_loss: 3.4344\n",
      "Epoch 21/40\n",
      "499/499 [==============================] - 5s 9ms/step - loss: 2.6485 - val_loss: 3.4103\n",
      "Epoch 22/40\n",
      "499/499 [==============================] - 5s 10ms/step - loss: 2.6004 - val_loss: 3.4088\n",
      "Epoch 23/40\n",
      "499/499 [==============================] - 5s 10ms/step - loss: 2.5118 - val_loss: 3.4730\n",
      "Epoch 00023: early stopping\n",
      "appceleratorstudio, 1753, 583\n",
      "Train on 1753 samples, validate on 583 samples\n",
      "Epoch 1/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 4.4072 - val_loss: 3.7265\n",
      "Epoch 2/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 3.9948 - val_loss: 1.9245\n",
      "Epoch 3/40\n",
      "1753/1753 [==============================] - 14s 8ms/step - loss: 2.1801 - val_loss: 1.3492\n",
      "Epoch 4/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0435 - val_loss: 1.3648\n",
      "Epoch 5/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0513 - val_loss: 1.3628\n",
      "Epoch 6/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0367 - val_loss: 1.4736\n",
      "Epoch 7/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0440 - val_loss: 1.4193\n",
      "Epoch 8/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 2.0237 - val_loss: 1.7954\n",
      "Epoch 9/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0318 - val_loss: 1.5626\n",
      "Epoch 10/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.9979 - val_loss: 1.5453\n",
      "Epoch 11/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0002 - val_loss: 1.4801\n",
      "Epoch 12/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.9746 - val_loss: 1.7412\n",
      "Epoch 13/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.9588 - val_loss: 1.7307\n",
      "Epoch 14/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.9547 - val_loss: 1.6260\n",
      "Epoch 15/40\n",
      "1753/1753 [==============================] - 17s 10ms/step - loss: 1.9259 - val_loss: 1.6341\n",
      "Epoch 00015: early stopping\n",
      "mesos, 1008, 336\n",
      "Train on 1008 samples, validate on 336 samples\n",
      "Epoch 1/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.8414 - val_loss: 1.5558\n",
      "Epoch 2/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.8197 - val_loss: 1.5320\n",
      "Epoch 3/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.7380 - val_loss: 1.3535\n",
      "Epoch 4/40\n",
      "1008/1008 [==============================] - 9s 8ms/step - loss: 1.3520 - val_loss: 1.1501\n",
      "Epoch 5/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.2317 - val_loss: 1.1492\n",
      "Epoch 6/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.2123 - val_loss: 1.1318\n",
      "Epoch 7/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1779 - val_loss: 1.1321\n",
      "Epoch 8/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1678 - val_loss: 1.1246\n",
      "Epoch 9/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1325 - val_loss: 1.1483\n",
      "Epoch 10/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1107 - val_loss: 1.2138\n",
      "Epoch 11/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.0821 - val_loss: 1.1625\n",
      "Epoch 12/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.0402 - val_loss: 1.1306\n",
      "Epoch 13/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.0071 - val_loss: 1.2256\n",
      "Epoch 14/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.9410 - val_loss: 1.2267\n",
      "Epoch 15/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.9145 - val_loss: 1.3373\n",
      "Epoch 16/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.8645 - val_loss: 1.2009\n",
      "Epoch 17/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.8089 - val_loss: 1.2278\n",
      "Epoch 18/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.7432 - val_loss: 1.2444\n",
      "Epoch 19/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.6808 - val_loss: 1.3183\n",
      "Epoch 20/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.6427 - val_loss: 1.2418\n",
      "Epoch 00020: early stopping\n",
      "talendesb, 522, 173\n",
      "Train on 522 samples, validate on 173 samples\n",
      "Epoch 1/40\n",
      "522/522 [==============================] - 4s 9ms/step - loss: 0.9355 - val_loss: 0.8248\n",
      "Epoch 2/40\n",
      "522/522 [==============================] - 4s 9ms/step - loss: 0.9332 - val_loss: 0.8227\n",
      "Epoch 3/40\n",
      "522/522 [==============================] - 4s 9ms/step - loss: 0.9304 - val_loss: 0.8206\n",
      "Epoch 4/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.9275 - val_loss: 0.8182\n",
      "Epoch 5/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.9237 - val_loss: 0.8138\n",
      "Epoch 6/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.9139 - val_loss: 0.7991\n",
      "Epoch 7/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.8696 - val_loss: 0.7445\n",
      "Epoch 8/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.7423 - val_loss: 0.7142\n",
      "Epoch 9/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.6762 - val_loss: 0.6969\n",
      "Epoch 10/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.6273 - val_loss: 0.6519\n",
      "Epoch 11/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.6115 - val_loss: 0.7370\n",
      "Epoch 12/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.6355 - val_loss: 0.6703\n",
      "Epoch 13/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.5716 - val_loss: 0.7485\n",
      "Epoch 14/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.6807 - val_loss: 0.6703\n",
      "Epoch 15/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.6212 - val_loss: 0.6552\n",
      "Epoch 16/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.6657 - val_loss: 0.8028\n",
      "Epoch 17/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.7324 - val_loss: 0.6903\n",
      "Epoch 18/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.7140 - val_loss: 0.6859\n",
      "Epoch 19/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.6745 - val_loss: 0.6883\n",
      "Epoch 20/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.6466 - val_loss: 0.7058\n",
      "Epoch 21/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.6022 - val_loss: 0.6942\n",
      "Epoch 22/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.5479 - val_loss: 0.6779\n",
      "Epoch 00022: early stopping\n",
      "springxd, 2116, 705\n",
      "Train on 2116 samples, validate on 705 samples\n",
      "Epoch 1/40\n",
      "2116/2116 [==============================] - 17s 8ms/step - loss: 2.4912 - val_loss: 2.5662\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2116/2116 [==============================] - 18s 8ms/step - loss: 2.4557 - val_loss: 2.5308\n",
      "Epoch 3/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 2.4207 - val_loss: 2.4960\n",
      "Epoch 4/40\n",
      "2116/2116 [==============================] - 17s 8ms/step - loss: 2.3854 - val_loss: 2.4611\n",
      "Epoch 5/40\n",
      "2116/2116 [==============================] - 17s 8ms/step - loss: 2.3504 - val_loss: 2.4265\n",
      "Epoch 6/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 2.3152 - val_loss: 2.3916\n",
      "Epoch 7/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 2.2807 - val_loss: 2.3569\n",
      "Epoch 8/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 2.2458 - val_loss: 2.3224\n",
      "Epoch 9/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 2.2116 - val_loss: 2.2884\n",
      "Epoch 10/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 2.1771 - val_loss: 2.2541\n",
      "Epoch 11/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 2.1425 - val_loss: 2.2196\n",
      "Epoch 12/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 2.1072 - val_loss: 2.1842\n",
      "Epoch 13/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 2.0716 - val_loss: 2.1492\n",
      "Epoch 14/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 2.0363 - val_loss: 2.1138\n",
      "Epoch 15/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 2.0009 - val_loss: 2.0789\n",
      "Epoch 16/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.9691 - val_loss: 2.0567\n",
      "Epoch 17/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.9604 - val_loss: 2.0508\n",
      "Epoch 18/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.9566 - val_loss: 2.0447\n",
      "Epoch 19/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.9524 - val_loss: 2.0383\n",
      "Epoch 20/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.9483 - val_loss: 2.0317\n",
      "Epoch 21/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.9440 - val_loss: 2.0252\n",
      "Epoch 22/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.9397 - val_loss: 2.0187\n",
      "Epoch 23/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.9352 - val_loss: 2.0115\n",
      "Epoch 24/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.9303 - val_loss: 2.0037\n",
      "Epoch 25/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.9255 - val_loss: 1.9961\n",
      "Epoch 26/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.9206 - val_loss: 1.9880\n",
      "Epoch 27/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.9156 - val_loss: 1.9808\n",
      "Epoch 28/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.9103 - val_loss: 1.9720\n",
      "Epoch 29/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.9047 - val_loss: 1.9637\n",
      "Epoch 30/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.8992 - val_loss: 1.9551\n",
      "Epoch 31/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.8936 - val_loss: 1.9461\n",
      "Epoch 32/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.8876 - val_loss: 1.9373\n",
      "Epoch 33/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.8817 - val_loss: 1.9274\n",
      "Epoch 34/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.8758 - val_loss: 1.9190\n",
      "Epoch 35/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.8700 - val_loss: 1.9094\n",
      "Epoch 36/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.8636 - val_loss: 1.8996\n",
      "Epoch 37/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.8575 - val_loss: 1.8895\n",
      "Epoch 38/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.8508 - val_loss: 1.8801\n",
      "Epoch 39/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.8445 - val_loss: 1.8697\n",
      "Epoch 40/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.8379 - val_loss: 1.8600\n",
      "mulestudio, 440, 146\n",
      "Train on 440 samples, validate on 146 samples\n",
      "Epoch 1/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.3760 - val_loss: 5.6508\n",
      "Epoch 2/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.3625 - val_loss: 5.6358\n",
      "Epoch 3/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.3472 - val_loss: 5.6173\n",
      "Epoch 4/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.3244 - val_loss: 5.5799\n",
      "Epoch 5/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.2603 - val_loss: 5.4607\n",
      "Epoch 6/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.0600 - val_loss: 5.0947\n",
      "Epoch 7/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 3.5245 - val_loss: 4.2180\n",
      "Epoch 8/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.7812 - val_loss: 3.3124\n",
      "Epoch 9/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5494 - val_loss: 3.2903\n",
      "Epoch 10/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5503 - val_loss: 3.3493\n",
      "Epoch 11/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4966 - val_loss: 3.3223\n",
      "Epoch 12/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5088 - val_loss: 3.3464\n",
      "Epoch 13/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5066 - val_loss: 3.2776\n",
      "Epoch 14/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5245 - val_loss: 3.4298\n",
      "Epoch 15/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4875 - val_loss: 3.2858\n",
      "Epoch 16/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4827 - val_loss: 3.3096\n",
      "Epoch 17/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4548 - val_loss: 3.3393\n",
      "Epoch 18/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4734 - val_loss: 3.3099\n",
      "Epoch 19/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4703 - val_loss: 3.3158\n",
      "Epoch 20/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4318 - val_loss: 3.3245\n",
      "Epoch 21/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4421 - val_loss: 3.3633\n",
      "Epoch 22/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4664 - val_loss: 3.2859\n",
      "Epoch 23/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4275 - val_loss: 3.3281\n",
      "Epoch 24/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4257 - val_loss: 3.2719\n",
      "Epoch 25/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4116 - val_loss: 3.3703\n",
      "Epoch 26/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.3663 - val_loss: 3.2352\n",
      "Epoch 27/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.3842 - val_loss: 3.2613\n",
      "Epoch 28/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.3193 - val_loss: 3.2653\n",
      "Epoch 29/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.2157 - val_loss: 3.2360\n",
      "Epoch 30/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.2216 - val_loss: 3.2244\n",
      "Epoch 31/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.0709 - val_loss: 3.3881\n",
      "Epoch 32/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.9275 - val_loss: 3.3562\n",
      "Epoch 33/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.7422 - val_loss: 3.3210\n",
      "Epoch 34/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.6818 - val_loss: 3.4088\n",
      "Epoch 35/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.5197 - val_loss: 3.4183\n",
      "Epoch 36/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.4827 - val_loss: 3.3933\n",
      "Epoch 37/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.4053 - val_loss: 3.6843\n",
      "Epoch 38/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.3700 - val_loss: 3.6398\n",
      "Epoch 39/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.3000 - val_loss: 3.5998\n",
      "Epoch 40/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.2481 - val_loss: 3.6004\n",
      "moodle, 700, 233\n",
      "Train on 700 samples, validate on 233 samples\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 6s 8ms/step - loss: 12.8446 - val_loss: 13.9662\n",
      "Epoch 2/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.8175 - val_loss: 13.9287\n",
      "Epoch 3/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.7390 - val_loss: 13.7359\n",
      "Epoch 4/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.2620 - val_loss: 12.6889\n",
      "Epoch 5/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 10.8254 - val_loss: 10.3652\n",
      "Epoch 6/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 9.5682 - val_loss: 9.9064\n",
      "Epoch 7/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.5344 - val_loss: 9.8872\n",
      "Epoch 8/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.4781 - val_loss: 9.8958\n",
      "Epoch 9/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.4878 - val_loss: 9.8889\n",
      "Epoch 10/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.4672 - val_loss: 9.8789\n",
      "Epoch 11/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.4803 - val_loss: 9.8883\n",
      "Epoch 12/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.3817 - val_loss: 9.8690\n",
      "Epoch 13/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.2922 - val_loss: 9.6793\n",
      "Epoch 14/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.0410 - val_loss: 9.7710\n",
      "Epoch 15/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.8324 - val_loss: 9.3852\n",
      "Epoch 16/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.2748 - val_loss: 8.9168\n",
      "Epoch 17/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 7.7957 - val_loss: 9.2843\n",
      "Epoch 18/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 7.3387 - val_loss: 9.1603\n",
      "Epoch 19/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 7.1213 - val_loss: 8.8436\n",
      "Epoch 20/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 6.5325 - val_loss: 9.1137\n",
      "Epoch 21/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 7.7950 - val_loss: 9.6513\n",
      "Epoch 22/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 7.3611 - val_loss: 9.0333\n",
      "Epoch 23/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 6.5145 - val_loss: 9.0249\n",
      "Epoch 24/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 6.2031 - val_loss: 9.0575\n",
      "Epoch 25/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 5.6369 - val_loss: 9.1362\n",
      "Epoch 26/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 5.4287 - val_loss: 9.4324\n",
      "Epoch 27/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 5.2883 - val_loss: 9.3773\n",
      "Epoch 28/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 5.3310 - val_loss: 9.1728\n",
      "Epoch 29/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 4.8288 - val_loss: 9.1898\n",
      "Epoch 30/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 4.5647 - val_loss: 9.2225\n",
      "Epoch 31/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 4.2221 - val_loss: 9.1645\n",
      "Epoch 00031: early stopping\n",
      "jirasoftware, 212, 70\n",
      "Train on 212 samples, validate on 70 samples\n",
      "Epoch 1/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.4693 - val_loss: 2.0958\n",
      "Epoch 2/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.4636 - val_loss: 2.0914\n",
      "Epoch 3/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.4576 - val_loss: 2.0870\n",
      "Epoch 4/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4513 - val_loss: 2.0823\n",
      "Epoch 5/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4447 - val_loss: 2.0772\n",
      "Epoch 6/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4373 - val_loss: 2.0707\n",
      "Epoch 7/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4269 - val_loss: 2.0609\n",
      "Epoch 8/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4094 - val_loss: 2.0428\n",
      "Epoch 9/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.3761 - val_loss: 2.0076\n",
      "Epoch 10/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.3160 - val_loss: 1.9462\n",
      "Epoch 11/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.2123 - val_loss: 1.8407\n",
      "Epoch 12/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.0271 - val_loss: 1.6638\n",
      "Epoch 13/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.7547 - val_loss: 1.5072\n",
      "Epoch 14/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.4813 - val_loss: 1.4492\n",
      "Epoch 15/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.2607 - val_loss: 1.6838\n",
      "Epoch 16/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1904 - val_loss: 1.9530\n",
      "Epoch 17/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1899 - val_loss: 2.1169\n",
      "Epoch 18/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1940 - val_loss: 2.0840\n",
      "Epoch 19/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.2009 - val_loss: 2.0471\n",
      "Epoch 20/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1199 - val_loss: 2.0681\n",
      "Epoch 21/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1980 - val_loss: 2.0934\n",
      "Epoch 22/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1140 - val_loss: 2.0493\n",
      "Epoch 23/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1294 - val_loss: 2.0231\n",
      "Epoch 24/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1179 - val_loss: 2.0296\n",
      "Epoch 25/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1048 - val_loss: 1.9764\n",
      "Epoch 26/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.0176 - val_loss: 1.8990\n",
      "Epoch 00026: early stopping\n",
      "duracloud, 400, 133\n",
      "Train on 400 samples, validate on 133 samples\n",
      "Epoch 1/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9276 - val_loss: 0.6992\n",
      "Epoch 2/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 3/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 4/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 5/40\n",
      "400/400 [==============================] - 3s 9ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 6/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 7/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 8/40\n",
      "400/400 [==============================] - 3s 9ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 9/40\n",
      "400/400 [==============================] - 3s 9ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 10/40\n",
      "400/400 [==============================] - 3s 9ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 11/40\n",
      "400/400 [==============================] - 3s 9ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 12/40\n",
      "400/400 [==============================] - 3s 9ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 13/40\n",
      "400/400 [==============================] - 3s 9ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 14/40\n",
      "400/400 [==============================] - 3s 9ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 00014: early stopping\n",
      "titanium, 1351, 450\n",
      "Train on 1351 samples, validate on 450 samples\n",
      "Epoch 1/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 5.0866 - val_loss: 4.4972\n",
      "Epoch 2/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.9675 - val_loss: 4.1043\n",
      "Epoch 3/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.7799 - val_loss: 2.4858\n",
      "Epoch 4/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1315 - val_loss: 2.2837\n",
      "Epoch 5/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.0864 - val_loss: 2.3344\n",
      "Epoch 6/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1452 - val_loss: 2.3057\n",
      "Epoch 7/40\n",
      "1351/1351 [==============================] - 11s 9ms/step - loss: 3.1306 - val_loss: 2.3240\n",
      "Epoch 8/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.1142 - val_loss: 2.3108\n",
      "Epoch 9/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1289 - val_loss: 2.3075\n",
      "Epoch 10/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1041 - val_loss: 2.3369\n",
      "Epoch 11/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1383 - val_loss: 2.3833\n",
      "Epoch 12/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1092 - val_loss: 2.3367\n",
      "Epoch 13/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1133 - val_loss: 2.3586\n",
      "Epoch 14/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.0909 - val_loss: 2.3338\n",
      "Epoch 15/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.0876 - val_loss: 2.3374\n",
      "Epoch 16/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.0617 - val_loss: 2.4034\n",
      "Epoch 00016: early stopping\n",
      "aptanastudio, 499, 165\n",
      "Train on 499 samples, validate on 165 samples\n",
      "Epoch 1/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.1493 - val_loss: 7.3723\n",
      "Epoch 2/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 6.1384 - val_loss: 7.3565\n",
      "Epoch 3/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 6.1272 - val_loss: 7.3410\n",
      "Epoch 4/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 6.1160 - val_loss: 7.3255\n",
      "Epoch 5/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 6.1051 - val_loss: 7.3097\n",
      "Epoch 6/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.0939 - val_loss: 7.2941\n",
      "Epoch 7/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 6.0827 - val_loss: 7.2786\n",
      "Epoch 8/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 6.0718 - val_loss: 7.2626\n",
      "Epoch 9/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.0607 - val_loss: 7.2467\n",
      "Epoch 10/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 6.0495 - val_loss: 7.2310\n",
      "Epoch 11/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 6.0384 - val_loss: 7.2155\n",
      "Epoch 12/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 6.0273 - val_loss: 7.1998\n",
      "Epoch 13/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 6.0161 - val_loss: 7.1841\n",
      "Epoch 14/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 6.0050 - val_loss: 7.1683\n",
      "Epoch 15/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 5.9939 - val_loss: 7.1528\n",
      "Epoch 16/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 5.9829 - val_loss: 7.1368\n",
      "Epoch 17/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 5.9717 - val_loss: 7.1214\n",
      "Epoch 18/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 5.9606 - val_loss: 7.1058\n",
      "Epoch 19/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 5.9497 - val_loss: 7.0899\n",
      "Epoch 20/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 5.9384 - val_loss: 7.0741\n",
      "Epoch 21/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 5.9274 - val_loss: 7.0583\n",
      "Epoch 22/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 5.9162 - val_loss: 7.0428\n",
      "Epoch 23/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 5.9052 - val_loss: 7.0272\n",
      "Epoch 24/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 5.8941 - val_loss: 7.0115\n",
      "Epoch 25/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 5.8833 - val_loss: 6.9954\n",
      "Epoch 26/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 5.8719 - val_loss: 6.9803\n",
      "Epoch 27/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 5.8611 - val_loss: 6.9646\n",
      "Epoch 28/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 5.8500 - val_loss: 6.9490\n",
      "Epoch 29/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 5.8388 - val_loss: 6.9334\n",
      "Epoch 30/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 5.8279 - val_loss: 6.9177\n",
      "Epoch 31/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 5.8167 - val_loss: 6.9023\n",
      "Epoch 32/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 5.8058 - val_loss: 6.8868\n",
      "Epoch 33/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 5.7948 - val_loss: 6.8708\n",
      "Epoch 34/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 5.7836 - val_loss: 6.8552\n",
      "Epoch 35/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 5.7724 - val_loss: 6.8396\n",
      "Epoch 36/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 5.7614 - val_loss: 6.8237\n",
      "Epoch 37/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 5.7504 - val_loss: 6.8080\n",
      "Epoch 38/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 5.7391 - val_loss: 6.7927\n",
      "Epoch 39/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 5.7282 - val_loss: 6.7768\n",
      "Epoch 40/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 5.7171 - val_loss: 6.7609\n",
      "appceleratorstudio, 1753, 583\n",
      "Train on 1753 samples, validate on 583 samples\n",
      "Epoch 1/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 4.4114 - val_loss: 3.7409\n",
      "Epoch 2/40\n",
      "1753/1753 [==============================] - 14s 8ms/step - loss: 3.9358 - val_loss: 1.7515\n",
      "Epoch 3/40\n",
      "1753/1753 [==============================] - 14s 8ms/step - loss: 2.1528 - val_loss: 1.4935\n",
      "Epoch 4/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 2.0627 - val_loss: 1.4142\n",
      "Epoch 5/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 2.0569 - val_loss: 1.4152\n",
      "Epoch 6/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 2.0701 - val_loss: 1.5503\n",
      "Epoch 7/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 2.0207 - val_loss: 1.5581\n",
      "Epoch 8/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.9986 - val_loss: 1.4088\n",
      "Epoch 9/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.9818 - val_loss: 1.4561\n",
      "Epoch 10/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.9865 - val_loss: 1.4371\n",
      "Epoch 11/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.9545 - val_loss: 1.6794\n",
      "Epoch 12/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.8399 - val_loss: 1.6212\n",
      "Epoch 13/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.7584 - val_loss: 1.8850\n",
      "Epoch 14/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.7772 - val_loss: 1.7862\n",
      "Epoch 15/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.6618 - val_loss: 1.7132\n",
      "Epoch 16/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.6136 - val_loss: 1.6507\n",
      "Epoch 17/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.5603 - val_loss: 1.5636\n",
      "Epoch 18/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.4755 - val_loss: 1.7987\n",
      "Epoch 19/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.4565 - val_loss: 1.8663\n",
      "Epoch 20/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.3600 - val_loss: 1.8338\n",
      "Epoch 00020: early stopping\n",
      "mesos, 1008, 336\n",
      "Train on 1008 samples, validate on 336 samples\n",
      "Epoch 1/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.8415 - val_loss: 1.5557\n",
      "Epoch 2/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.8194 - val_loss: 1.5297\n",
      "Epoch 3/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.7098 - val_loss: 1.2652\n",
      "Epoch 4/40\n",
      "1008/1008 [==============================] - 8s 8ms/step - loss: 1.2960 - val_loss: 1.1474\n",
      "Epoch 5/40\n",
      "1008/1008 [==============================] - 8s 8ms/step - loss: 1.2305 - val_loss: 1.1462\n",
      "Epoch 6/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.2102 - val_loss: 1.1330\n",
      "Epoch 7/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1877 - val_loss: 1.1430\n",
      "Epoch 8/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1790 - val_loss: 1.1492\n",
      "Epoch 9/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1442 - val_loss: 1.1064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1365 - val_loss: 1.1366\n",
      "Epoch 11/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.0763 - val_loss: 1.1472\n",
      "Epoch 12/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.0455 - val_loss: 1.1302\n",
      "Epoch 13/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.0138 - val_loss: 1.1024\n",
      "Epoch 14/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.9963 - val_loss: 1.1423\n",
      "Epoch 15/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.9626 - val_loss: 1.1784\n",
      "Epoch 16/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.9141 - val_loss: 1.1496\n",
      "Epoch 17/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.9151 - val_loss: 1.1679\n",
      "Epoch 18/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.8826 - val_loss: 1.1406\n",
      "Epoch 19/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.8108 - val_loss: 1.2387\n",
      "Epoch 20/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.7289 - val_loss: 1.1872\n",
      "Epoch 21/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.7029 - val_loss: 1.2442\n",
      "Epoch 22/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.6334 - val_loss: 1.2415\n",
      "Epoch 23/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.6016 - val_loss: 1.2163\n",
      "Epoch 24/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.5609 - val_loss: 1.2443\n",
      "Epoch 25/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.5838 - val_loss: 1.2217\n",
      "Epoch 00025: early stopping\n",
      "talendesb, 522, 173\n",
      "Train on 522 samples, validate on 173 samples\n",
      "Epoch 1/40\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.9358 - val_loss: 0.8247\n",
      "Epoch 2/40\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.9333 - val_loss: 0.8227\n",
      "Epoch 3/40\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.9306 - val_loss: 0.8205\n",
      "Epoch 4/40\n",
      "522/522 [==============================] - 4s 9ms/step - loss: 0.9273 - val_loss: 0.8176\n",
      "Epoch 5/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.9219 - val_loss: 0.8105\n",
      "Epoch 6/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.9085 - val_loss: 0.7847\n",
      "Epoch 7/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.8415 - val_loss: 0.7073\n",
      "Epoch 8/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.7291 - val_loss: 0.6926\n",
      "Epoch 9/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.6902 - val_loss: 0.6773\n",
      "Epoch 10/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.6619 - val_loss: 0.6617\n",
      "Epoch 11/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.6412 - val_loss: 0.6839\n",
      "Epoch 12/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.6565 - val_loss: 0.6875\n",
      "Epoch 13/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.6451 - val_loss: 0.6803\n",
      "Epoch 14/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.5811 - val_loss: 0.6994\n",
      "Epoch 15/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.6484 - val_loss: 0.6559\n",
      "Epoch 16/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.6615 - val_loss: 0.6338\n",
      "Epoch 17/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.5988 - val_loss: 0.6829\n",
      "Epoch 18/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.5471 - val_loss: 0.6299\n",
      "Epoch 19/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.5538 - val_loss: 0.7580\n",
      "Epoch 20/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.5602 - val_loss: 0.6694\n",
      "Epoch 21/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.5214 - val_loss: 0.7104\n",
      "Epoch 22/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.4904 - val_loss: 0.6872\n",
      "Epoch 23/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.4617 - val_loss: 0.7040\n",
      "Epoch 24/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.4471 - val_loss: 0.6998\n",
      "Epoch 25/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.4204 - val_loss: 0.6764\n",
      "Epoch 26/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.4480 - val_loss: 0.6917\n",
      "Epoch 27/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.4055 - val_loss: 0.6624\n",
      "Epoch 28/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.3963 - val_loss: 0.6808\n",
      "Epoch 29/40\n",
      "522/522 [==============================] - 5s 10ms/step - loss: 0.3698 - val_loss: 0.6869\n",
      "Epoch 30/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.3621 - val_loss: 0.7032\n",
      "Epoch 00030: early stopping\n",
      "springxd, 2116, 705\n",
      "Train on 2116 samples, validate on 705 samples\n",
      "Epoch 1/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 2.4831 - val_loss: 2.5120\n",
      "Epoch 2/40\n",
      "2116/2116 [==============================] - 17s 8ms/step - loss: 2.0082 - val_loss: 1.8135\n",
      "Epoch 3/40\n",
      "2116/2116 [==============================] - 17s 8ms/step - loss: 1.8249 - val_loss: 1.8688\n",
      "Epoch 4/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.8049 - val_loss: 1.7991\n",
      "Epoch 5/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.7758 - val_loss: 1.8003\n",
      "Epoch 6/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.7524 - val_loss: 1.7735\n",
      "Epoch 7/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.7115 - val_loss: 1.7617\n",
      "Epoch 8/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.6634 - val_loss: 1.8143\n",
      "Epoch 9/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.6186 - val_loss: 1.8381\n",
      "Epoch 10/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.5639 - val_loss: 1.7118\n",
      "Epoch 11/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.5449 - val_loss: 1.7404\n",
      "Epoch 12/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.4919 - val_loss: 1.7315\n",
      "Epoch 13/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.4254 - val_loss: 1.7054\n",
      "Epoch 14/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.4136 - val_loss: 1.7082\n",
      "Epoch 15/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.3687 - val_loss: 1.7683\n",
      "Epoch 16/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.3133 - val_loss: 1.7791\n",
      "Epoch 17/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.2900 - val_loss: 1.7124\n",
      "Epoch 18/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.2487 - val_loss: 1.8140\n",
      "Epoch 19/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.1979 - val_loss: 1.7648\n",
      "Epoch 20/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.1596 - val_loss: 1.8341\n",
      "Epoch 21/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.1199 - val_loss: 1.7659\n",
      "Epoch 22/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.0682 - val_loss: 1.8089\n",
      "Epoch 23/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.0367 - val_loss: 1.8498\n",
      "Epoch 24/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 0.9867 - val_loss: 1.8554\n",
      "Epoch 25/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 0.9801 - val_loss: 1.7974\n",
      "Epoch 00025: early stopping\n",
      "mulestudio, 440, 146\n",
      "Train on 440 samples, validate on 146 samples\n",
      "Epoch 1/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.3759 - val_loss: 5.6502\n",
      "Epoch 2/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.3617 - val_loss: 5.6336\n",
      "Epoch 3/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.3440 - val_loss: 5.6104\n",
      "Epoch 4/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.3123 - val_loss: 5.5519\n",
      "Epoch 5/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.2075 - val_loss: 5.3509\n",
      "Epoch 6/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 3.8646 - val_loss: 4.7384\n",
      "Epoch 7/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440/440 [==============================] - 4s 8ms/step - loss: 3.1595 - val_loss: 3.7241\n",
      "Epoch 8/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.6134 - val_loss: 3.2763\n",
      "Epoch 9/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5553 - val_loss: 3.3997\n",
      "Epoch 10/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4997 - val_loss: 3.3163\n",
      "Epoch 11/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4948 - val_loss: 3.2792\n",
      "Epoch 12/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4942 - val_loss: 3.3119\n",
      "Epoch 13/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5198 - val_loss: 3.2899\n",
      "Epoch 14/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4887 - val_loss: 3.2796\n",
      "Epoch 15/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4615 - val_loss: 3.2267\n",
      "Epoch 16/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4149 - val_loss: 3.2576\n",
      "Epoch 17/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4363 - val_loss: 3.2299\n",
      "Epoch 18/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4139 - val_loss: 3.2137\n",
      "Epoch 19/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.3929 - val_loss: 3.2135\n",
      "Epoch 20/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4029 - val_loss: 3.2242\n",
      "Epoch 21/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.2571 - val_loss: 3.2555\n",
      "Epoch 22/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.2257 - val_loss: 3.2183\n",
      "Epoch 23/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.1412 - val_loss: 3.2526\n",
      "Epoch 24/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.1217 - val_loss: 3.3611\n",
      "Epoch 25/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.0891 - val_loss: 3.2205\n",
      "Epoch 26/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.0344 - val_loss: 3.2967\n",
      "Epoch 27/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.9762 - val_loss: 3.3198\n",
      "Epoch 28/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.8676 - val_loss: 3.3036\n",
      "Epoch 29/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.7455 - val_loss: 3.3037\n",
      "Epoch 30/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.5977 - val_loss: 3.2515\n",
      "Epoch 31/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.5985 - val_loss: 3.3352\n",
      "Epoch 00031: early stopping\n",
      "moodle, 700, 233\n",
      "Train on 700 samples, validate on 233 samples\n",
      "Epoch 1/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.8476 - val_loss: 13.9712\n",
      "Epoch 2/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.8259 - val_loss: 13.9465\n",
      "Epoch 3/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.8013 - val_loss: 13.9176\n",
      "Epoch 4/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.7624 - val_loss: 13.8461\n",
      "Epoch 5/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.6126 - val_loss: 13.5197\n",
      "Epoch 6/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 11.9773 - val_loss: 12.3094\n",
      "Epoch 7/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 10.5890 - val_loss: 10.3685\n",
      "Epoch 8/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 9.6565 - val_loss: 9.9113\n",
      "Epoch 9/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 9.5100 - val_loss: 9.9617\n",
      "Epoch 10/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.4611 - val_loss: 9.9326\n",
      "Epoch 11/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.4213 - val_loss: 9.9605\n",
      "Epoch 12/40\n",
      "700/700 [==============================] - 7s 9ms/step - loss: 9.3364 - val_loss: 10.4522\n",
      "Epoch 13/40\n",
      "700/700 [==============================] - 7s 9ms/step - loss: 9.3824 - val_loss: 10.3793\n",
      "Epoch 14/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.5710 - val_loss: 10.1765\n",
      "Epoch 15/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.0918 - val_loss: 9.9737\n",
      "Epoch 16/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.1801 - val_loss: 9.7074\n",
      "Epoch 17/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.0106 - val_loss: 9.6642\n",
      "Epoch 18/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.7054 - val_loss: 9.5620\n",
      "Epoch 19/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.4875 - val_loss: 9.4597\n",
      "Epoch 20/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.3313 - val_loss: 9.4700\n",
      "Epoch 21/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.2333 - val_loss: 10.2758\n",
      "Epoch 22/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.0352 - val_loss: 9.8951\n",
      "Epoch 23/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.3805 - val_loss: 10.0902\n",
      "Epoch 24/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.1409 - val_loss: 9.5098\n",
      "Epoch 25/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 7.9931 - val_loss: 9.5721\n",
      "Epoch 26/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 7.6340 - val_loss: 9.6358\n",
      "Epoch 27/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 7.4516 - val_loss: 9.6907\n",
      "Epoch 28/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 7.3452 - val_loss: 9.8610\n",
      "Epoch 29/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 7.3452 - val_loss: 9.5358\n",
      "Epoch 30/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 6.7527 - val_loss: 9.8505\n",
      "Epoch 31/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 6.6211 - val_loss: 9.8457\n",
      "Epoch 00031: early stopping\n",
      "jirasoftware, 212, 70\n",
      "Train on 212 samples, validate on 70 samples\n",
      "Epoch 1/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4694 - val_loss: 2.0957\n",
      "Epoch 2/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.4633 - val_loss: 2.0913\n",
      "Epoch 3/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4572 - val_loss: 2.0866\n",
      "Epoch 4/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4507 - val_loss: 2.0817\n",
      "Epoch 5/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4439 - val_loss: 2.0763\n",
      "Epoch 6/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4360 - val_loss: 2.0698\n",
      "Epoch 7/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4254 - val_loss: 2.0606\n",
      "Epoch 8/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4098 - val_loss: 2.0445\n",
      "Epoch 9/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.3810 - val_loss: 2.0136\n",
      "Epoch 10/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.3240 - val_loss: 1.9589\n",
      "Epoch 11/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.2313 - val_loss: 1.8643\n",
      "Epoch 12/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.0668 - val_loss: 1.7018\n",
      "Epoch 13/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.8098 - val_loss: 1.5144\n",
      "Epoch 14/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.5330 - val_loss: 1.4576\n",
      "Epoch 15/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.2969 - val_loss: 1.6688\n",
      "Epoch 16/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1614 - val_loss: 1.9477\n",
      "Epoch 17/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1505 - val_loss: 2.1396\n",
      "Epoch 18/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.2312 - val_loss: 2.0916\n",
      "Epoch 19/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1883 - val_loss: 2.0282\n",
      "Epoch 20/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.2143 - val_loss: 1.9714\n",
      "Epoch 21/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1862 - val_loss: 1.9502\n",
      "Epoch 22/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1582 - val_loss: 1.9978\n",
      "Epoch 23/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1615 - val_loss: 2.0400\n",
      "Epoch 24/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1226 - val_loss: 1.9502\n",
      "Epoch 25/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1481 - val_loss: 2.0097\n",
      "Epoch 26/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.0864 - val_loss: 1.9992\n",
      "Epoch 00026: early stopping\n",
      "duracloud, 400, 133\n",
      "Train on 400 samples, validate on 133 samples\n",
      "Epoch 1/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 2/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 3/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 4/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 5/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 6/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 7/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 8/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 9/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 10/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 11/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 12/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 13/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 00013: early stopping\n",
      "titanium, 1351, 450\n",
      "Train on 1351 samples, validate on 450 samples\n",
      "Epoch 1/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 5.0888 - val_loss: 4.5036\n",
      "Epoch 2/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 5.0243 - val_loss: 4.3301\n",
      "Epoch 3/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 4.2214 - val_loss: 2.5495\n",
      "Epoch 4/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1968 - val_loss: 2.3771\n",
      "Epoch 5/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1313 - val_loss: 2.3195\n",
      "Epoch 6/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1350 - val_loss: 2.2992\n",
      "Epoch 7/40\n",
      "1351/1351 [==============================] - 11s 9ms/step - loss: 3.1249 - val_loss: 2.3174\n",
      "Epoch 8/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.0873 - val_loss: 2.3255\n",
      "Epoch 9/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.0808 - val_loss: 2.3180\n",
      "Epoch 10/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.0690 - val_loss: 2.3671\n",
      "Epoch 11/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.0492 - val_loss: 2.3447\n",
      "Epoch 12/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.0089 - val_loss: 2.3284\n",
      "Epoch 13/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.8869 - val_loss: 2.3682\n",
      "Epoch 14/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.7971 - val_loss: 2.4245\n",
      "Epoch 15/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.5746 - val_loss: 2.3783\n",
      "Epoch 16/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.4289 - val_loss: 2.4496\n",
      "Epoch 17/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.2621 - val_loss: 2.4954\n",
      "Epoch 18/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.0937 - val_loss: 2.6498\n",
      "Epoch 00018: early stopping\n",
      "aptanastudio, 499, 165\n",
      "Train on 499 samples, validate on 165 samples\n",
      "Epoch 1/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.1485 - val_loss: 7.3706\n",
      "Epoch 2/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.1361 - val_loss: 7.3522\n",
      "Epoch 3/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.1221 - val_loss: 7.3298\n",
      "Epoch 4/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.0994 - val_loss: 7.2778\n",
      "Epoch 5/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.0344 - val_loss: 7.1047\n",
      "Epoch 6/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 5.8124 - val_loss: 6.5708\n",
      "Epoch 7/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 5.2632 - val_loss: 5.2556\n",
      "Epoch 8/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 4.2907 - val_loss: 3.3903\n",
      "Epoch 9/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.6385 - val_loss: 2.9242\n",
      "Epoch 10/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.3704 - val_loss: 2.8412\n",
      "Epoch 11/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.3143 - val_loss: 2.7193\n",
      "Epoch 12/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.2928 - val_loss: 3.0831\n",
      "Epoch 13/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.2921 - val_loss: 2.7836\n",
      "Epoch 14/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.2082 - val_loss: 3.4358\n",
      "Epoch 15/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.2797 - val_loss: 3.0472\n",
      "Epoch 16/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.1653 - val_loss: 3.2564\n",
      "Epoch 17/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.1306 - val_loss: 3.5293\n",
      "Epoch 18/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.2573 - val_loss: 2.8103\n",
      "Epoch 19/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.1005 - val_loss: 2.8085\n",
      "Epoch 20/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.0441 - val_loss: 3.0993\n",
      "Epoch 21/40\n",
      "499/499 [==============================] - 5s 9ms/step - loss: 2.8966 - val_loss: 3.2820\n",
      "Epoch 22/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 2.9829 - val_loss: 2.9006\n",
      "Epoch 23/40\n",
      "499/499 [==============================] - 5s 9ms/step - loss: 2.9882 - val_loss: 3.2693\n",
      "Epoch 00023: early stopping\n",
      "appceleratorstudio, 1753, 583\n",
      "Train on 1753 samples, validate on 583 samples\n",
      "Epoch 1/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 4.4358 - val_loss: 3.8079\n",
      "Epoch 2/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 4.4358 - val_loss: 3.8079\n",
      "Epoch 3/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 4.4358 - val_loss: 3.8079\n",
      "Epoch 4/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 4.4358 - val_loss: 3.8079\n",
      "Epoch 5/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 4.4358 - val_loss: 3.8079\n",
      "Epoch 6/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 4.4358 - val_loss: 3.8079\n",
      "Epoch 7/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 4.4358 - val_loss: 3.8079\n",
      "Epoch 8/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 4.4358 - val_loss: 3.8079\n",
      "Epoch 9/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 4.4358 - val_loss: 3.8079\n",
      "Epoch 10/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 4.4358 - val_loss: 3.8079\n",
      "Epoch 11/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 4.4358 - val_loss: 3.8079\n",
      "Epoch 12/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 4.4358 - val_loss: 3.8079\n",
      "Epoch 13/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 4.4358 - val_loss: 3.8079\n",
      "Epoch 00013: early stopping\n",
      "mesos, 1008, 336\n",
      "Train on 1008 samples, validate on 336 samples\n",
      "Epoch 1/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.8424 - val_loss: 1.5578\n",
      "Epoch 2/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.8260 - val_loss: 1.5437\n",
      "Epoch 3/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.8093 - val_loss: 1.5303\n",
      "Epoch 4/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.7928 - val_loss: 1.5165\n",
      "Epoch 5/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.7761 - val_loss: 1.5026\n",
      "Epoch 6/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.7597 - val_loss: 1.4886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.7431 - val_loss: 1.4749\n",
      "Epoch 8/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.7265 - val_loss: 1.4613\n",
      "Epoch 9/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.7100 - val_loss: 1.4473\n",
      "Epoch 10/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.6935 - val_loss: 1.4334\n",
      "Epoch 11/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.6768 - val_loss: 1.4198\n",
      "Epoch 12/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.6602 - val_loss: 1.4062\n",
      "Epoch 13/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.6439 - val_loss: 1.3917\n",
      "Epoch 14/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.6270 - val_loss: 1.3784\n",
      "Epoch 15/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.6106 - val_loss: 1.3645\n",
      "Epoch 16/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.5940 - val_loss: 1.3508\n",
      "Epoch 17/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.5776 - val_loss: 1.3366\n",
      "Epoch 18/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.5609 - val_loss: 1.3232\n",
      "Epoch 19/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.5444 - val_loss: 1.3093\n",
      "Epoch 20/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.5279 - val_loss: 1.2954\n",
      "Epoch 21/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.5111 - val_loss: 1.2819\n",
      "Epoch 22/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.4948 - val_loss: 1.2678\n",
      "Epoch 23/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.4779 - val_loss: 1.2544\n",
      "Epoch 24/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.4618 - val_loss: 1.2399\n",
      "Epoch 25/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.4448 - val_loss: 1.2264\n",
      "Epoch 26/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.4284 - val_loss: 1.2127\n",
      "Epoch 27/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.4120 - val_loss: 1.1990\n",
      "Epoch 28/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.3956 - val_loss: 1.1854\n",
      "Epoch 29/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.3792 - val_loss: 1.1716\n",
      "Epoch 30/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.3628 - val_loss: 1.1578\n",
      "Epoch 31/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.3462 - val_loss: 1.1445\n",
      "Epoch 32/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.3297 - val_loss: 1.1305\n",
      "Epoch 33/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.3155 - val_loss: 1.1253\n",
      "Epoch 34/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.3128 - val_loss: 1.1255\n",
      "Epoch 35/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.3120 - val_loss: 1.1258\n",
      "Epoch 36/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.3111 - val_loss: 1.1260\n",
      "Epoch 37/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.3103 - val_loss: 1.1262\n",
      "Epoch 38/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.3094 - val_loss: 1.1264\n",
      "Epoch 39/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.3085 - val_loss: 1.1266\n",
      "Epoch 40/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.3076 - val_loss: 1.1269\n",
      "talendesb, 522, 173\n",
      "Train on 522 samples, validate on 173 samples\n",
      "Epoch 1/40\n",
      "522/522 [==============================] - 4s 9ms/step - loss: 0.9356 - val_loss: 0.8248\n",
      "Epoch 2/40\n",
      "522/522 [==============================] - 4s 9ms/step - loss: 0.9334 - val_loss: 0.8229\n",
      "Epoch 3/40\n",
      "522/522 [==============================] - 4s 9ms/step - loss: 0.9311 - val_loss: 0.8213\n",
      "Epoch 4/40\n",
      "522/522 [==============================] - 4s 9ms/step - loss: 0.9290 - val_loss: 0.8195\n",
      "Epoch 5/40\n",
      "522/522 [==============================] - 4s 9ms/step - loss: 0.9269 - val_loss: 0.8176\n",
      "Epoch 6/40\n",
      "522/522 [==============================] - 4s 9ms/step - loss: 0.9245 - val_loss: 0.8160\n",
      "Epoch 7/40\n",
      "522/522 [==============================] - 4s 9ms/step - loss: 0.9222 - val_loss: 0.8142\n",
      "Epoch 8/40\n",
      "522/522 [==============================] - 4s 9ms/step - loss: 0.9200 - val_loss: 0.8124\n",
      "Epoch 9/40\n",
      "522/522 [==============================] - 4s 9ms/step - loss: 0.9177 - val_loss: 0.8107\n",
      "Epoch 10/40\n",
      "522/522 [==============================] - 4s 9ms/step - loss: 0.9154 - val_loss: 0.8089\n",
      "Epoch 11/40\n",
      "522/522 [==============================] - 4s 9ms/step - loss: 0.9131 - val_loss: 0.8070\n",
      "Epoch 12/40\n",
      "522/522 [==============================] - 4s 9ms/step - loss: 0.9108 - val_loss: 0.8050\n",
      "Epoch 13/40\n",
      "522/522 [==============================] - 4s 9ms/step - loss: 0.9084 - val_loss: 0.8032\n",
      "Epoch 14/40\n",
      "522/522 [==============================] - 4s 9ms/step - loss: 0.9061 - val_loss: 0.8016\n",
      "Epoch 15/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.9039 - val_loss: 0.7997\n",
      "Epoch 16/40\n",
      "522/522 [==============================] - 4s 9ms/step - loss: 0.9014 - val_loss: 0.7980\n",
      "Epoch 17/40\n",
      "522/522 [==============================] - 4s 9ms/step - loss: 0.8991 - val_loss: 0.7961\n",
      "Epoch 18/40\n",
      "522/522 [==============================] - 4s 9ms/step - loss: 0.8968 - val_loss: 0.7941\n",
      "Epoch 19/40\n",
      "522/522 [==============================] - 4s 9ms/step - loss: 0.8944 - val_loss: 0.7924\n",
      "Epoch 20/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.8922 - val_loss: 0.7908\n",
      "Epoch 21/40\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.8901 - val_loss: 0.7887\n",
      "Epoch 22/40\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.8876 - val_loss: 0.7870\n",
      "Epoch 23/40\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.8856 - val_loss: 0.7852\n",
      "Epoch 24/40\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.8832 - val_loss: 0.7836\n",
      "Epoch 25/40\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.8813 - val_loss: 0.7819\n",
      "Epoch 26/40\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.8788 - val_loss: 0.7803\n",
      "Epoch 27/40\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.8768 - val_loss: 0.7783\n",
      "Epoch 28/40\n",
      "522/522 [==============================] - 4s 9ms/step - loss: 0.8744 - val_loss: 0.7764\n",
      "Epoch 29/40\n",
      "522/522 [==============================] - 4s 9ms/step - loss: 0.8719 - val_loss: 0.7749\n",
      "Epoch 30/40\n",
      "522/522 [==============================] - 4s 9ms/step - loss: 0.8701 - val_loss: 0.7729\n",
      "Epoch 31/40\n",
      "522/522 [==============================] - 4s 9ms/step - loss: 0.8675 - val_loss: 0.7713\n",
      "Epoch 32/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.8653 - val_loss: 0.7694\n",
      "Epoch 33/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.8627 - val_loss: 0.7677\n",
      "Epoch 34/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.8607 - val_loss: 0.7657\n",
      "Epoch 35/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.8584 - val_loss: 0.7638\n",
      "Epoch 36/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.8559 - val_loss: 0.7621\n",
      "Epoch 37/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.8538 - val_loss: 0.7603\n",
      "Epoch 38/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.8513 - val_loss: 0.7584\n",
      "Epoch 39/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.8490 - val_loss: 0.7566\n",
      "Epoch 40/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.8466 - val_loss: 0.7548\n",
      "springxd, 2116, 705\n",
      "Train on 2116 samples, validate on 705 samples\n",
      "Epoch 1/40\n",
      "2116/2116 [==============================] - 17s 8ms/step - loss: 2.4836 - val_loss: 2.5222\n",
      "Epoch 2/40\n",
      "2116/2116 [==============================] - 17s 8ms/step - loss: 2.0403 - val_loss: 1.8091\n",
      "Epoch 3/40\n",
      "2116/2116 [==============================] - 17s 8ms/step - loss: 1.8318 - val_loss: 1.7909\n",
      "Epoch 4/40\n",
      "2116/2116 [==============================] - 17s 8ms/step - loss: 1.8225 - val_loss: 1.7945\n",
      "Epoch 5/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.7963 - val_loss: 1.8131\n",
      "Epoch 6/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.7603 - val_loss: 1.7954\n",
      "Epoch 7/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.7495 - val_loss: 1.7830\n",
      "Epoch 8/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.7074 - val_loss: 1.8234\n",
      "Epoch 9/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.6588 - val_loss: 1.8167\n",
      "Epoch 10/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.6059 - val_loss: 1.8302\n",
      "Epoch 11/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.5260 - val_loss: 1.8158\n",
      "Epoch 12/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.5215 - val_loss: 1.7803\n",
      "Epoch 13/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.4592 - val_loss: 1.7683\n",
      "Epoch 14/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.3616 - val_loss: 1.7464\n",
      "Epoch 15/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.3220 - val_loss: 1.7607\n",
      "Epoch 16/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.2600 - val_loss: 1.8071\n",
      "Epoch 17/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.1886 - val_loss: 1.8319\n",
      "Epoch 18/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.1381 - val_loss: 1.9141\n",
      "Epoch 19/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.1453 - val_loss: 1.8268\n",
      "Epoch 20/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.0744 - val_loss: 1.7438\n",
      "Epoch 21/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.0299 - val_loss: 1.7947\n",
      "Epoch 22/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.9606 - val_loss: 1.7861\n",
      "Epoch 23/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.9298 - val_loss: 1.9783\n",
      "Epoch 24/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.8890 - val_loss: 1.8098\n",
      "Epoch 25/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.8862 - val_loss: 1.8285\n",
      "Epoch 26/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.8393 - val_loss: 1.8272\n",
      "Epoch 27/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.7986 - val_loss: 1.8507\n",
      "Epoch 28/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.7529 - val_loss: 1.9132\n",
      "Epoch 29/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.7396 - val_loss: 1.8372\n",
      "Epoch 30/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.7178 - val_loss: 1.8595\n",
      "Epoch 31/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.7298 - val_loss: 1.8244\n",
      "Epoch 32/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.6922 - val_loss: 1.8533\n",
      "Epoch 00032: early stopping\n",
      "mulestudio, 440, 146\n",
      "Train on 440 samples, validate on 146 samples\n",
      "Epoch 1/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.3762 - val_loss: 5.6506\n",
      "Epoch 2/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.3624 - val_loss: 5.6352\n",
      "Epoch 3/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.3464 - val_loss: 5.6162\n",
      "Epoch 4/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.3239 - val_loss: 5.5832\n",
      "Epoch 5/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.2725 - val_loss: 5.4903\n",
      "Epoch 6/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.1283 - val_loss: 5.2286\n",
      "Epoch 7/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 3.7103 - val_loss: 4.5402\n",
      "Epoch 8/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.9547 - val_loss: 3.5938\n",
      "Epoch 9/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.6312 - val_loss: 3.2888\n",
      "Epoch 10/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5246 - val_loss: 3.4115\n",
      "Epoch 11/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4933 - val_loss: 3.3259\n",
      "Epoch 12/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5041 - val_loss: 3.4079\n",
      "Epoch 13/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.5155 - val_loss: 3.2888\n",
      "Epoch 14/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4660 - val_loss: 3.2365\n",
      "Epoch 15/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4335 - val_loss: 3.4012\n",
      "Epoch 16/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4485 - val_loss: 3.2213\n",
      "Epoch 17/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.3683 - val_loss: 3.2119\n",
      "Epoch 18/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.3853 - val_loss: 3.2371\n",
      "Epoch 19/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.3164 - val_loss: 3.2366\n",
      "Epoch 20/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.2875 - val_loss: 3.2500\n",
      "Epoch 21/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.2331 - val_loss: 3.2060\n",
      "Epoch 22/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.2542 - val_loss: 3.2363\n",
      "Epoch 23/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.2170 - val_loss: 3.2062\n",
      "Epoch 24/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.1178 - val_loss: 3.2385\n",
      "Epoch 25/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.0935 - val_loss: 3.3394\n",
      "Epoch 26/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.0757 - val_loss: 3.2241\n",
      "Epoch 27/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.0131 - val_loss: 3.2655\n",
      "Epoch 28/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.0014 - val_loss: 3.3747\n",
      "Epoch 29/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.9600 - val_loss: 3.3276\n",
      "Epoch 30/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.9218 - val_loss: 3.2786\n",
      "Epoch 31/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.8090 - val_loss: 3.3226\n",
      "Epoch 32/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.7204 - val_loss: 3.1907\n",
      "Epoch 33/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.6531 - val_loss: 3.2541\n",
      "Epoch 34/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.5983 - val_loss: 3.2892\n",
      "Epoch 35/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.4725 - val_loss: 3.2449\n",
      "Epoch 36/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.4216 - val_loss: 3.2943\n",
      "Epoch 37/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.4525 - val_loss: 3.3524\n",
      "Epoch 38/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.3970 - val_loss: 3.3495\n",
      "Epoch 39/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.3800 - val_loss: 3.3269\n",
      "Epoch 40/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.4433 - val_loss: 3.3205\n",
      "moodle, 700, 233\n",
      "Train on 700 samples, validate on 233 samples\n",
      "Epoch 1/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.8453 - val_loss: 13.9673\n",
      "Epoch 2/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.8205 - val_loss: 13.9367\n",
      "Epoch 3/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.7714 - val_loss: 13.8281\n",
      "Epoch 4/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.4949 - val_loss: 13.1607\n",
      "Epoch 5/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 11.3191 - val_loss: 10.9309\n",
      "Epoch 6/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 9.8039 - val_loss: 9.9160\n",
      "Epoch 7/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 9.5806 - val_loss: 9.8773\n",
      "Epoch 8/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.5547 - val_loss: 9.8855\n",
      "Epoch 9/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.5198 - val_loss: 9.8740\n",
      "Epoch 10/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.3625 - val_loss: 9.9089\n",
      "Epoch 11/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.5084 - val_loss: 10.0263\n",
      "Epoch 12/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.3868 - val_loss: 9.8906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.1704 - val_loss: 9.7296\n",
      "Epoch 14/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.9921 - val_loss: 9.6442\n",
      "Epoch 15/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.9002 - val_loss: 9.6859\n",
      "Epoch 16/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.4388 - val_loss: 9.7229\n",
      "Epoch 17/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.2006 - val_loss: 9.6025\n",
      "Epoch 18/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.0022 - val_loss: 10.5214\n",
      "Epoch 19/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.7089 - val_loss: 9.6931\n",
      "Epoch 20/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.4330 - val_loss: 9.9791\n",
      "Epoch 21/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.1339 - val_loss: 9.5940\n",
      "Epoch 22/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 7.8184 - val_loss: 9.6908\n",
      "Epoch 23/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 7.8865 - val_loss: 9.6506\n",
      "Epoch 24/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.0107 - val_loss: 9.5856\n",
      "Epoch 25/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 7.4929 - val_loss: 9.4668\n",
      "Epoch 26/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 7.3798 - val_loss: 9.5454\n",
      "Epoch 27/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 6.9213 - val_loss: 9.3232\n",
      "Epoch 28/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 6.7558 - val_loss: 9.6557\n",
      "Epoch 29/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 6.2573 - val_loss: 9.6843\n",
      "Epoch 30/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 6.1145 - val_loss: 10.2552\n",
      "Epoch 31/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 5.9598 - val_loss: 9.4003\n",
      "Epoch 32/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 5.9671 - val_loss: 9.6423\n",
      "Epoch 33/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 5.4998 - val_loss: 9.8953\n",
      "Epoch 34/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 6.0243 - val_loss: 9.6461\n",
      "Epoch 35/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 5.3232 - val_loss: 9.9264\n",
      "Epoch 36/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 5.1167 - val_loss: 9.9828\n",
      "Epoch 37/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 4.7073 - val_loss: 10.0554\n",
      "Epoch 38/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 4.2497 - val_loss: 10.5650\n",
      "Epoch 39/40\n",
      "700/700 [==============================] - 7s 10ms/step - loss: 4.2756 - val_loss: 10.0942\n",
      "Epoch 00039: early stopping\n",
      "jirasoftware, 212, 70\n",
      "Train on 212 samples, validate on 70 samples\n",
      "Epoch 1/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4694 - val_loss: 2.0957\n",
      "Epoch 2/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4633 - val_loss: 2.0911\n",
      "Epoch 3/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4569 - val_loss: 2.0862\n",
      "Epoch 4/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4501 - val_loss: 2.0809\n",
      "Epoch 5/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4424 - val_loss: 2.0752\n",
      "Epoch 6/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4341 - val_loss: 2.0683\n",
      "Epoch 7/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4236 - val_loss: 2.0588\n",
      "Epoch 8/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4080 - val_loss: 2.0435\n",
      "Epoch 9/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.3798 - val_loss: 2.0148\n",
      "Epoch 10/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.3278 - val_loss: 1.9640\n",
      "Epoch 11/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.2428 - val_loss: 1.8766\n",
      "Epoch 12/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.0887 - val_loss: 1.7282\n",
      "Epoch 13/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.8458 - val_loss: 1.5221\n",
      "Epoch 14/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.5913 - val_loss: 1.4704\n",
      "Epoch 15/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.3332 - val_loss: 1.6079\n",
      "Epoch 16/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.2489 - val_loss: 1.9108\n",
      "Epoch 17/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.2231 - val_loss: 2.1677\n",
      "Epoch 18/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1774 - val_loss: 2.1357\n",
      "Epoch 19/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1812 - val_loss: 2.0084\n",
      "Epoch 20/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1583 - val_loss: 1.9375\n",
      "Epoch 21/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1706 - val_loss: 1.9532\n",
      "Epoch 22/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1726 - val_loss: 2.0173\n",
      "Epoch 23/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1520 - val_loss: 2.1199\n",
      "Epoch 24/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1450 - val_loss: 2.0368\n",
      "Epoch 25/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.2020 - val_loss: 1.9629\n",
      "Epoch 26/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.0928 - val_loss: 1.9866\n",
      "Epoch 00026: early stopping\n",
      "duracloud, 400, 133\n",
      "Train on 400 samples, validate on 133 samples\n",
      "Epoch 1/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 2/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 3/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 4/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 5/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 6/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 7/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 8/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 9/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 10/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 11/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 12/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 13/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 00013: early stopping\n",
      "titanium, 1351, 450\n",
      "Train on 1351 samples, validate on 450 samples\n",
      "Epoch 1/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 5.0887 - val_loss: 4.5025\n",
      "Epoch 2/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.9491 - val_loss: 3.9352\n",
      "Epoch 3/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.5148 - val_loss: 2.2869\n",
      "Epoch 4/40\n",
      "1351/1351 [==============================] - 11s 9ms/step - loss: 3.1190 - val_loss: 2.3405\n",
      "Epoch 5/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.1637 - val_loss: 2.3444\n",
      "Epoch 6/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.1201 - val_loss: 2.2935\n",
      "Epoch 7/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1042 - val_loss: 2.3441\n",
      "Epoch 8/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1307 - val_loss: 2.3315\n",
      "Epoch 9/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1122 - val_loss: 2.3023\n",
      "Epoch 10/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1257 - val_loss: 2.3211\n",
      "Epoch 11/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.0959 - val_loss: 2.3553\n",
      "Epoch 12/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.0906 - val_loss: 2.3284\n",
      "Epoch 13/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.0529 - val_loss: 2.4160\n",
      "Epoch 14/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.0137 - val_loss: 2.3332\n",
      "Epoch 15/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.9543 - val_loss: 2.2706\n",
      "Epoch 16/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.8630 - val_loss: 2.3271\n",
      "Epoch 17/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.7707 - val_loss: 2.3891\n",
      "Epoch 18/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.6679 - val_loss: 2.3809\n",
      "Epoch 19/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.5982 - val_loss: 2.4751\n",
      "Epoch 20/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.5241 - val_loss: 2.7437\n",
      "Epoch 21/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.3668 - val_loss: 2.4421\n",
      "Epoch 22/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.2791 - val_loss: 2.6063\n",
      "Epoch 23/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.1882 - val_loss: 2.5727\n",
      "Epoch 24/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.0220 - val_loss: 2.9128\n",
      "Epoch 25/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 1.9507 - val_loss: 2.7544\n",
      "Epoch 26/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 1.9021 - val_loss: 2.7063\n",
      "Epoch 27/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 1.8339 - val_loss: 2.8243\n",
      "Epoch 00027: early stopping\n",
      "aptanastudio, 499, 165\n",
      "Train on 499 samples, validate on 165 samples\n",
      "Epoch 1/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.1486 - val_loss: 7.3705\n",
      "Epoch 2/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.1360 - val_loss: 7.3511\n",
      "Epoch 3/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.1200 - val_loss: 7.3211\n",
      "Epoch 4/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.0796 - val_loss: 7.2099\n",
      "Epoch 5/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 5.9232 - val_loss: 6.7889\n",
      "Epoch 6/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 5.3992 - val_loss: 5.4606\n",
      "Epoch 7/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 4.4013 - val_loss: 3.3130\n",
      "Epoch 8/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 3.6678 - val_loss: 2.7614\n",
      "Epoch 9/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.5747 - val_loss: 2.8695\n",
      "Epoch 10/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.4251 - val_loss: 2.7683\n",
      "Epoch 11/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.2810 - val_loss: 2.9458\n",
      "Epoch 12/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.3121 - val_loss: 2.7908\n",
      "Epoch 13/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.2658 - val_loss: 2.8246\n",
      "Epoch 14/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.1546 - val_loss: 3.2907\n",
      "Epoch 15/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.1007 - val_loss: 3.3718\n",
      "Epoch 16/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.2343 - val_loss: 2.8994\n",
      "Epoch 17/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.0466 - val_loss: 3.2875\n",
      "Epoch 18/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.0704 - val_loss: 2.8576\n",
      "Epoch 19/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.1333 - val_loss: 2.8368\n",
      "Epoch 20/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 2.9354 - val_loss: 3.0297\n",
      "Epoch 00020: early stopping\n",
      "appceleratorstudio, 1753, 583\n",
      "Train on 1753 samples, validate on 583 samples\n",
      "Epoch 1/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 4.4041 - val_loss: 3.6710\n",
      "Epoch 2/40\n",
      "1753/1753 [==============================] - 14s 8ms/step - loss: 3.2627 - val_loss: 2.0517\n",
      "Epoch 3/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 2.1076 - val_loss: 1.5539\n",
      "Epoch 4/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 2.0606 - val_loss: 1.5705\n",
      "Epoch 5/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 2.0667 - val_loss: 1.3586\n",
      "Epoch 6/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 2.0602 - val_loss: 1.6276\n",
      "Epoch 7/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 2.0762 - val_loss: 1.6660\n",
      "Epoch 8/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0555 - val_loss: 1.3845\n",
      "Epoch 9/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0292 - val_loss: 1.4913\n",
      "Epoch 10/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0272 - val_loss: 1.4243\n",
      "Epoch 11/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0280 - val_loss: 1.3871\n",
      "Epoch 12/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.9731 - val_loss: 1.4788\n",
      "Epoch 13/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.9119 - val_loss: 1.4043\n",
      "Epoch 14/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.8193 - val_loss: 1.6887\n",
      "Epoch 15/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.6974 - val_loss: 1.6943\n",
      "Epoch 16/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.5907 - val_loss: 1.6860\n",
      "Epoch 17/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.4631 - val_loss: 1.6782\n",
      "Epoch 00017: early stopping\n",
      "mesos, 1008, 336\n",
      "Train on 1008 samples, validate on 336 samples\n",
      "Epoch 1/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.8415 - val_loss: 1.5559\n",
      "Epoch 2/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.8168 - val_loss: 1.5155\n",
      "Epoch 3/40\n",
      "1008/1008 [==============================] - 8s 8ms/step - loss: 1.6401 - val_loss: 1.1266\n",
      "Epoch 4/40\n",
      "1008/1008 [==============================] - 8s 8ms/step - loss: 1.2424 - val_loss: 1.1520\n",
      "Epoch 5/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.2381 - val_loss: 1.1490\n",
      "Epoch 6/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1968 - val_loss: 1.1300\n",
      "Epoch 7/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1721 - val_loss: 1.1165\n",
      "Epoch 8/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1576 - val_loss: 1.1296\n",
      "Epoch 9/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1391 - val_loss: 1.1137\n",
      "Epoch 10/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1178 - val_loss: 1.1339\n",
      "Epoch 11/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.0998 - val_loss: 1.1979\n",
      "Epoch 12/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.0570 - val_loss: 1.1438\n",
      "Epoch 13/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.0367 - val_loss: 1.1388\n",
      "Epoch 14/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.0288 - val_loss: 1.1429\n",
      "Epoch 15/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.9917 - val_loss: 1.1592\n",
      "Epoch 16/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.9773 - val_loss: 1.1796\n",
      "Epoch 17/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.9394 - val_loss: 1.2035\n",
      "Epoch 18/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.8811 - val_loss: 1.1744\n",
      "Epoch 19/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.8756 - val_loss: 1.1351\n",
      "Epoch 20/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.8145 - val_loss: 1.2175\n",
      "Epoch 21/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.8154 - val_loss: 1.2355\n",
      "Epoch 00021: early stopping\n",
      "talendesb, 522, 173\n",
      "Train on 522 samples, validate on 173 samples\n",
      "Epoch 1/40\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.9361 - val_loss: 0.8249\n",
      "Epoch 2/40\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.9335 - val_loss: 0.8229\n",
      "Epoch 3/40\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.9308 - val_loss: 0.8206\n",
      "Epoch 4/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "522/522 [==============================] - 4s 9ms/step - loss: 0.9278 - val_loss: 0.8181\n",
      "Epoch 5/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.9240 - val_loss: 0.8143\n",
      "Epoch 6/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.9180 - val_loss: 0.8063\n",
      "Epoch 7/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.8960 - val_loss: 0.7705\n",
      "Epoch 8/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.8169 - val_loss: 0.6887\n",
      "Epoch 9/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.7202 - val_loss: 0.7429\n",
      "Epoch 10/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.6994 - val_loss: 0.6810\n",
      "Epoch 11/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.6796 - val_loss: 0.6602\n",
      "Epoch 12/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.6855 - val_loss: 0.6577\n",
      "Epoch 13/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.6449 - val_loss: 0.7088\n",
      "Epoch 14/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.6508 - val_loss: 0.6645\n",
      "Epoch 15/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.6679 - val_loss: 0.7520\n",
      "Epoch 16/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.6712 - val_loss: 0.6807\n",
      "Epoch 17/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.6313 - val_loss: 0.6370\n",
      "Epoch 18/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.5956 - val_loss: 0.6786\n",
      "Epoch 19/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.5663 - val_loss: 0.6886\n",
      "Epoch 20/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.5568 - val_loss: 0.6281\n",
      "Epoch 21/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.5229 - val_loss: 0.6492\n",
      "Epoch 22/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.4944 - val_loss: 0.6414\n",
      "Epoch 23/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.4841 - val_loss: 0.6428\n",
      "Epoch 24/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.4475 - val_loss: 0.6246\n",
      "Epoch 25/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.4509 - val_loss: 0.6126\n",
      "Epoch 26/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.4459 - val_loss: 0.5846\n",
      "Epoch 27/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.4116 - val_loss: 0.5828\n",
      "Epoch 28/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.3946 - val_loss: 0.6072\n",
      "Epoch 29/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.3696 - val_loss: 0.5935\n",
      "Epoch 30/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.3777 - val_loss: 0.5963\n",
      "Epoch 31/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.3541 - val_loss: 0.5671\n",
      "Epoch 32/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.3701 - val_loss: 0.5968\n",
      "Epoch 33/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.3692 - val_loss: 0.6465\n",
      "Epoch 34/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.3864 - val_loss: 0.5974\n",
      "Epoch 35/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.3459 - val_loss: 0.6053\n",
      "Epoch 36/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.3631 - val_loss: 0.6350\n",
      "Epoch 37/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.3446 - val_loss: 0.6147\n",
      "Epoch 38/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.2874 - val_loss: 0.5798\n",
      "Epoch 39/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.2938 - val_loss: 0.5989\n",
      "Epoch 40/40\n",
      "522/522 [==============================] - 5s 9ms/step - loss: 0.2752 - val_loss: 0.5935\n",
      "springxd, 2116, 705\n",
      "Train on 2116 samples, validate on 705 samples\n",
      "Epoch 1/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 2.4799 - val_loss: 2.4710\n",
      "Epoch 2/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.9625 - val_loss: 1.7979\n",
      "Epoch 3/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.8112 - val_loss: 1.8077\n",
      "Epoch 4/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.7838 - val_loss: 1.8031\n",
      "Epoch 5/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.7713 - val_loss: 1.7733\n",
      "Epoch 6/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.7525 - val_loss: 1.7402\n",
      "Epoch 7/40\n",
      "2116/2116 [==============================] - 20s 9ms/step - loss: 1.7054 - val_loss: 1.7508\n",
      "Epoch 8/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.6691 - val_loss: 1.6927\n",
      "Epoch 9/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.6194 - val_loss: 1.7153\n",
      "Epoch 10/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.5919 - val_loss: 1.7279\n",
      "Epoch 11/40\n",
      "2116/2116 [==============================] - 20s 9ms/step - loss: 1.4965 - val_loss: 1.6766\n",
      "Epoch 12/40\n",
      "2116/2116 [==============================] - 20s 9ms/step - loss: 1.4425 - val_loss: 1.7386\n",
      "Epoch 13/40\n",
      "2116/2116 [==============================] - 20s 9ms/step - loss: 1.3664 - val_loss: 1.6418\n",
      "Epoch 14/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.3272 - val_loss: 1.6577\n",
      "Epoch 15/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.2901 - val_loss: 1.6720\n",
      "Epoch 16/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.2144 - val_loss: 1.6655\n",
      "Epoch 17/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.1850 - val_loss: 1.8484\n",
      "Epoch 18/40\n",
      "2116/2116 [==============================] - 20s 9ms/step - loss: 1.1200 - val_loss: 1.7471\n",
      "Epoch 19/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.0499 - val_loss: 1.6976\n",
      "Epoch 20/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.9867 - val_loss: 1.7177\n",
      "Epoch 21/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.9670 - val_loss: 1.8839\n",
      "Epoch 22/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.9409 - val_loss: 1.8282\n",
      "Epoch 23/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.9249 - val_loss: 1.7556\n",
      "Epoch 24/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.8194 - val_loss: 1.8160\n",
      "Epoch 25/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.8475 - val_loss: 1.8042\n",
      "Epoch 00025: early stopping\n",
      "mulestudio, 440, 146\n",
      "Train on 440 samples, validate on 146 samples\n",
      "Epoch 1/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.3762 - val_loss: 5.6512\n",
      "Epoch 2/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.3631 - val_loss: 5.6365\n",
      "Epoch 3/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.3484 - val_loss: 5.6195\n",
      "Epoch 4/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.3289 - val_loss: 5.5911\n",
      "Epoch 5/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.2845 - val_loss: 5.5089\n",
      "Epoch 6/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.1510 - val_loss: 5.2734\n",
      "Epoch 7/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 3.7915 - val_loss: 4.6590\n",
      "Epoch 8/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 3.1029 - val_loss: 3.7861\n",
      "Epoch 9/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5877 - val_loss: 3.2741\n",
      "Epoch 10/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5152 - val_loss: 3.3304\n",
      "Epoch 11/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5170 - val_loss: 3.2935\n",
      "Epoch 12/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5275 - val_loss: 3.3013\n",
      "Epoch 13/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4976 - val_loss: 3.2816\n",
      "Epoch 14/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4826 - val_loss: 3.2866\n",
      "Epoch 15/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4698 - val_loss: 3.2965\n",
      "Epoch 16/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4558 - val_loss: 3.4070\n",
      "Epoch 17/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4171 - val_loss: 3.3010\n",
      "Epoch 18/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4529 - val_loss: 3.2711\n",
      "Epoch 19/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4316 - val_loss: 3.2996\n",
      "Epoch 20/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.3773 - val_loss: 3.3115\n",
      "Epoch 21/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.3026 - val_loss: 3.2495\n",
      "Epoch 22/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.2467 - val_loss: 3.2818\n",
      "Epoch 23/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.1834 - val_loss: 3.2462\n",
      "Epoch 24/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.0739 - val_loss: 3.3268\n",
      "Epoch 25/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.9762 - val_loss: 3.4777\n",
      "Epoch 26/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.7497 - val_loss: 3.3211\n",
      "Epoch 27/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.7319 - val_loss: 3.4837\n",
      "Epoch 28/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.6253 - val_loss: 3.3860\n",
      "Epoch 29/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.4945 - val_loss: 3.4815\n",
      "Epoch 30/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.4388 - val_loss: 3.4639\n",
      "Epoch 31/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.4401 - val_loss: 3.6090\n",
      "Epoch 32/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.4323 - val_loss: 3.3899\n",
      "Epoch 33/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.3484 - val_loss: 3.5600\n",
      "Epoch 34/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.2970 - val_loss: 3.4140\n",
      "Epoch 35/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.2490 - val_loss: 3.3732\n",
      "Epoch 00035: early stopping\n",
      "moodle, 700, 233\n",
      "Train on 700 samples, validate on 233 samples\n",
      "Epoch 1/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.8459 - val_loss: 13.9688\n",
      "Epoch 2/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.8236 - val_loss: 13.9438\n",
      "Epoch 3/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.7978 - val_loss: 13.9109\n",
      "Epoch 4/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.7411 - val_loss: 13.7924\n",
      "Epoch 5/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.4921 - val_loss: 13.2729\n",
      "Epoch 6/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 11.6397 - val_loss: 11.7648\n",
      "Epoch 7/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 10.1191 - val_loss: 10.0973\n",
      "Epoch 8/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 9.5338 - val_loss: 9.9087\n",
      "Epoch 9/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.4813 - val_loss: 9.8958\n",
      "Epoch 10/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.4293 - val_loss: 9.8958\n",
      "Epoch 11/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.3651 - val_loss: 9.9180\n",
      "Epoch 12/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.1999 - val_loss: 9.8574\n",
      "Epoch 13/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.0082 - val_loss: 9.8915\n",
      "Epoch 14/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.7683 - val_loss: 10.2775\n",
      "Epoch 15/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.5886 - val_loss: 9.9881\n",
      "Epoch 16/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.5299 - val_loss: 10.4971\n",
      "Epoch 17/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.5201 - val_loss: 9.7209\n",
      "Epoch 18/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.5499 - val_loss: 9.9409\n",
      "Epoch 19/40\n",
      "700/700 [==============================] - 7s 10ms/step - loss: 8.5119 - val_loss: 9.6911\n",
      "Epoch 20/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.1529 - val_loss: 9.7423\n",
      "Epoch 21/40\n",
      "700/700 [==============================] - 7s 9ms/step - loss: 7.9319 - val_loss: 9.4286\n",
      "Epoch 22/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 7.5517 - val_loss: 9.3999\n",
      "Epoch 23/40\n",
      "700/700 [==============================] - 7s 9ms/step - loss: 7.3009 - val_loss: 9.4473\n",
      "Epoch 24/40\n",
      "700/700 [==============================] - 7s 9ms/step - loss: 7.1677 - val_loss: 9.4259\n",
      "Epoch 25/40\n",
      "700/700 [==============================] - 7s 10ms/step - loss: 6.8484 - val_loss: 9.6658\n",
      "Epoch 26/40\n",
      "700/700 [==============================] - 7s 10ms/step - loss: 6.3935 - val_loss: 9.6801\n",
      "Epoch 27/40\n",
      "700/700 [==============================] - 7s 10ms/step - loss: 6.4650 - val_loss: 9.8917\n",
      "Epoch 28/40\n",
      "700/700 [==============================] - 7s 10ms/step - loss: 6.2996 - val_loss: 9.6795\n",
      "Epoch 29/40\n",
      "700/700 [==============================] - 7s 9ms/step - loss: 5.9311 - val_loss: 9.8456\n",
      "Epoch 30/40\n",
      "700/700 [==============================] - 7s 10ms/step - loss: 5.7192 - val_loss: 9.9530\n",
      "Epoch 31/40\n",
      "700/700 [==============================] - 7s 9ms/step - loss: 5.4922 - val_loss: 10.0053\n",
      "Epoch 32/40\n",
      "700/700 [==============================] - 7s 9ms/step - loss: 5.1308 - val_loss: 10.0868\n",
      "Epoch 33/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 5.0810 - val_loss: 9.6913\n",
      "Epoch 34/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 4.7720 - val_loss: 9.8564\n",
      "Epoch 00034: early stopping\n",
      "jirasoftware, 212, 70\n",
      "Train on 212 samples, validate on 70 samples\n",
      "Epoch 1/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4717 - val_loss: 2.0997\n",
      "Epoch 2/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4698 - val_loss: 2.0964\n",
      "Epoch 3/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4645 - val_loss: 2.0922\n",
      "Epoch 4/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4584 - val_loss: 2.0876\n",
      "Epoch 5/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4522 - val_loss: 2.0828\n",
      "Epoch 6/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4455 - val_loss: 2.0779\n",
      "Epoch 7/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4387 - val_loss: 2.0727\n",
      "Epoch 8/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4312 - val_loss: 2.0668\n",
      "Epoch 9/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4221 - val_loss: 2.0588\n",
      "Epoch 10/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4081 - val_loss: 2.0451\n",
      "Epoch 11/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.3841 - val_loss: 2.0183\n",
      "Epoch 12/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.3385 - val_loss: 1.9726\n",
      "Epoch 13/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.2609 - val_loss: 1.8958\n",
      "Epoch 14/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.1255 - val_loss: 1.7690\n",
      "Epoch 15/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.9037 - val_loss: 1.5659\n",
      "Epoch 16/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.6392 - val_loss: 1.4901\n",
      "Epoch 17/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.3976 - val_loss: 1.4817\n",
      "Epoch 18/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.2164 - val_loss: 1.7396\n",
      "Epoch 19/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.2467 - val_loss: 1.9594\n",
      "Epoch 20/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1379 - val_loss: 2.1006\n",
      "Epoch 21/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1429 - val_loss: 2.1962\n",
      "Epoch 22/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1915 - val_loss: 2.0945\n",
      "Epoch 23/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1842 - val_loss: 1.9890\n",
      "Epoch 24/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1240 - val_loss: 1.9908\n",
      "Epoch 25/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1514 - val_loss: 2.0572\n",
      "Epoch 26/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1704 - val_loss: 2.0601\n",
      "Epoch 27/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.0925 - val_loss: 2.0435\n",
      "Epoch 28/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1379 - val_loss: 1.9678\n",
      "Epoch 29/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1597 - val_loss: 1.9682\n",
      "Epoch 00029: early stopping\n",
      "duracloud, 400, 133\n",
      "Train on 400 samples, validate on 133 samples\n",
      "Epoch 1/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9276 - val_loss: 0.6993\n",
      "Epoch 2/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 3/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 4/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 5/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 6/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 7/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 8/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 9/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 10/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 11/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 12/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 13/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 14/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 00014: early stopping\n",
      "titanium, 1351, 450\n",
      "Train on 1351 samples, validate on 450 samples\n",
      "Epoch 1/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 5.0851 - val_loss: 4.4855\n",
      "Epoch 2/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.7398 - val_loss: 3.1604\n",
      "Epoch 3/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.2569 - val_loss: 2.3251\n",
      "Epoch 4/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1364 - val_loss: 2.3155\n",
      "Epoch 5/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1258 - val_loss: 2.3011\n",
      "Epoch 6/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1400 - val_loss: 2.3652\n",
      "Epoch 7/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.1007 - val_loss: 2.3143\n",
      "Epoch 8/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.1133 - val_loss: 2.3019\n",
      "Epoch 9/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.0765 - val_loss: 2.2852\n",
      "Epoch 10/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.0560 - val_loss: 2.2906\n",
      "Epoch 11/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.0496 - val_loss: 2.3319\n",
      "Epoch 12/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.9456 - val_loss: 2.3497\n",
      "Epoch 13/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.9182 - val_loss: 2.3837\n",
      "Epoch 14/40\n",
      "1351/1351 [==============================] - 13s 9ms/step - loss: 2.7356 - val_loss: 2.4102\n",
      "Epoch 15/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.6102 - val_loss: 2.6232\n",
      "Epoch 16/40\n",
      "1351/1351 [==============================] - 13s 9ms/step - loss: 2.4152 - val_loss: 2.4783\n",
      "Epoch 17/40\n",
      "1351/1351 [==============================] - 13s 9ms/step - loss: 2.3424 - val_loss: 2.4223\n",
      "Epoch 18/40\n",
      "1351/1351 [==============================] - 13s 9ms/step - loss: 2.2735 - val_loss: 2.4953\n",
      "Epoch 19/40\n",
      "1351/1351 [==============================] - 13s 9ms/step - loss: 2.1052 - val_loss: 2.5322\n",
      "Epoch 20/40\n",
      "1351/1351 [==============================] - 13s 9ms/step - loss: 1.9865 - val_loss: 2.6011\n",
      "Epoch 21/40\n",
      "1351/1351 [==============================] - 13s 9ms/step - loss: 1.9468 - val_loss: 2.7568\n",
      "Epoch 00021: early stopping\n",
      "aptanastudio, 499, 165\n",
      "Train on 499 samples, validate on 165 samples\n",
      "Epoch 1/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.1486 - val_loss: 7.3705\n",
      "Epoch 2/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.1359 - val_loss: 7.3511\n",
      "Epoch 3/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.1201 - val_loss: 7.3219\n",
      "Epoch 4/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.0839 - val_loss: 7.2190\n",
      "Epoch 5/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 5.9269 - val_loss: 6.8082\n",
      "Epoch 6/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 5.4228 - val_loss: 5.4380\n",
      "Epoch 7/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 4.3370 - val_loss: 3.2336\n",
      "Epoch 8/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 3.7051 - val_loss: 2.8185\n",
      "Epoch 9/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.5901 - val_loss: 2.9814\n",
      "Epoch 10/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.3294 - val_loss: 3.0703\n",
      "Epoch 11/40\n",
      "499/499 [==============================] - 5s 9ms/step - loss: 3.2966 - val_loss: 2.7062\n",
      "Epoch 12/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.2797 - val_loss: 2.8118\n",
      "Epoch 13/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.2872 - val_loss: 2.8634\n",
      "Epoch 14/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.1138 - val_loss: 2.7828\n",
      "Epoch 15/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.1742 - val_loss: 2.8863\n",
      "Epoch 16/40\n",
      "499/499 [==============================] - 5s 9ms/step - loss: 3.1558 - val_loss: 2.9104\n",
      "Epoch 17/40\n",
      "499/499 [==============================] - 5s 9ms/step - loss: 3.0969 - val_loss: 2.7674\n",
      "Epoch 18/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.1196 - val_loss: 3.2266\n",
      "Epoch 19/40\n",
      "499/499 [==============================] - 5s 9ms/step - loss: 3.0976 - val_loss: 2.9227\n",
      "Epoch 20/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 2.9931 - val_loss: 2.8193\n",
      "Epoch 21/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.0052 - val_loss: 3.2723\n",
      "Epoch 22/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 2.8733 - val_loss: 2.9370\n",
      "Epoch 23/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 2.9012 - val_loss: 3.3190\n",
      "Epoch 00023: early stopping\n",
      "appceleratorstudio, 1753, 583\n",
      "Train on 1753 samples, validate on 583 samples\n",
      "Epoch 1/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 4.4103 - val_loss: 3.7406\n",
      "Epoch 2/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 4.1946 - val_loss: 2.7530\n",
      "Epoch 3/40\n",
      "1753/1753 [==============================] - 14s 8ms/step - loss: 2.3947 - val_loss: 1.3988\n",
      "Epoch 4/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0764 - val_loss: 1.4924\n",
      "Epoch 5/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0352 - val_loss: 1.5335\n",
      "Epoch 6/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0585 - val_loss: 1.5310\n",
      "Epoch 7/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0011 - val_loss: 1.5184\n",
      "Epoch 8/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.9799 - val_loss: 1.5778\n",
      "Epoch 9/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.9279 - val_loss: 1.4748\n",
      "Epoch 10/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.8689 - val_loss: 1.7724\n",
      "Epoch 11/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.7109 - val_loss: 1.8853\n",
      "Epoch 12/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.6676 - val_loss: 1.7926\n",
      "Epoch 13/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.5402 - val_loss: 1.7650\n",
      "Epoch 14/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.5205 - val_loss: 1.7785\n",
      "Epoch 15/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.4236 - val_loss: 2.2002\n",
      "Epoch 00015: early stopping\n",
      "mesos, 1008, 336\n",
      "Train on 1008 samples, validate on 336 samples\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.8418 - val_loss: 1.5559\n",
      "Epoch 2/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.8203 - val_loss: 1.5314\n",
      "Epoch 3/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.7450 - val_loss: 1.3689\n",
      "Epoch 4/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.3516 - val_loss: 1.1663\n",
      "Epoch 5/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.2291 - val_loss: 1.1493\n",
      "Epoch 6/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.2109 - val_loss: 1.1199\n",
      "Epoch 7/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.2053 - val_loss: 1.1299\n",
      "Epoch 8/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1650 - val_loss: 1.1260\n",
      "Epoch 9/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1618 - val_loss: 1.1385\n",
      "Epoch 10/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1522 - val_loss: 1.1163\n",
      "Epoch 11/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1288 - val_loss: 1.1484\n",
      "Epoch 12/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.0930 - val_loss: 1.1149\n",
      "Epoch 13/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.0604 - val_loss: 1.1191\n",
      "Epoch 14/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.0672 - val_loss: 1.1320\n",
      "Epoch 15/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.0416 - val_loss: 1.1378\n",
      "Epoch 16/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.9900 - val_loss: 1.1526\n",
      "Epoch 17/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.9628 - val_loss: 1.1457\n",
      "Epoch 18/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.9239 - val_loss: 1.1976\n",
      "Epoch 19/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.8661 - val_loss: 1.2100\n",
      "Epoch 20/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.7955 - val_loss: 1.2578\n",
      "Epoch 21/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.7635 - val_loss: 1.1844\n",
      "Epoch 22/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.7128 - val_loss: 1.1735\n",
      "Epoch 23/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.6861 - val_loss: 1.2013\n",
      "Epoch 24/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.6491 - val_loss: 1.2499\n",
      "Epoch 00024: early stopping\n",
      "springxd, 2116, 705\n",
      "Train on 2116 samples, validate on 705 samples\n",
      "Epoch 1/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 2.4819 - val_loss: 2.4932\n",
      "Epoch 2/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.9748 - val_loss: 1.8677\n",
      "Epoch 3/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.8021 - val_loss: 1.7968\n",
      "Epoch 4/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.7707 - val_loss: 1.7920\n",
      "Epoch 5/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.7675 - val_loss: 1.9439\n",
      "Epoch 6/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.7256 - val_loss: 1.7387\n",
      "Epoch 7/40\n",
      "2116/2116 [==============================] - 20s 9ms/step - loss: 1.6575 - val_loss: 1.7301\n",
      "Epoch 8/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.6126 - val_loss: 1.7158\n",
      "Epoch 9/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.6260 - val_loss: 1.7666\n",
      "Epoch 10/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.5459 - val_loss: 1.7230\n",
      "Epoch 11/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.4694 - val_loss: 1.6987\n",
      "Epoch 12/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.4347 - val_loss: 1.7177\n",
      "Epoch 13/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.3561 - val_loss: 1.7896\n",
      "Epoch 14/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.2952 - val_loss: 1.7012\n",
      "Epoch 15/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.2594 - val_loss: 1.8767\n",
      "Epoch 16/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.1768 - val_loss: 1.7672\n",
      "Epoch 17/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.1196 - val_loss: 1.8206\n",
      "Epoch 18/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.0719 - val_loss: 1.7831\n",
      "Epoch 19/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 0.9995 - val_loss: 1.8743\n",
      "Epoch 20/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 0.9402 - val_loss: 1.8363\n",
      "Epoch 21/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 0.9017 - val_loss: 1.8128\n",
      "Epoch 22/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 0.8637 - val_loss: 1.8443\n",
      "Epoch 23/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 0.8244 - val_loss: 1.8719\n",
      "Epoch 00023: early stopping\n",
      "mulestudio, 440, 146\n",
      "Train on 440 samples, validate on 146 samples\n",
      "Epoch 1/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.3757 - val_loss: 5.6499\n",
      "Epoch 2/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.3609 - val_loss: 5.6331\n",
      "Epoch 3/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.3437 - val_loss: 5.6112\n",
      "Epoch 4/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.3163 - val_loss: 5.5677\n",
      "Epoch 5/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.2423 - val_loss: 5.4233\n",
      "Epoch 6/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.0000 - val_loss: 4.9702\n",
      "Epoch 7/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 3.3438 - val_loss: 3.9479\n",
      "Epoch 8/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.6803 - val_loss: 3.3016\n",
      "Epoch 9/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.5582 - val_loss: 3.3774\n",
      "Epoch 10/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.5393 - val_loss: 3.2994\n",
      "Epoch 11/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5057 - val_loss: 3.3207\n",
      "Epoch 12/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5144 - val_loss: 3.2943\n",
      "Epoch 13/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4580 - val_loss: 3.3820\n",
      "Epoch 14/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4524 - val_loss: 3.3011\n",
      "Epoch 15/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4437 - val_loss: 3.2914\n",
      "Epoch 16/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4739 - val_loss: 3.3274\n",
      "Epoch 17/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4185 - val_loss: 3.3122\n",
      "Epoch 18/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.3644 - val_loss: 3.2504\n",
      "Epoch 19/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.3765 - val_loss: 3.3785\n",
      "Epoch 20/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.3292 - val_loss: 3.4208\n",
      "Epoch 21/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.2312 - val_loss: 3.2553\n",
      "Epoch 22/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.1764 - val_loss: 3.2371\n",
      "Epoch 23/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.1169 - val_loss: 3.2686\n",
      "Epoch 24/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.0208 - val_loss: 3.4788\n",
      "Epoch 25/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.0211 - val_loss: 3.3168\n",
      "Epoch 26/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.9146 - val_loss: 3.3553\n",
      "Epoch 27/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.7902 - val_loss: 3.4050\n",
      "Epoch 28/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.7131 - val_loss: 3.3826\n",
      "Epoch 29/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.6291 - val_loss: 3.3160\n",
      "Epoch 30/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.5495 - val_loss: 3.5207\n",
      "Epoch 31/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.5056 - val_loss: 3.3877\n",
      "Epoch 32/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440/440 [==============================] - 4s 9ms/step - loss: 1.4061 - val_loss: 3.4321\n",
      "Epoch 33/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.4469 - val_loss: 3.4090\n",
      "Epoch 34/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.3833 - val_loss: 3.5263\n",
      "Epoch 00034: early stopping\n",
      "moodle, 700, 233\n",
      "Train on 700 samples, validate on 233 samples\n",
      "Epoch 1/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.8462 - val_loss: 13.9697\n",
      "Epoch 2/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.8253 - val_loss: 13.9474\n",
      "Epoch 3/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.8044 - val_loss: 13.9252\n",
      "Epoch 4/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.7835 - val_loss: 13.9031\n",
      "Epoch 5/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.7628 - val_loss: 13.8809\n",
      "Epoch 6/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.7420 - val_loss: 13.8589\n",
      "Epoch 7/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.7213 - val_loss: 13.8368\n",
      "Epoch 8/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.7006 - val_loss: 13.8148\n",
      "Epoch 9/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.6799 - val_loss: 13.7928\n",
      "Epoch 10/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.6592 - val_loss: 13.7708\n",
      "Epoch 11/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.6385 - val_loss: 13.7488\n",
      "Epoch 12/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.6178 - val_loss: 13.7268\n",
      "Epoch 13/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.5971 - val_loss: 13.7048\n",
      "Epoch 14/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.5764 - val_loss: 13.6828\n",
      "Epoch 15/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.5558 - val_loss: 13.6608\n",
      "Epoch 16/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.5351 - val_loss: 13.6388\n",
      "Epoch 17/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.5145 - val_loss: 13.6168\n",
      "Epoch 18/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.4938 - val_loss: 13.5948\n",
      "Epoch 19/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.4731 - val_loss: 13.5730\n",
      "Epoch 20/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.4525 - val_loss: 13.5509\n",
      "Epoch 21/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.4318 - val_loss: 13.5290\n",
      "Epoch 22/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.4112 - val_loss: 13.5069\n",
      "Epoch 23/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.3905 - val_loss: 13.4849\n",
      "Epoch 24/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.3698 - val_loss: 13.4630\n",
      "Epoch 25/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.3492 - val_loss: 13.4410\n",
      "Epoch 26/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.3286 - val_loss: 13.4190\n",
      "Epoch 27/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.3079 - val_loss: 13.3970\n",
      "Epoch 28/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.2872 - val_loss: 13.3751\n",
      "Epoch 29/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.2666 - val_loss: 13.3532\n",
      "Epoch 30/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.2460 - val_loss: 13.3312\n",
      "Epoch 31/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.2253 - val_loss: 13.3093\n",
      "Epoch 32/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.2047 - val_loss: 13.2873\n",
      "Epoch 33/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.1840 - val_loss: 13.2653\n",
      "Epoch 34/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.1634 - val_loss: 13.2433\n",
      "Epoch 35/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.1427 - val_loss: 13.2214\n",
      "Epoch 36/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.1222 - val_loss: 13.1993\n",
      "Epoch 37/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.1014 - val_loss: 13.1775\n",
      "Epoch 38/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.0808 - val_loss: 13.1555\n",
      "Epoch 39/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.0602 - val_loss: 13.1336\n",
      "Epoch 40/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.0395 - val_loss: 13.1116\n",
      "jirasoftware, 212, 70\n",
      "Train on 212 samples, validate on 70 samples\n",
      "Epoch 1/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.4694 - val_loss: 2.0958\n",
      "Epoch 2/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4636 - val_loss: 2.0915\n",
      "Epoch 3/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.4574 - val_loss: 2.0869\n",
      "Epoch 4/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.4510 - val_loss: 2.0820\n",
      "Epoch 5/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4441 - val_loss: 2.0763\n",
      "Epoch 6/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4353 - val_loss: 2.0687\n",
      "Epoch 7/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4231 - val_loss: 2.0563\n",
      "Epoch 8/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4011 - val_loss: 2.0331\n",
      "Epoch 9/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.3596 - val_loss: 1.9894\n",
      "Epoch 10/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.2828 - val_loss: 1.9116\n",
      "Epoch 11/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.1442 - val_loss: 1.7764\n",
      "Epoch 12/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.9150 - val_loss: 1.5476\n",
      "Epoch 13/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.6293 - val_loss: 1.4806\n",
      "Epoch 14/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.3392 - val_loss: 1.5742\n",
      "Epoch 15/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.2215 - val_loss: 1.8873\n",
      "Epoch 16/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1466 - val_loss: 2.0926\n",
      "Epoch 17/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1803 - val_loss: 2.1121\n",
      "Epoch 18/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1695 - val_loss: 2.0566\n",
      "Epoch 19/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1592 - val_loss: 1.9441\n",
      "Epoch 20/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.2024 - val_loss: 1.9147\n",
      "Epoch 21/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1899 - val_loss: 1.9888\n",
      "Epoch 22/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1880 - val_loss: 2.0182\n",
      "Epoch 23/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1612 - val_loss: 2.0580\n",
      "Epoch 24/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1556 - val_loss: 1.9806\n",
      "Epoch 25/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1450 - val_loss: 1.9937\n",
      "Epoch 00025: early stopping\n",
      "duracloud, 400, 133\n",
      "Train on 400 samples, validate on 133 samples\n",
      "Epoch 1/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9277 - val_loss: 0.6993\n",
      "Epoch 2/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 3/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 4/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 5/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 6/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 7/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 8/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 9/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 10/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 11/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 12/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 13/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 14/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 00014: early stopping\n",
      "titanium, 1351, 450\n",
      "Train on 1351 samples, validate on 450 samples\n",
      "Epoch 1/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 5.0892 - val_loss: 4.5032\n",
      "Epoch 2/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.9830 - val_loss: 4.1541\n",
      "Epoch 3/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.8712 - val_loss: 2.3556\n",
      "Epoch 4/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1383 - val_loss: 2.2941\n",
      "Epoch 5/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1291 - val_loss: 2.3105\n",
      "Epoch 6/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1210 - val_loss: 2.2878\n",
      "Epoch 7/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1344 - val_loss: 2.3335\n",
      "Epoch 8/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1057 - val_loss: 2.3142\n",
      "Epoch 9/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1186 - val_loss: 2.3160\n",
      "Epoch 10/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1101 - val_loss: 2.3250\n",
      "Epoch 11/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.0785 - val_loss: 2.3280\n",
      "Epoch 12/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.1126 - val_loss: 2.3523\n",
      "Epoch 13/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.0609 - val_loss: 2.3219\n",
      "Epoch 14/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.9826 - val_loss: 2.3086\n",
      "Epoch 15/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.8226 - val_loss: 2.3388\n",
      "Epoch 16/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.6416 - val_loss: 2.4255\n",
      "Epoch 17/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.5466 - val_loss: 2.3964\n",
      "Epoch 18/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.3487 - val_loss: 2.5184\n",
      "Epoch 00018: early stopping\n",
      "aptanastudio, 499, 165\n",
      "Train on 499 samples, validate on 165 samples\n",
      "Epoch 1/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 6.1490 - val_loss: 7.3710\n",
      "Epoch 2/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 6.1364 - val_loss: 7.3524\n",
      "Epoch 3/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.1221 - val_loss: 7.3286\n",
      "Epoch 4/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.0992 - val_loss: 7.2782\n",
      "Epoch 5/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 6.0347 - val_loss: 7.1210\n",
      "Epoch 6/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 5.8392 - val_loss: 6.6567\n",
      "Epoch 7/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 5.3618 - val_loss: 5.4590\n",
      "Epoch 8/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 4.4471 - val_loss: 3.5532\n",
      "Epoch 9/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 3.7131 - val_loss: 2.8820\n",
      "Epoch 10/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.4366 - val_loss: 2.6684\n",
      "Epoch 11/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.2735 - val_loss: 2.7885\n",
      "Epoch 12/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.2735 - val_loss: 2.7748\n",
      "Epoch 13/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.2311 - val_loss: 3.5928\n",
      "Epoch 14/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.9607 - val_loss: 3.3164\n",
      "Epoch 15/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.2355 - val_loss: 3.0682\n",
      "Epoch 16/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.3346 - val_loss: 2.8321\n",
      "Epoch 17/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.1299 - val_loss: 2.9184\n",
      "Epoch 18/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.2031 - val_loss: 2.8403\n",
      "Epoch 19/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.1991 - val_loss: 2.8953\n",
      "Epoch 20/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.1360 - val_loss: 2.9531\n",
      "Epoch 21/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.0979 - val_loss: 2.9061\n",
      "Epoch 22/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.0619 - val_loss: 2.8435\n",
      "Epoch 00022: early stopping\n",
      "appceleratorstudio, 1753, 583\n",
      "Train on 1753 samples, validate on 583 samples\n",
      "Epoch 1/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 4.4033 - val_loss: 3.6913\n",
      "Epoch 2/40\n",
      "1753/1753 [==============================] - 14s 8ms/step - loss: 3.5643 - val_loss: 1.5376\n",
      "Epoch 3/40\n",
      "1753/1753 [==============================] - 14s 8ms/step - loss: 2.0804 - val_loss: 1.4109\n",
      "Epoch 4/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 2.0753 - val_loss: 1.4850\n",
      "Epoch 5/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0477 - val_loss: 1.5501\n",
      "Epoch 6/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0487 - val_loss: 1.4040\n",
      "Epoch 7/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 2.0434 - val_loss: 1.7439\n",
      "Epoch 8/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 2.0299 - val_loss: 1.4704\n",
      "Epoch 9/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0353 - val_loss: 1.4115\n",
      "Epoch 10/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 2.0332 - val_loss: 1.5412\n",
      "Epoch 11/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0261 - val_loss: 1.5100\n",
      "Epoch 12/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.9872 - val_loss: 1.6100\n",
      "Epoch 13/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.9212 - val_loss: 1.9230\n",
      "Epoch 14/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.8577 - val_loss: 2.0550\n",
      "Epoch 15/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.7821 - val_loss: 1.5431\n",
      "Epoch 16/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.6035 - val_loss: 1.6566\n",
      "Epoch 17/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.5427 - val_loss: 1.8041\n",
      "Epoch 18/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.4954 - val_loss: 1.7579\n",
      "Epoch 00018: early stopping\n",
      "mesos, 1008, 336\n",
      "Train on 1008 samples, validate on 336 samples\n",
      "Epoch 1/40\n",
      "1008/1008 [==============================] - 8s 8ms/step - loss: 1.8422 - val_loss: 1.5575\n",
      "Epoch 2/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.8254 - val_loss: 1.5435\n",
      "Epoch 3/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.8090 - val_loss: 1.5295\n",
      "Epoch 4/40\n",
      "1008/1008 [==============================] - 8s 8ms/step - loss: 1.7923 - val_loss: 1.5159\n",
      "Epoch 5/40\n",
      "1008/1008 [==============================] - 8s 8ms/step - loss: 1.7758 - val_loss: 1.5022\n",
      "Epoch 6/40\n",
      "1008/1008 [==============================] - 8s 8ms/step - loss: 1.7593 - val_loss: 1.4882\n",
      "Epoch 7/40\n",
      "1008/1008 [==============================] - 8s 8ms/step - loss: 1.7427 - val_loss: 1.4745\n",
      "Epoch 8/40\n",
      "1008/1008 [==============================] - 8s 8ms/step - loss: 1.7262 - val_loss: 1.4607\n",
      "Epoch 9/40\n",
      "1008/1008 [==============================] - 8s 8ms/step - loss: 1.7096 - val_loss: 1.4470\n",
      "Epoch 10/40\n",
      "1008/1008 [==============================] - 8s 8ms/step - loss: 1.6930 - val_loss: 1.4331\n",
      "Epoch 11/40\n",
      "1008/1008 [==============================] - 8s 8ms/step - loss: 1.6765 - val_loss: 1.4194\n",
      "Epoch 12/40\n",
      "1008/1008 [==============================] - 8s 8ms/step - loss: 1.6599 - val_loss: 1.4057\n",
      "Epoch 13/40\n",
      "1008/1008 [==============================] - 8s 8ms/step - loss: 1.6434 - val_loss: 1.3918\n",
      "Epoch 14/40\n",
      "1008/1008 [==============================] - 8s 8ms/step - loss: 1.6267 - val_loss: 1.3784\n",
      "Epoch 15/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008/1008 [==============================] - 8s 8ms/step - loss: 1.6103 - val_loss: 1.3643\n",
      "Epoch 16/40\n",
      "1008/1008 [==============================] - 8s 8ms/step - loss: 1.5937 - val_loss: 1.3502\n",
      "Epoch 17/40\n",
      "1008/1008 [==============================] - 9s 8ms/step - loss: 1.5769 - val_loss: 1.3365\n",
      "Epoch 18/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.5604 - val_loss: 1.3226\n",
      "Epoch 19/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.5438 - val_loss: 1.3089\n",
      "Epoch 20/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.5272 - val_loss: 1.2951\n",
      "Epoch 21/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.5104 - val_loss: 1.2813\n",
      "Epoch 22/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.4941 - val_loss: 1.2670\n",
      "Epoch 23/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.4772 - val_loss: 1.2532\n",
      "Epoch 24/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.4606 - val_loss: 1.2396\n",
      "Epoch 25/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.4441 - val_loss: 1.2258\n",
      "Epoch 26/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.4276 - val_loss: 1.2119\n",
      "Epoch 27/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.4110 - val_loss: 1.1982\n",
      "Epoch 28/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.3944 - val_loss: 1.1846\n",
      "Epoch 29/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.3779 - val_loss: 1.1707\n",
      "Epoch 30/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.3613 - val_loss: 1.1567\n",
      "Epoch 31/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.3447 - val_loss: 1.1429\n",
      "Epoch 32/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.3283 - val_loss: 1.1294\n",
      "Epoch 33/40\n",
      "1008/1008 [==============================] - 9s 8ms/step - loss: 1.3148 - val_loss: 1.1253\n",
      "Epoch 34/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.3128 - val_loss: 1.1255\n",
      "Epoch 35/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.3120 - val_loss: 1.1258\n",
      "Epoch 36/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.3111 - val_loss: 1.1260\n",
      "Epoch 37/40\n",
      "1008/1008 [==============================] - 9s 8ms/step - loss: 1.3103 - val_loss: 1.1262\n",
      "Epoch 38/40\n",
      "1008/1008 [==============================] - 9s 8ms/step - loss: 1.3094 - val_loss: 1.1264\n",
      "Epoch 39/40\n",
      "1008/1008 [==============================] - 9s 8ms/step - loss: 1.3086 - val_loss: 1.1266\n",
      "Epoch 40/40\n",
      "1008/1008 [==============================] - 9s 8ms/step - loss: 1.3076 - val_loss: 1.1269\n",
      "springxd, 2116, 705\n",
      "Train on 2116 samples, validate on 705 samples\n",
      "Epoch 1/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 2.4851 - val_loss: 2.5280\n",
      "Epoch 2/40\n",
      "2116/2116 [==============================] - 17s 8ms/step - loss: 2.0456 - val_loss: 1.8497\n",
      "Epoch 3/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.8073 - val_loss: 1.8353\n",
      "Epoch 4/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.7897 - val_loss: 2.1398\n",
      "Epoch 5/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.8295 - val_loss: 1.7966\n",
      "Epoch 6/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.7600 - val_loss: 1.7986\n",
      "Epoch 7/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.7239 - val_loss: 1.7852\n",
      "Epoch 8/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.6804 - val_loss: 1.7589\n",
      "Epoch 9/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.6331 - val_loss: 1.7304\n",
      "Epoch 10/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.5933 - val_loss: 1.7328\n",
      "Epoch 11/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.5537 - val_loss: 1.6904\n",
      "Epoch 12/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.4872 - val_loss: 1.6953\n",
      "Epoch 13/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.4342 - val_loss: 1.6970\n",
      "Epoch 14/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.4278 - val_loss: 1.6729\n",
      "Epoch 15/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.3937 - val_loss: 1.7138\n",
      "Epoch 16/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.3210 - val_loss: 1.8258\n",
      "Epoch 17/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.3232 - val_loss: 1.8041\n",
      "Epoch 18/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.2828 - val_loss: 1.6815\n",
      "Epoch 19/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.2158 - val_loss: 1.7389\n",
      "Epoch 20/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.1369 - val_loss: 1.7433\n",
      "Epoch 21/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.0970 - val_loss: 1.7387\n",
      "Epoch 22/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.0639 - val_loss: 1.8214\n",
      "Epoch 23/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.9974 - val_loss: 1.6947\n",
      "Epoch 24/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.9812 - val_loss: 1.7569\n",
      "Epoch 25/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.9378 - val_loss: 1.7487\n",
      "Epoch 26/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.9085 - val_loss: 1.7507\n",
      "Epoch 00026: early stopping\n",
      "mulestudio, 440, 146\n",
      "Train on 440 samples, validate on 146 samples\n",
      "Epoch 1/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.3760 - val_loss: 5.6502\n",
      "Epoch 2/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.3617 - val_loss: 5.6336\n",
      "Epoch 3/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.3426 - val_loss: 5.6060\n",
      "Epoch 4/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.2979 - val_loss: 5.5152\n",
      "Epoch 5/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.1349 - val_loss: 5.2073\n",
      "Epoch 6/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 3.6657 - val_loss: 4.3760\n",
      "Epoch 7/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.8649 - val_loss: 3.4271\n",
      "Epoch 8/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5386 - val_loss: 3.2659\n",
      "Epoch 9/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4931 - val_loss: 3.3475\n",
      "Epoch 10/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5108 - val_loss: 3.2905\n",
      "Epoch 11/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4684 - val_loss: 3.3953\n",
      "Epoch 12/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5060 - val_loss: 3.3213\n",
      "Epoch 13/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5137 - val_loss: 3.3146\n",
      "Epoch 14/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4596 - val_loss: 3.3523\n",
      "Epoch 15/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4516 - val_loss: 3.2696\n",
      "Epoch 16/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4379 - val_loss: 3.3380\n",
      "Epoch 17/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4226 - val_loss: 3.2210\n",
      "Epoch 18/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4441 - val_loss: 3.2650\n",
      "Epoch 19/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.3948 - val_loss: 3.2562\n",
      "Epoch 20/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.3932 - val_loss: 3.3168\n",
      "Epoch 21/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.3320 - val_loss: 3.4500\n",
      "Epoch 22/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.3177 - val_loss: 3.2528\n",
      "Epoch 23/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.2803 - val_loss: 3.2497\n",
      "Epoch 24/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.1448 - val_loss: 3.2218\n",
      "Epoch 25/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.0699 - val_loss: 3.2171\n",
      "Epoch 26/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.9081 - val_loss: 3.2496\n",
      "Epoch 27/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440/440 [==============================] - 4s 9ms/step - loss: 1.8255 - val_loss: 3.3074\n",
      "Epoch 28/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.6953 - val_loss: 3.3777\n",
      "Epoch 29/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.4872 - val_loss: 3.2728\n",
      "Epoch 30/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.5708 - val_loss: 3.2994\n",
      "Epoch 31/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.4465 - val_loss: 3.3419\n",
      "Epoch 32/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.3866 - val_loss: 3.3523\n",
      "Epoch 33/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.3197 - val_loss: 3.5737\n",
      "Epoch 34/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.3337 - val_loss: 3.4249\n",
      "Epoch 35/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.2638 - val_loss: 3.3636\n",
      "Epoch 36/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.1973 - val_loss: 3.3794\n",
      "Epoch 37/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.1516 - val_loss: 3.5254\n",
      "Epoch 00037: early stopping\n",
      "moodle, 700, 233\n",
      "Train on 700 samples, validate on 233 samples\n",
      "Epoch 1/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.8455 - val_loss: 13.9680\n",
      "Epoch 2/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.8223 - val_loss: 13.9409\n",
      "Epoch 3/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.7838 - val_loss: 13.8652\n",
      "Epoch 4/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.6098 - val_loss: 13.4702\n",
      "Epoch 5/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 11.8609 - val_loss: 12.0394\n",
      "Epoch 6/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 10.3567 - val_loss: 10.1487\n",
      "Epoch 7/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 9.6369 - val_loss: 9.8973\n",
      "Epoch 8/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.5449 - val_loss: 9.9330\n",
      "Epoch 9/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.5029 - val_loss: 10.0373\n",
      "Epoch 10/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.5353 - val_loss: 9.8798\n",
      "Epoch 11/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.4244 - val_loss: 9.8641\n",
      "Epoch 12/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.2943 - val_loss: 9.9492\n",
      "Epoch 13/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.2770 - val_loss: 9.7024\n",
      "Epoch 14/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.0360 - val_loss: 9.6479\n",
      "Epoch 15/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.6423 - val_loss: 9.4629\n",
      "Epoch 16/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.3598 - val_loss: 9.6444\n",
      "Epoch 17/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 7.9433 - val_loss: 9.1181\n",
      "Epoch 18/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 7.5415 - val_loss: 9.0625\n",
      "Epoch 19/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 7.3059 - val_loss: 9.2849\n",
      "Epoch 20/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 7.1514 - val_loss: 9.2160\n",
      "Epoch 21/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 6.5931 - val_loss: 9.4525\n",
      "Epoch 22/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 6.3928 - val_loss: 10.1660\n",
      "Epoch 23/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 5.9028 - val_loss: 9.2114\n",
      "Epoch 24/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 5.5052 - val_loss: 9.1471\n",
      "Epoch 25/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 5.1572 - val_loss: 9.1079\n",
      "Epoch 26/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 4.9093 - val_loss: 9.4786\n",
      "Epoch 27/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 4.6960 - val_loss: 9.4027\n",
      "Epoch 28/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 4.2830 - val_loss: 9.6347\n",
      "Epoch 29/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 4.0900 - val_loss: 9.4906\n",
      "Epoch 30/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 3.9844 - val_loss: 9.6344\n",
      "Epoch 00030: early stopping\n",
      "jirasoftware, 212, 70\n",
      "Train on 212 samples, validate on 70 samples\n",
      "Epoch 1/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4693 - val_loss: 2.0958\n",
      "Epoch 2/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.4633 - val_loss: 2.0913\n",
      "Epoch 3/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.4572 - val_loss: 2.0865\n",
      "Epoch 4/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.4502 - val_loss: 2.0814\n",
      "Epoch 5/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.4432 - val_loss: 2.0757\n",
      "Epoch 6/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4349 - val_loss: 2.0688\n",
      "Epoch 7/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4239 - val_loss: 2.0588\n",
      "Epoch 8/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4063 - val_loss: 2.0409\n",
      "Epoch 9/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.3729 - val_loss: 2.0051\n",
      "Epoch 10/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.3100 - val_loss: 1.9391\n",
      "Epoch 11/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.1982 - val_loss: 1.8257\n",
      "Epoch 12/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.0044 - val_loss: 1.6332\n",
      "Epoch 13/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.7152 - val_loss: 1.4983\n",
      "Epoch 14/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.4669 - val_loss: 1.4829\n",
      "Epoch 15/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.2530 - val_loss: 1.7804\n",
      "Epoch 16/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1677 - val_loss: 2.0242\n",
      "Epoch 17/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1553 - val_loss: 2.1853\n",
      "Epoch 18/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.2390 - val_loss: 2.0934\n",
      "Epoch 19/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1528 - val_loss: 2.0607\n",
      "Epoch 20/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1030 - val_loss: 2.0274\n",
      "Epoch 21/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.2064 - val_loss: 2.0329\n",
      "Epoch 22/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1474 - val_loss: 2.0336\n",
      "Epoch 23/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1998 - val_loss: 2.0225\n",
      "Epoch 24/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1373 - val_loss: 2.0371\n",
      "Epoch 25/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1789 - val_loss: 2.0472\n",
      "Epoch 26/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.0975 - val_loss: 2.0345\n",
      "Epoch 00026: early stopping\n",
      "duracloud, 400, 133\n",
      "Train on 400 samples, validate on 133 samples\n",
      "Epoch 1/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 2/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 3/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 4/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 5/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 6/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 7/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 8/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 9/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 10/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 11/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 12/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 13/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 00013: early stopping\n",
      "titanium, 1351, 450\n",
      "Train on 1351 samples, validate on 450 samples\n",
      "Epoch 1/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 5.0872 - val_loss: 4.4937\n",
      "Epoch 2/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.7569 - val_loss: 3.1674\n",
      "Epoch 3/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.2472 - val_loss: 2.3988\n",
      "Epoch 4/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1246 - val_loss: 2.3627\n",
      "Epoch 5/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1300 - val_loss: 2.2935\n",
      "Epoch 6/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.1041 - val_loss: 2.3413\n",
      "Epoch 7/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.1410 - val_loss: 2.3440\n",
      "Epoch 8/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.1257 - val_loss: 2.3097\n",
      "Epoch 9/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.0976 - val_loss: 2.3085\n",
      "Epoch 10/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1086 - val_loss: 2.3202\n",
      "Epoch 11/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1040 - val_loss: 2.3243\n",
      "Epoch 12/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.0985 - val_loss: 2.3941\n",
      "Epoch 13/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.0888 - val_loss: 2.3209\n",
      "Epoch 14/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.0980 - val_loss: 2.3309\n",
      "Epoch 15/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.0694 - val_loss: 2.3493\n",
      "Epoch 16/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.0556 - val_loss: 2.4264\n",
      "Epoch 17/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.9812 - val_loss: 2.3328\n",
      "Epoch 00017: early stopping\n",
      "aptanastudio, 499, 165\n",
      "Train on 499 samples, validate on 165 samples\n",
      "Epoch 1/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 6.1487 - val_loss: 7.3700\n",
      "Epoch 2/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 6.1354 - val_loss: 7.3500\n",
      "Epoch 3/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.1197 - val_loss: 7.3229\n",
      "Epoch 4/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.0890 - val_loss: 7.2472\n",
      "Epoch 5/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 5.9872 - val_loss: 6.9864\n",
      "Epoch 6/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 5.6528 - val_loss: 6.1531\n",
      "Epoch 7/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 4.8706 - val_loss: 4.2676\n",
      "Epoch 8/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 3.8737 - val_loss: 2.7211\n",
      "Epoch 9/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.4853 - val_loss: 3.1080\n",
      "Epoch 10/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.3371 - val_loss: 2.8028\n",
      "Epoch 11/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.2725 - val_loss: 2.8131\n",
      "Epoch 12/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.2374 - val_loss: 2.8340\n",
      "Epoch 13/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.2357 - val_loss: 2.7504\n",
      "Epoch 14/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.1761 - val_loss: 2.8843\n",
      "Epoch 15/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.0853 - val_loss: 2.7468\n",
      "Epoch 16/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.1060 - val_loss: 2.7633\n",
      "Epoch 17/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.0658 - val_loss: 3.0047\n",
      "Epoch 18/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 2.9637 - val_loss: 2.7637\n",
      "Epoch 19/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 2.9014 - val_loss: 2.8763\n",
      "Epoch 20/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 2.7778 - val_loss: 3.0576\n",
      "Epoch 00020: early stopping\n",
      "appceleratorstudio, 1753, 583\n",
      "Train on 1753 samples, validate on 583 samples\n",
      "Epoch 1/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 4.4040 - val_loss: 3.6872\n",
      "Epoch 2/40\n",
      "1753/1753 [==============================] - 14s 8ms/step - loss: 3.3521 - val_loss: 1.8874\n",
      "Epoch 3/40\n",
      "1753/1753 [==============================] - 14s 8ms/step - loss: 2.0767 - val_loss: 1.4312\n",
      "Epoch 4/40\n",
      "1753/1753 [==============================] - 14s 8ms/step - loss: 2.0720 - val_loss: 1.4588\n",
      "Epoch 5/40\n",
      "1753/1753 [==============================] - 14s 8ms/step - loss: 2.0562 - val_loss: 1.4549\n",
      "Epoch 6/40\n",
      "1753/1753 [==============================] - 14s 8ms/step - loss: 2.0608 - val_loss: 1.4475\n",
      "Epoch 7/40\n",
      "1753/1753 [==============================] - 14s 8ms/step - loss: 2.0387 - val_loss: 1.6238\n",
      "Epoch 8/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 2.0449 - val_loss: 1.4706\n",
      "Epoch 9/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 2.0428 - val_loss: 1.5841\n",
      "Epoch 10/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 2.0654 - val_loss: 1.7784\n",
      "Epoch 11/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 2.0145 - val_loss: 1.5475\n",
      "Epoch 12/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 1.9894 - val_loss: 1.6037\n",
      "Epoch 13/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 1.9801 - val_loss: 1.5629\n",
      "Epoch 14/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.9785 - val_loss: 1.4221\n",
      "Epoch 15/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.9047 - val_loss: 1.6046\n",
      "Epoch 16/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.8218 - val_loss: 1.6339\n",
      "Epoch 17/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.7617 - val_loss: 1.7525\n",
      "Epoch 18/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.7062 - val_loss: 1.6596\n",
      "Epoch 19/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.6090 - val_loss: 1.7574\n",
      "Epoch 20/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.5429 - val_loss: 1.7441\n",
      "Epoch 21/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.4614 - val_loss: 1.7379\n",
      "Epoch 22/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.4094 - val_loss: 1.8290\n",
      "Epoch 23/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.3380 - val_loss: 1.8457\n",
      "Epoch 24/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.3104 - val_loss: 1.7456\n",
      "Epoch 25/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.2393 - val_loss: 1.8226\n",
      "Epoch 26/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.1761 - val_loss: 1.8566\n",
      "Epoch 00026: early stopping\n",
      "mesos, 1008, 336\n",
      "Train on 1008 samples, validate on 336 samples\n",
      "Epoch 1/40\n",
      "1008/1008 [==============================] - 8s 8ms/step - loss: 1.8410 - val_loss: 1.5546\n",
      "Epoch 2/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.8155 - val_loss: 1.5218\n",
      "Epoch 3/40\n",
      "1008/1008 [==============================] - 8s 8ms/step - loss: 1.7071 - val_loss: 1.3131\n",
      "Epoch 4/40\n",
      "1008/1008 [==============================] - 8s 8ms/step - loss: 1.3063 - val_loss: 1.1502\n",
      "Epoch 5/40\n",
      "1008/1008 [==============================] - 8s 8ms/step - loss: 1.2307 - val_loss: 1.1433\n",
      "Epoch 6/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1952 - val_loss: 1.1350\n",
      "Epoch 7/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1798 - val_loss: 1.1316\n",
      "Epoch 8/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1690 - val_loss: 1.1326\n",
      "Epoch 9/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1593 - val_loss: 1.1144\n",
      "Epoch 10/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1010 - val_loss: 1.1760\n",
      "Epoch 11/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.0525 - val_loss: 1.2068\n",
      "Epoch 12/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.0213 - val_loss: 1.2379\n",
      "Epoch 13/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.9637 - val_loss: 1.1424\n",
      "Epoch 14/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.9173 - val_loss: 1.1680\n",
      "Epoch 15/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.9287 - val_loss: 1.1937\n",
      "Epoch 16/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.8167 - val_loss: 1.2317\n",
      "Epoch 17/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.7470 - val_loss: 1.2818\n",
      "Epoch 18/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.7141 - val_loss: 1.2106\n",
      "Epoch 19/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.6512 - val_loss: 1.2710\n",
      "Epoch 20/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.6305 - val_loss: 1.2434\n",
      "Epoch 21/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.6000 - val_loss: 1.2917\n",
      "Epoch 00021: early stopping\n",
      "springxd, 2116, 705\n",
      "Train on 2116 samples, validate on 705 samples\n",
      "Epoch 1/40\n",
      "2116/2116 [==============================] - 17s 8ms/step - loss: 2.4724 - val_loss: 2.4225\n",
      "Epoch 2/40\n",
      "2116/2116 [==============================] - 17s 8ms/step - loss: 1.9517 - val_loss: 1.8124\n",
      "Epoch 3/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.7945 - val_loss: 1.7906\n",
      "Epoch 4/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.7890 - val_loss: 1.8015\n",
      "Epoch 5/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.7757 - val_loss: 1.8107\n",
      "Epoch 6/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.7479 - val_loss: 1.7580\n",
      "Epoch 7/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.7382 - val_loss: 1.7602\n",
      "Epoch 8/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.7090 - val_loss: 1.7994\n",
      "Epoch 9/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.6871 - val_loss: 1.7407\n",
      "Epoch 10/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.6496 - val_loss: 1.7419\n",
      "Epoch 11/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.6073 - val_loss: 1.7026\n",
      "Epoch 12/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.5546 - val_loss: 1.7626\n",
      "Epoch 13/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.5285 - val_loss: 1.7200\n",
      "Epoch 14/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.5087 - val_loss: 1.7134\n",
      "Epoch 15/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.4661 - val_loss: 1.8378\n",
      "Epoch 16/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.4373 - val_loss: 1.7651\n",
      "Epoch 17/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.3908 - val_loss: 1.7320\n",
      "Epoch 18/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.3582 - val_loss: 1.7414\n",
      "Epoch 19/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.3147 - val_loss: 1.7183\n",
      "Epoch 20/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.2588 - val_loss: 1.7854\n",
      "Epoch 21/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.2444 - val_loss: 1.8061\n",
      "Epoch 22/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.1521 - val_loss: 1.8354\n",
      "Epoch 23/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.1020 - val_loss: 1.8550\n",
      "Epoch 00023: early stopping\n",
      "mulestudio, 440, 146\n",
      "Train on 440 samples, validate on 146 samples\n",
      "Epoch 1/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.3759 - val_loss: 5.6505\n",
      "Epoch 2/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.3625 - val_loss: 5.6355\n",
      "Epoch 3/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.3474 - val_loss: 5.6179\n",
      "Epoch 4/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.3272 - val_loss: 5.5886\n",
      "Epoch 5/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.2809 - val_loss: 5.5064\n",
      "Epoch 6/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.1535 - val_loss: 5.2859\n",
      "Epoch 7/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 3.8272 - val_loss: 4.7342\n",
      "Epoch 8/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 3.2041 - val_loss: 3.8737\n",
      "Epoch 9/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.6424 - val_loss: 3.2718\n",
      "Epoch 10/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5277 - val_loss: 3.3092\n",
      "Epoch 11/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5185 - val_loss: 3.3550\n",
      "Epoch 12/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5165 - val_loss: 3.3007\n",
      "Epoch 13/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5360 - val_loss: 3.3444\n",
      "Epoch 14/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4885 - val_loss: 3.3107\n",
      "Epoch 15/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4834 - val_loss: 3.2691\n",
      "Epoch 16/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4682 - val_loss: 3.2973\n",
      "Epoch 17/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4263 - val_loss: 3.2998\n",
      "Epoch 18/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4119 - val_loss: 3.2741\n",
      "Epoch 19/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.3937 - val_loss: 3.2849\n",
      "Epoch 20/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.3555 - val_loss: 3.2449\n",
      "Epoch 21/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.3453 - val_loss: 3.2866\n",
      "Epoch 22/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.2789 - val_loss: 3.2483\n",
      "Epoch 23/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.2746 - val_loss: 3.2717\n",
      "Epoch 24/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.2614 - val_loss: 3.3039\n",
      "Epoch 25/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.1363 - val_loss: 3.4119\n",
      "Epoch 26/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.0588 - val_loss: 3.3482\n",
      "Epoch 27/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.9652 - val_loss: 3.3536\n",
      "Epoch 28/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.8954 - val_loss: 3.4767\n",
      "Epoch 29/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.7142 - val_loss: 3.4906\n",
      "Epoch 30/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.6724 - val_loss: 3.5346\n",
      "Epoch 31/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.5443 - val_loss: 3.4416\n",
      "Epoch 32/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.5366 - val_loss: 3.5915\n",
      "Epoch 00032: early stopping\n",
      "moodle, 700, 233\n",
      "Train on 700 samples, validate on 233 samples\n",
      "Epoch 1/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.8453 - val_loss: 13.9677\n",
      "Epoch 2/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.8210 - val_loss: 13.9384\n",
      "Epoch 3/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.7785 - val_loss: 13.8473\n",
      "Epoch 4/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.5293 - val_loss: 13.2425\n",
      "Epoch 5/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 11.4143 - val_loss: 11.0302\n",
      "Epoch 6/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 9.8140 - val_loss: 9.9109\n",
      "Epoch 7/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.5697 - val_loss: 9.8899\n",
      "Epoch 8/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.5631 - val_loss: 9.8640\n",
      "Epoch 9/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.5297 - val_loss: 9.9656\n",
      "Epoch 10/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.3490 - val_loss: 9.8359\n",
      "Epoch 11/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.3087 - val_loss: 9.7870\n",
      "Epoch 12/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.0831 - val_loss: 9.7069\n",
      "Epoch 13/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 6s 9ms/step - loss: 8.6969 - val_loss: 9.8413\n",
      "Epoch 14/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.8342 - val_loss: 9.7311\n",
      "Epoch 15/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.9780 - val_loss: 9.6353\n",
      "Epoch 16/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.5440 - val_loss: 9.3989\n",
      "Epoch 17/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.1175 - val_loss: 9.5553\n",
      "Epoch 18/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.1323 - val_loss: 9.4211\n",
      "Epoch 19/40\n",
      "700/700 [==============================] - 7s 9ms/step - loss: 7.6352 - val_loss: 9.1954\n",
      "Epoch 20/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 7.2873 - val_loss: 9.1071\n",
      "Epoch 21/40\n",
      "700/700 [==============================] - 7s 9ms/step - loss: 7.0109 - val_loss: 9.2116\n",
      "Epoch 22/40\n",
      "700/700 [==============================] - 7s 9ms/step - loss: 6.8674 - val_loss: 9.0056\n",
      "Epoch 23/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 6.5737 - val_loss: 9.3239\n",
      "Epoch 24/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 6.3589 - val_loss: 9.3731\n",
      "Epoch 25/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 6.1327 - val_loss: 9.4058\n",
      "Epoch 26/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 5.8605 - val_loss: 9.1682\n",
      "Epoch 27/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 5.6115 - val_loss: 9.4042\n",
      "Epoch 28/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 5.4256 - val_loss: 9.4779\n",
      "Epoch 29/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 5.1569 - val_loss: 9.9452\n",
      "Epoch 30/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 4.8376 - val_loss: 9.7199\n",
      "Epoch 31/40\n",
      "700/700 [==============================] - 7s 9ms/step - loss: 4.5876 - val_loss: 9.2550\n",
      "Epoch 32/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 4.7233 - val_loss: 9.9339\n",
      "Epoch 33/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 4.2001 - val_loss: 9.5024\n",
      "Epoch 34/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 3.9436 - val_loss: 9.2881\n",
      "Epoch 00034: early stopping\n",
      "jirasoftware, 212, 70\n",
      "Train on 212 samples, validate on 70 samples\n",
      "Epoch 1/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4693 - val_loss: 2.0957\n",
      "Epoch 2/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4634 - val_loss: 2.0912\n",
      "Epoch 3/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4571 - val_loss: 2.0865\n",
      "Epoch 4/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4504 - val_loss: 2.0814\n",
      "Epoch 5/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.4430 - val_loss: 2.0758\n",
      "Epoch 6/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4350 - val_loss: 2.0693\n",
      "Epoch 7/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4255 - val_loss: 2.0604\n",
      "Epoch 8/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4111 - val_loss: 2.0464\n",
      "Epoch 9/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.3850 - val_loss: 2.0195\n",
      "Epoch 10/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.3385 - val_loss: 1.9706\n",
      "Epoch 11/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.2479 - val_loss: 1.8836\n",
      "Epoch 12/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.1063 - val_loss: 1.7294\n",
      "Epoch 13/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.8369 - val_loss: 1.5193\n",
      "Epoch 14/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.5392 - val_loss: 1.4597\n",
      "Epoch 15/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.2302 - val_loss: 1.7368\n",
      "Epoch 16/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.2138 - val_loss: 2.1112\n",
      "Epoch 17/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1930 - val_loss: 2.1911\n",
      "Epoch 18/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1634 - val_loss: 1.9700\n",
      "Epoch 19/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1910 - val_loss: 1.9516\n",
      "Epoch 20/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1806 - val_loss: 2.0071\n",
      "Epoch 21/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1576 - val_loss: 2.0695\n",
      "Epoch 22/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1433 - val_loss: 2.0965\n",
      "Epoch 23/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1186 - val_loss: 1.9947\n",
      "Epoch 24/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1721 - val_loss: 1.9658\n",
      "Epoch 25/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1168 - val_loss: 1.9601\n",
      "Epoch 26/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1268 - val_loss: 1.9915\n",
      "Epoch 00026: early stopping\n",
      "duracloud, 400, 133\n",
      "Train on 400 samples, validate on 133 samples\n",
      "Epoch 1/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9277 - val_loss: 0.6994\n",
      "Epoch 2/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9276 - val_loss: 0.6992\n",
      "Epoch 3/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 4/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 5/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 6/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 7/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 8/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 9/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 10/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 11/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 12/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 13/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 14/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 00014: early stopping\n",
      "titanium, 1351, 450\n",
      "Train on 1351 samples, validate on 450 samples\n",
      "Epoch 1/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 5.0882 - val_loss: 4.5011\n",
      "Epoch 2/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.9799 - val_loss: 4.1695\n",
      "Epoch 3/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.9571 - val_loss: 2.3249\n",
      "Epoch 4/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1550 - val_loss: 2.3410\n",
      "Epoch 5/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1250 - val_loss: 2.2938\n",
      "Epoch 6/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1181 - val_loss: 2.3147\n",
      "Epoch 7/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1168 - val_loss: 2.2921\n",
      "Epoch 8/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.0787 - val_loss: 2.3688\n",
      "Epoch 9/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.1092 - val_loss: 2.2947\n",
      "Epoch 10/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.0846 - val_loss: 2.2991\n",
      "Epoch 11/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.0571 - val_loss: 2.2776\n",
      "Epoch 12/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.9302 - val_loss: 2.2937\n",
      "Epoch 13/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.8407 - val_loss: 2.2861\n",
      "Epoch 14/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.7456 - val_loss: 2.2999\n",
      "Epoch 15/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.6241 - val_loss: 2.3557\n",
      "Epoch 16/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.5227 - val_loss: 2.3906\n",
      "Epoch 17/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.3458 - val_loss: 2.4341\n",
      "Epoch 18/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.3726 - val_loss: 2.4066\n",
      "Epoch 19/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.1826 - val_loss: 2.6781\n",
      "Epoch 20/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.0638 - val_loss: 2.5031\n",
      "Epoch 21/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 1.9975 - val_loss: 2.4753\n",
      "Epoch 22/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 1.8718 - val_loss: 2.5947\n",
      "Epoch 23/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 1.8021 - val_loss: 2.7243\n",
      "Epoch 00023: early stopping\n",
      "aptanastudio, 499, 165\n",
      "Train on 499 samples, validate on 165 samples\n",
      "Epoch 1/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 6.1486 - val_loss: 7.3707\n",
      "Epoch 2/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 6.1360 - val_loss: 7.3516\n",
      "Epoch 3/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.1215 - val_loss: 7.3265\n",
      "Epoch 4/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.0933 - val_loss: 7.2572\n",
      "Epoch 5/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 5.9964 - val_loss: 6.9952\n",
      "Epoch 6/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 5.6657 - val_loss: 6.1440\n",
      "Epoch 7/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 4.9133 - val_loss: 4.1647\n",
      "Epoch 8/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 3.8893 - val_loss: 2.7033\n",
      "Epoch 9/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 3.5798 - val_loss: 2.8865\n",
      "Epoch 10/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.4057 - val_loss: 2.8746\n",
      "Epoch 11/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.3733 - val_loss: 5.4889\n",
      "Epoch 12/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 4.2268 - val_loss: 3.2719\n",
      "Epoch 13/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.4299 - val_loss: 2.7759\n",
      "Epoch 14/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.4280 - val_loss: 2.9246\n",
      "Epoch 15/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.3385 - val_loss: 2.8467\n",
      "Epoch 16/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.3914 - val_loss: 2.7843\n",
      "Epoch 17/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.2934 - val_loss: 2.9631\n",
      "Epoch 18/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.3031 - val_loss: 2.8960\n",
      "Epoch 19/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.1909 - val_loss: 2.8595\n",
      "Epoch 20/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.1950 - val_loss: 2.8903\n",
      "Epoch 00020: early stopping\n",
      "appceleratorstudio, 1753, 583\n",
      "Train on 1753 samples, validate on 583 samples\n",
      "Epoch 1/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 4.4046 - val_loss: 3.6887\n",
      "Epoch 2/40\n",
      "1753/1753 [==============================] - 14s 8ms/step - loss: 3.4255 - val_loss: 2.0616\n",
      "Epoch 3/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 2.1236 - val_loss: 1.6806\n",
      "Epoch 4/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 2.0570 - val_loss: 1.4558\n",
      "Epoch 5/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 2.0625 - val_loss: 1.3710\n",
      "Epoch 6/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 2.0378 - val_loss: 1.4287\n",
      "Epoch 7/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0477 - val_loss: 1.3645\n",
      "Epoch 8/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0395 - val_loss: 1.5968\n",
      "Epoch 9/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0044 - val_loss: 1.4656\n",
      "Epoch 10/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.9322 - val_loss: 1.6350\n",
      "Epoch 11/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.8323 - val_loss: 1.7698\n",
      "Epoch 12/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.7331 - val_loss: 2.0210\n",
      "Epoch 13/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.6470 - val_loss: 1.6998\n",
      "Epoch 14/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.5245 - val_loss: 1.7517\n",
      "Epoch 15/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.4731 - val_loss: 1.9827\n",
      "Epoch 16/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.3872 - val_loss: 1.9336\n",
      "Epoch 17/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.2999 - val_loss: 1.9738\n",
      "Epoch 18/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.2172 - val_loss: 1.9142\n",
      "Epoch 19/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.2042 - val_loss: 1.9449\n",
      "Epoch 00019: early stopping\n",
      "mesos, 1008, 336\n",
      "Train on 1008 samples, validate on 336 samples\n",
      "Epoch 1/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.8415 - val_loss: 1.5553\n",
      "Epoch 2/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.8132 - val_loss: 1.5052\n",
      "Epoch 3/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.5845 - val_loss: 1.1345\n",
      "Epoch 4/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.2382 - val_loss: 1.1426\n",
      "Epoch 5/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.2217 - val_loss: 1.1304\n",
      "Epoch 6/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1811 - val_loss: 1.1349\n",
      "Epoch 7/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1854 - val_loss: 1.1476\n",
      "Epoch 8/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1514 - val_loss: 1.1347\n",
      "Epoch 9/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1430 - val_loss: 1.1004\n",
      "Epoch 10/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.0957 - val_loss: 1.1225\n",
      "Epoch 11/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.0730 - val_loss: 1.1780\n",
      "Epoch 12/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.0321 - val_loss: 1.1640\n",
      "Epoch 13/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.0176 - val_loss: 1.2235\n",
      "Epoch 14/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.9739 - val_loss: 1.2256\n",
      "Epoch 15/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.9099 - val_loss: 1.2364\n",
      "Epoch 16/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.8590 - val_loss: 1.2661\n",
      "Epoch 17/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.8116 - val_loss: 1.2329\n",
      "Epoch 18/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.7586 - val_loss: 1.2488\n",
      "Epoch 19/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.6784 - val_loss: 1.3393\n",
      "Epoch 20/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.6530 - val_loss: 1.2765\n",
      "Epoch 21/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.6221 - val_loss: 1.3113\n",
      "Epoch 00021: early stopping\n",
      "springxd, 2116, 705\n",
      "Train on 2116 samples, validate on 705 samples\n",
      "Epoch 1/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 2.4776 - val_loss: 2.4636\n",
      "Epoch 2/40\n",
      "2116/2116 [==============================] - 17s 8ms/step - loss: 1.9224 - val_loss: 1.7942\n",
      "Epoch 3/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.7950 - val_loss: 1.7844\n",
      "Epoch 4/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.7854 - val_loss: 1.8897\n",
      "Epoch 5/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.8418 - val_loss: 1.8091\n",
      "Epoch 6/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.7793 - val_loss: 1.7892\n",
      "Epoch 7/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.7713 - val_loss: 1.7779\n",
      "Epoch 8/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.7359 - val_loss: 1.7956\n",
      "Epoch 9/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.6815 - val_loss: 1.7831\n",
      "Epoch 10/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.6093 - val_loss: 1.7888\n",
      "Epoch 11/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.5258 - val_loss: 1.7420\n",
      "Epoch 12/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.4491 - val_loss: 1.7959\n",
      "Epoch 13/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.4039 - val_loss: 1.7880\n",
      "Epoch 14/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.3185 - val_loss: 1.7780\n",
      "Epoch 15/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.2647 - val_loss: 1.8212\n",
      "Epoch 16/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.2116 - val_loss: 1.7782\n",
      "Epoch 17/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.1744 - val_loss: 1.8932\n",
      "Epoch 18/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.1096 - val_loss: 1.8495\n",
      "Epoch 19/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.0574 - val_loss: 1.8398\n",
      "Epoch 20/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.0259 - val_loss: 1.8045\n",
      "Epoch 21/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 0.9644 - val_loss: 1.9495\n",
      "Epoch 22/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 0.9235 - val_loss: 1.8786\n",
      "Epoch 23/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 0.8729 - val_loss: 1.8852\n",
      "Epoch 00023: early stopping\n",
      "mulestudio, 440, 146\n",
      "Train on 440 samples, validate on 146 samples\n",
      "Epoch 1/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.3759 - val_loss: 5.6508\n",
      "Epoch 2/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.3626 - val_loss: 5.6357\n",
      "Epoch 3/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.3468 - val_loss: 5.6152\n",
      "Epoch 4/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.3179 - val_loss: 5.5607\n",
      "Epoch 5/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.2143 - val_loss: 5.3585\n",
      "Epoch 6/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 3.8666 - val_loss: 4.7044\n",
      "Epoch 7/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 3.0615 - val_loss: 3.6291\n",
      "Epoch 8/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5772 - val_loss: 3.2936\n",
      "Epoch 9/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5233 - val_loss: 3.3591\n",
      "Epoch 10/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5215 - val_loss: 3.3203\n",
      "Epoch 11/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5052 - val_loss: 3.3662\n",
      "Epoch 12/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5271 - val_loss: 3.3114\n",
      "Epoch 13/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5118 - val_loss: 3.3209\n",
      "Epoch 14/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4871 - val_loss: 3.3278\n",
      "Epoch 15/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4721 - val_loss: 3.2962\n",
      "Epoch 16/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4599 - val_loss: 3.3000\n",
      "Epoch 17/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4586 - val_loss: 3.3015\n",
      "Epoch 18/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4183 - val_loss: 3.2622\n",
      "Epoch 19/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4043 - val_loss: 3.2266\n",
      "Epoch 20/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4500 - val_loss: 3.2850\n",
      "Epoch 21/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.3724 - val_loss: 3.2249\n",
      "Epoch 22/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.3741 - val_loss: 3.3154\n",
      "Epoch 23/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.3274 - val_loss: 3.2319\n",
      "Epoch 24/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.3148 - val_loss: 3.2318\n",
      "Epoch 25/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.2811 - val_loss: 3.3501\n",
      "Epoch 26/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.2167 - val_loss: 3.5184\n",
      "Epoch 27/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.1849 - val_loss: 3.3659\n",
      "Epoch 28/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.0999 - val_loss: 3.3886\n",
      "Epoch 29/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.0622 - val_loss: 3.5256\n",
      "Epoch 30/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.9810 - val_loss: 3.3667\n",
      "Epoch 31/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.8192 - val_loss: 3.4918\n",
      "Epoch 32/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.7798 - val_loss: 3.4961\n",
      "Epoch 33/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.6866 - val_loss: 3.6139\n",
      "Epoch 00033: early stopping\n",
      "moodle, 700, 233\n",
      "Train on 700 samples, validate on 233 samples\n",
      "Epoch 1/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.8447 - val_loss: 13.9654\n",
      "Epoch 2/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.8160 - val_loss: 13.9261\n",
      "Epoch 3/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.7388 - val_loss: 13.7505\n",
      "Epoch 4/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.3241 - val_loss: 12.8506\n",
      "Epoch 5/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 10.9980 - val_loss: 10.5804\n",
      "Epoch 6/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 9.6598 - val_loss: 9.9225\n",
      "Epoch 7/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 9.5799 - val_loss: 9.8851\n",
      "Epoch 8/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.5019 - val_loss: 9.9331\n",
      "Epoch 9/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.3860 - val_loss: 10.0259\n",
      "Epoch 10/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.2510 - val_loss: 10.1488\n",
      "Epoch 11/40\n",
      "700/700 [==============================] - 7s 9ms/step - loss: 9.2646 - val_loss: 10.1598\n",
      "Epoch 12/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.0191 - val_loss: 9.9274\n",
      "Epoch 13/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.7128 - val_loss: 10.1887\n",
      "Epoch 14/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.4428 - val_loss: 9.7973\n",
      "Epoch 15/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.2785 - val_loss: 10.0186\n",
      "Epoch 16/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 7.8287 - val_loss: 9.6926\n",
      "Epoch 17/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 7.5596 - val_loss: 9.8335\n",
      "Epoch 18/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 7.2663 - val_loss: 9.5666\n",
      "Epoch 19/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 7.0860 - val_loss: 9.2930\n",
      "Epoch 20/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 6.6718 - val_loss: 9.4689\n",
      "Epoch 21/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 6.0583 - val_loss: 9.4917\n",
      "Epoch 22/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 6.0867 - val_loss: 9.3583\n",
      "Epoch 23/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 5.8797 - val_loss: 9.5015\n",
      "Epoch 24/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 5.4255 - val_loss: 9.1369\n",
      "Epoch 25/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 5.2026 - val_loss: 9.2439\n",
      "Epoch 26/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 4.7529 - val_loss: 9.4496\n",
      "Epoch 27/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 4.5087 - val_loss: 9.5053\n",
      "Epoch 28/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 4.0880 - val_loss: 9.5870\n",
      "Epoch 29/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 4.0676 - val_loss: 9.2203\n",
      "Epoch 30/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 4.0241 - val_loss: 9.4914\n",
      "Epoch 31/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 3.6602 - val_loss: 9.0948\n",
      "Epoch 32/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 3.6238 - val_loss: 9.4981\n",
      "Epoch 33/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 6s 9ms/step - loss: 3.4036 - val_loss: 9.2910\n",
      "Epoch 34/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 3.2060 - val_loss: 9.4118\n",
      "Epoch 35/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 3.1381 - val_loss: 9.3191\n",
      "Epoch 36/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 3.0556 - val_loss: 9.3756\n",
      "Epoch 37/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 2.9064 - val_loss: 9.1835\n",
      "Epoch 38/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 2.7815 - val_loss: 9.3224\n",
      "Epoch 39/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 2.8660 - val_loss: 9.3302\n",
      "Epoch 40/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 2.6141 - val_loss: 9.2641\n",
      "jirasoftware, 212, 70\n",
      "Train on 212 samples, validate on 70 samples\n",
      "Epoch 1/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4693 - val_loss: 2.0958\n",
      "Epoch 2/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.4634 - val_loss: 2.0914\n",
      "Epoch 3/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.4573 - val_loss: 2.0868\n",
      "Epoch 4/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.4508 - val_loss: 2.0820\n",
      "Epoch 5/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4441 - val_loss: 2.0766\n",
      "Epoch 6/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4365 - val_loss: 2.0704\n",
      "Epoch 7/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4267 - val_loss: 2.0617\n",
      "Epoch 8/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4124 - val_loss: 2.0471\n",
      "Epoch 9/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.3858 - val_loss: 2.0196\n",
      "Epoch 10/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.3378 - val_loss: 1.9712\n",
      "Epoch 11/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.2547 - val_loss: 1.8912\n",
      "Epoch 12/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.1169 - val_loss: 1.7566\n",
      "Epoch 13/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.8922 - val_loss: 1.5367\n",
      "Epoch 14/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.6129 - val_loss: 1.4818\n",
      "Epoch 15/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.3830 - val_loss: 1.5543\n",
      "Epoch 16/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.2137 - val_loss: 1.8492\n",
      "Epoch 17/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1643 - val_loss: 2.0722\n",
      "Epoch 18/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1929 - val_loss: 2.1148\n",
      "Epoch 19/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1489 - val_loss: 2.0567\n",
      "Epoch 20/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1501 - val_loss: 1.9947\n",
      "Epoch 21/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.2073 - val_loss: 2.0272\n",
      "Epoch 22/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1636 - val_loss: 2.0685\n",
      "Epoch 23/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1608 - val_loss: 2.0845\n",
      "Epoch 24/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1440 - val_loss: 2.0475\n",
      "Epoch 25/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1019 - val_loss: 2.0375\n",
      "Epoch 26/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.0664 - val_loss: 1.9724\n",
      "Epoch 00026: early stopping\n",
      "duracloud, 400, 133\n",
      "Train on 400 samples, validate on 133 samples\n",
      "Epoch 1/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9277 - val_loss: 0.6993\n",
      "Epoch 2/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 3/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 4/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 5/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 6/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 7/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 8/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 9/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 10/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 11/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 12/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 13/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 14/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 00014: early stopping\n",
      "titanium, 1351, 450\n",
      "Train on 1351 samples, validate on 450 samples\n",
      "Epoch 1/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 5.0962 - val_loss: 4.5132\n",
      "Epoch 2/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 5.0584 - val_loss: 4.4737\n",
      "Epoch 3/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 5.0204 - val_loss: 4.4348\n",
      "Epoch 4/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.9830 - val_loss: 4.3969\n",
      "Epoch 5/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.9460 - val_loss: 4.3592\n",
      "Epoch 6/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.9094 - val_loss: 4.3213\n",
      "Epoch 7/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.8730 - val_loss: 4.2840\n",
      "Epoch 8/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.8365 - val_loss: 4.2462\n",
      "Epoch 9/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.7996 - val_loss: 4.2085\n",
      "Epoch 10/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.7631 - val_loss: 4.1709\n",
      "Epoch 11/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.7264 - val_loss: 4.1335\n",
      "Epoch 12/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.6900 - val_loss: 4.0958\n",
      "Epoch 13/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.6534 - val_loss: 4.0583\n",
      "Epoch 14/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.6167 - val_loss: 4.0209\n",
      "Epoch 15/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.5803 - val_loss: 3.9831\n",
      "Epoch 16/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.5442 - val_loss: 3.9462\n",
      "Epoch 17/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.5083 - val_loss: 3.9094\n",
      "Epoch 18/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.4721 - val_loss: 3.8720\n",
      "Epoch 19/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.4356 - val_loss: 3.8346\n",
      "Epoch 20/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.3992 - val_loss: 3.7972\n",
      "Epoch 21/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.3627 - val_loss: 3.7599\n",
      "Epoch 22/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.3264 - val_loss: 3.7225\n",
      "Epoch 23/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.2900 - val_loss: 3.6848\n",
      "Epoch 24/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.2559 - val_loss: 3.6548\n",
      "Epoch 25/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.2307 - val_loss: 3.6291\n",
      "Epoch 26/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.2064 - val_loss: 3.6035\n",
      "Epoch 27/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.1822 - val_loss: 3.5777\n",
      "Epoch 28/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.1574 - val_loss: 3.5515\n",
      "Epoch 29/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.1328 - val_loss: 3.5252\n",
      "Epoch 30/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.1077 - val_loss: 3.4988\n",
      "Epoch 31/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.0825 - val_loss: 3.4716\n",
      "Epoch 32/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.0572 - val_loss: 3.4449\n",
      "Epoch 33/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.0318 - val_loss: 3.4183\n",
      "Epoch 34/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.0064 - val_loss: 3.3908\n",
      "Epoch 35/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.9803 - val_loss: 3.3634\n",
      "Epoch 36/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.9543 - val_loss: 3.3357\n",
      "Epoch 37/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.9280 - val_loss: 3.3078\n",
      "Epoch 38/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.9019 - val_loss: 3.2800\n",
      "Epoch 39/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.8754 - val_loss: 3.2519\n",
      "Epoch 40/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.8488 - val_loss: 3.2240\n",
      "aptanastudio, 499, 165\n",
      "Train on 499 samples, validate on 165 samples\n",
      "Epoch 1/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.1487 - val_loss: 7.3706\n",
      "Epoch 2/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.1363 - val_loss: 7.3518\n",
      "Epoch 3/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.1215 - val_loss: 7.3267\n",
      "Epoch 4/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.0923 - val_loss: 7.2583\n",
      "Epoch 5/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 6.0061 - val_loss: 7.0408\n",
      "Epoch 6/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 5.7355 - val_loss: 6.3952\n",
      "Epoch 7/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 5.1147 - val_loss: 4.9165\n",
      "Epoch 8/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 4.0748 - val_loss: 3.1249\n",
      "Epoch 9/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.4642 - val_loss: 3.0042\n",
      "Epoch 10/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.2960 - val_loss: 2.7239\n",
      "Epoch 11/40\n",
      "499/499 [==============================] - 5s 10ms/step - loss: 3.3037 - val_loss: 3.0834\n",
      "Epoch 12/40\n",
      "499/499 [==============================] - 5s 9ms/step - loss: 3.3592 - val_loss: 2.7327\n",
      "Epoch 13/40\n",
      "499/499 [==============================] - 5s 9ms/step - loss: 3.2531 - val_loss: 2.9944\n",
      "Epoch 14/40\n",
      "499/499 [==============================] - 5s 9ms/step - loss: 3.2376 - val_loss: 2.7486\n",
      "Epoch 15/40\n",
      "499/499 [==============================] - 5s 9ms/step - loss: 3.1650 - val_loss: 2.7147\n",
      "Epoch 16/40\n",
      "499/499 [==============================] - 5s 9ms/step - loss: 3.3091 - val_loss: 2.9379\n",
      "Epoch 17/40\n",
      "499/499 [==============================] - 5s 9ms/step - loss: 3.1794 - val_loss: 2.7039\n",
      "Epoch 18/40\n",
      "499/499 [==============================] - 5s 9ms/step - loss: 3.2726 - val_loss: 2.7222\n",
      "Epoch 19/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.2519 - val_loss: 2.8339\n",
      "Epoch 20/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.1745 - val_loss: 2.7442\n",
      "Epoch 21/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.0614 - val_loss: 2.8818\n",
      "Epoch 22/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 2.9508 - val_loss: 3.0355\n",
      "Epoch 23/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 2.8778 - val_loss: 2.9865\n",
      "Epoch 24/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 2.8667 - val_loss: 3.3323\n",
      "Epoch 25/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 2.9000 - val_loss: 3.0100\n",
      "Epoch 26/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 2.6852 - val_loss: 3.0961\n",
      "Epoch 27/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 2.5495 - val_loss: 3.3286\n",
      "Epoch 28/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 2.5128 - val_loss: 3.4216\n",
      "Epoch 29/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 2.2241 - val_loss: 3.6886\n",
      "Epoch 00029: early stopping\n",
      "appceleratorstudio, 1753, 583\n",
      "Train on 1753 samples, validate on 583 samples\n",
      "Epoch 1/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 4.4358 - val_loss: 3.8079\n",
      "Epoch 2/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 4.4358 - val_loss: 3.8079\n",
      "Epoch 3/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 4.4358 - val_loss: 3.8079\n",
      "Epoch 4/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 4.4358 - val_loss: 3.8079\n",
      "Epoch 5/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 4.4358 - val_loss: 3.8079\n",
      "Epoch 6/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 4.4358 - val_loss: 3.8079\n",
      "Epoch 7/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 4.4358 - val_loss: 3.8079\n",
      "Epoch 8/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 4.4358 - val_loss: 3.8079\n",
      "Epoch 9/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 4.4358 - val_loss: 3.8079\n",
      "Epoch 10/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 4.4358 - val_loss: 3.8079\n",
      "Epoch 11/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 4.4358 - val_loss: 3.8079\n",
      "Epoch 12/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 4.4358 - val_loss: 3.8079\n",
      "Epoch 13/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 4.4358 - val_loss: 3.8079\n",
      "Epoch 00013: early stopping\n",
      "mesos, 1008, 336\n",
      "Train on 1008 samples, validate on 336 samples\n",
      "Epoch 1/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.8421 - val_loss: 1.5571\n",
      "Epoch 2/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.8232 - val_loss: 1.5381\n",
      "Epoch 3/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.7646 - val_loss: 1.4104\n",
      "Epoch 4/40\n",
      "1008/1008 [==============================] - 8s 8ms/step - loss: 1.3920 - val_loss: 1.1527\n",
      "Epoch 5/40\n",
      "1008/1008 [==============================] - 8s 8ms/step - loss: 1.2281 - val_loss: 1.1449\n",
      "Epoch 6/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.2217 - val_loss: 1.1244\n",
      "Epoch 7/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1821 - val_loss: 1.1302\n",
      "Epoch 8/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1689 - val_loss: 1.1203\n",
      "Epoch 9/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1338 - val_loss: 1.1115\n",
      "Epoch 10/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1101 - val_loss: 1.1876\n",
      "Epoch 11/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1194 - val_loss: 1.1278\n",
      "Epoch 12/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.0865 - val_loss: 1.1399\n",
      "Epoch 13/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.0479 - val_loss: 1.1104\n",
      "Epoch 14/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.0295 - val_loss: 1.1306\n",
      "Epoch 15/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.0106 - val_loss: 1.1120\n",
      "Epoch 16/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.9914 - val_loss: 1.1459\n",
      "Epoch 17/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.9747 - val_loss: 1.1318\n",
      "Epoch 18/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.9190 - val_loss: 1.1525\n",
      "Epoch 19/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.8421 - val_loss: 1.2791\n",
      "Epoch 20/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.8375 - val_loss: 1.2319\n",
      "Epoch 21/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.8266 - val_loss: 1.1777\n",
      "Epoch 22/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.7706 - val_loss: 1.2172\n",
      "Epoch 23/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.7281 - val_loss: 1.1812\n",
      "Epoch 24/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.6804 - val_loss: 1.1763\n",
      "Epoch 25/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.6663 - val_loss: 1.2076\n",
      "Epoch 00025: early stopping\n",
      "springxd, 2116, 705\n",
      "Train on 2116 samples, validate on 705 samples\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2116/2116 [==============================] - 18s 9ms/step - loss: 2.4809 - val_loss: 2.4842\n",
      "Epoch 2/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.9510 - val_loss: 1.7905\n",
      "Epoch 3/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.8251 - val_loss: 1.8272\n",
      "Epoch 4/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.8229 - val_loss: 1.7741\n",
      "Epoch 5/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.7960 - val_loss: 1.8048\n",
      "Epoch 6/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.7685 - val_loss: 1.7873\n",
      "Epoch 7/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.7505 - val_loss: 1.7737\n",
      "Epoch 8/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.7338 - val_loss: 1.7586\n",
      "Epoch 9/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.7183 - val_loss: 1.7621\n",
      "Epoch 10/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.6739 - val_loss: 1.7452\n",
      "Epoch 11/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.6275 - val_loss: 1.8156\n",
      "Epoch 12/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.5699 - val_loss: 1.7249\n",
      "Epoch 13/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.5313 - val_loss: 1.7466\n",
      "Epoch 14/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.4776 - val_loss: 1.7228\n",
      "Epoch 15/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.4205 - val_loss: 1.7717\n",
      "Epoch 16/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.4136 - val_loss: 1.7013\n",
      "Epoch 17/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.3347 - val_loss: 1.7225\n",
      "Epoch 18/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.3165 - val_loss: 1.6678\n",
      "Epoch 19/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.2419 - val_loss: 1.7508\n",
      "Epoch 20/40\n",
      "2116/2116 [==============================] - 20s 9ms/step - loss: 1.2205 - val_loss: 1.7291\n",
      "Epoch 21/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.1990 - val_loss: 1.7316\n",
      "Epoch 22/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.1260 - val_loss: 1.7559\n",
      "Epoch 23/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.1354 - val_loss: 1.7339\n",
      "Epoch 24/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.1091 - val_loss: 1.7852\n",
      "Epoch 25/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.0023 - val_loss: 1.7523\n",
      "Epoch 26/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.9964 - val_loss: 1.7853\n",
      "Epoch 27/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.9287 - val_loss: 1.7005\n",
      "Epoch 28/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.8905 - val_loss: 1.8073\n",
      "Epoch 29/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.8802 - val_loss: 1.8480\n",
      "Epoch 30/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.8682 - val_loss: 1.8415\n",
      "Epoch 00030: early stopping\n",
      "mulestudio, 440, 146\n",
      "Train on 440 samples, validate on 146 samples\n",
      "Epoch 1/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.3768 - val_loss: 5.6522\n",
      "Epoch 2/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.3646 - val_loss: 5.6390\n",
      "Epoch 3/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.3517 - val_loss: 5.6246\n",
      "Epoch 4/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.3377 - val_loss: 5.6086\n",
      "Epoch 5/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.3203 - val_loss: 5.5852\n",
      "Epoch 6/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.2841 - val_loss: 5.5139\n",
      "Epoch 7/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.1531 - val_loss: 5.2701\n",
      "Epoch 8/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 3.7450 - val_loss: 4.5328\n",
      "Epoch 9/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.9568 - val_loss: 3.4952\n",
      "Epoch 10/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.6070 - val_loss: 3.2749\n",
      "Epoch 11/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5597 - val_loss: 3.4659\n",
      "Epoch 12/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5018 - val_loss: 3.2649\n",
      "Epoch 13/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.5286 - val_loss: 3.2680\n",
      "Epoch 14/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.5270 - val_loss: 3.3729\n",
      "Epoch 15/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.5049 - val_loss: 3.2930\n",
      "Epoch 16/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.5342 - val_loss: 3.2908\n",
      "Epoch 17/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4584 - val_loss: 3.3439\n",
      "Epoch 18/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4933 - val_loss: 3.2581\n",
      "Epoch 19/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4455 - val_loss: 3.3042\n",
      "Epoch 20/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4682 - val_loss: 3.2477\n",
      "Epoch 21/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.3939 - val_loss: 3.3226\n",
      "Epoch 22/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.3851 - val_loss: 3.2277\n",
      "Epoch 23/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.3725 - val_loss: 3.4467\n",
      "Epoch 24/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.3425 - val_loss: 3.3708\n",
      "Epoch 25/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.2531 - val_loss: 3.2663\n",
      "Epoch 26/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.1768 - val_loss: 3.3418\n",
      "Epoch 27/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.1826 - val_loss: 3.2677\n",
      "Epoch 28/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.2493 - val_loss: 3.2921\n",
      "Epoch 29/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.1820 - val_loss: 3.2680\n",
      "Epoch 30/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.0905 - val_loss: 3.3804\n",
      "Epoch 31/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.0138 - val_loss: 3.3298\n",
      "Epoch 32/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.9001 - val_loss: 3.3354\n",
      "Epoch 33/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.8417 - val_loss: 3.3483\n",
      "Epoch 34/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.9481 - val_loss: 3.4202\n",
      "Epoch 00034: early stopping\n",
      "moodle, 700, 233\n",
      "Train on 700 samples, validate on 233 samples\n",
      "Epoch 1/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.8454 - val_loss: 13.9670\n",
      "Epoch 2/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.8198 - val_loss: 13.9372\n",
      "Epoch 3/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.7890 - val_loss: 13.9009\n",
      "Epoch 4/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.7519 - val_loss: 13.8574\n",
      "Epoch 5/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.7075 - val_loss: 13.8064\n",
      "Epoch 6/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.6562 - val_loss: 13.7469\n",
      "Epoch 7/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.5967 - val_loss: 13.6799\n",
      "Epoch 8/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.5300 - val_loss: 13.6045\n",
      "Epoch 9/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.4557 - val_loss: 13.5207\n",
      "Epoch 10/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.3735 - val_loss: 13.4296\n",
      "Epoch 11/40\n",
      "700/700 [==============================] - 7s 9ms/step - loss: 12.2840 - val_loss: 13.3302\n",
      "Epoch 12/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.1869 - val_loss: 13.2230\n",
      "Epoch 13/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.0823 - val_loss: 13.1078\n",
      "Epoch 14/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 11.9705 - val_loss: 12.9856\n",
      "Epoch 15/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 6s 9ms/step - loss: 11.8703 - val_loss: 12.8876\n",
      "Epoch 16/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 11.7887 - val_loss: 12.7890\n",
      "Epoch 17/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 11.7040 - val_loss: 12.6833\n",
      "Epoch 18/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 11.6123 - val_loss: 12.5747\n",
      "Epoch 19/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 11.5174 - val_loss: 12.4560\n",
      "Epoch 20/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 11.4155 - val_loss: 12.3319\n",
      "Epoch 21/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 11.3086 - val_loss: 12.2006\n",
      "Epoch 22/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 11.1975 - val_loss: 12.0785\n",
      "Epoch 23/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 11.1146 - val_loss: 11.9849\n",
      "Epoch 24/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 11.0445 - val_loss: 11.8874\n",
      "Epoch 25/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 10.9700 - val_loss: 11.7887\n",
      "Epoch 26/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 10.8924 - val_loss: 11.6872\n",
      "Epoch 27/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 10.8124 - val_loss: 11.5794\n",
      "Epoch 28/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 10.7299 - val_loss: 11.4622\n",
      "Epoch 29/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 10.6403 - val_loss: 11.3503\n",
      "Epoch 30/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 10.5585 - val_loss: 11.2403\n",
      "Epoch 31/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 10.4770 - val_loss: 11.1273\n",
      "Epoch 32/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 10.3927 - val_loss: 11.0095\n",
      "Epoch 33/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 10.3041 - val_loss: 10.8894\n",
      "Epoch 34/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 10.2174 - val_loss: 10.7537\n",
      "Epoch 35/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 10.1317 - val_loss: 10.6874\n",
      "Epoch 36/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 10.1016 - val_loss: 10.6579\n",
      "Epoch 37/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 10.0776 - val_loss: 10.6334\n",
      "Epoch 38/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 10.0557 - val_loss: 10.6060\n",
      "Epoch 39/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 10.0329 - val_loss: 10.5778\n",
      "Epoch 40/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 10.0096 - val_loss: 10.5475\n",
      "jirasoftware, 212, 70\n",
      "Train on 212 samples, validate on 70 samples\n",
      "Epoch 1/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4695 - val_loss: 2.0960\n",
      "Epoch 2/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4639 - val_loss: 2.0917\n",
      "Epoch 3/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4581 - val_loss: 2.0874\n",
      "Epoch 4/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4519 - val_loss: 2.0829\n",
      "Epoch 5/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4456 - val_loss: 2.0783\n",
      "Epoch 6/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4392 - val_loss: 2.0732\n",
      "Epoch 7/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4318 - val_loss: 2.0672\n",
      "Epoch 8/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4225 - val_loss: 2.0587\n",
      "Epoch 9/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4087 - val_loss: 2.0446\n",
      "Epoch 10/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.3841 - val_loss: 2.0199\n",
      "Epoch 11/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.3409 - val_loss: 1.9792\n",
      "Epoch 12/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.2727 - val_loss: 1.9108\n",
      "Epoch 13/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.1484 - val_loss: 1.7995\n",
      "Epoch 14/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.9600 - val_loss: 1.6213\n",
      "Epoch 15/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.7250 - val_loss: 1.5029\n",
      "Epoch 16/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.4926 - val_loss: 1.4510\n",
      "Epoch 17/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.2554 - val_loss: 1.6553\n",
      "Epoch 18/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.2197 - val_loss: 1.9006\n",
      "Epoch 19/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.2325 - val_loss: 2.0891\n",
      "Epoch 20/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.2097 - val_loss: 2.1458\n",
      "Epoch 21/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1774 - val_loss: 2.0720\n",
      "Epoch 22/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1805 - val_loss: 2.0062\n",
      "Epoch 23/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1529 - val_loss: 2.0066\n",
      "Epoch 24/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1048 - val_loss: 1.9558\n",
      "Epoch 25/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1657 - val_loss: 2.0766\n",
      "Epoch 26/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.0605 - val_loss: 1.8275\n",
      "Epoch 27/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.0943 - val_loss: 1.8089\n",
      "Epoch 28/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 1.9441 - val_loss: 1.8891\n",
      "Epoch 00028: early stopping\n",
      "duracloud, 400, 133\n",
      "Train on 400 samples, validate on 133 samples\n",
      "Epoch 1/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9276 - val_loss: 0.6993\n",
      "Epoch 2/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 3/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 4/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 5/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 6/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 7/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 8/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 9/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 10/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 11/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 12/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 13/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 14/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 00014: early stopping\n",
      "titanium, 1351, 450\n",
      "Train on 1351 samples, validate on 450 samples\n",
      "Epoch 1/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 5.0867 - val_loss: 4.4955\n",
      "Epoch 2/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.9101 - val_loss: 3.8488\n",
      "Epoch 3/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.5277 - val_loss: 2.3241\n",
      "Epoch 4/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1280 - val_loss: 2.3486\n",
      "Epoch 5/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.1364 - val_loss: 2.3080\n",
      "Epoch 6/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.1249 - val_loss: 2.3287\n",
      "Epoch 7/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.1097 - val_loss: 2.3194\n",
      "Epoch 8/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.1289 - val_loss: 2.3297\n",
      "Epoch 9/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.1182 - val_loss: 2.3280\n",
      "Epoch 10/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.1087 - val_loss: 2.3210\n",
      "Epoch 11/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.0768 - val_loss: 2.3482\n",
      "Epoch 12/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.0602 - val_loss: 2.3340\n",
      "Epoch 13/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.9999 - val_loss: 2.3508\n",
      "Epoch 14/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.9322 - val_loss: 2.3540\n",
      "Epoch 15/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.8279 - val_loss: 2.3644\n",
      "Epoch 16/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.6487 - val_loss: 2.5140\n",
      "Epoch 17/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.4899 - val_loss: 2.5613\n",
      "Epoch 00017: early stopping\n",
      "aptanastudio, 499, 165\n",
      "Train on 499 samples, validate on 165 samples\n",
      "Epoch 1/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.1494 - val_loss: 7.3717\n",
      "Epoch 2/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.1373 - val_loss: 7.3543\n",
      "Epoch 3/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.1242 - val_loss: 7.3344\n",
      "Epoch 4/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.1062 - val_loss: 7.2959\n",
      "Epoch 5/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.0527 - val_loss: 7.1578\n",
      "Epoch 6/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 5.8790 - val_loss: 6.7233\n",
      "Epoch 7/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 5.3798 - val_loss: 5.5784\n",
      "Epoch 8/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 4.5189 - val_loss: 3.6179\n",
      "Epoch 9/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.7048 - val_loss: 2.7214\n",
      "Epoch 10/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.4671 - val_loss: 2.8790\n",
      "Epoch 11/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.3416 - val_loss: 2.7477\n",
      "Epoch 12/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.2466 - val_loss: 2.9012\n",
      "Epoch 13/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.2293 - val_loss: 2.8396\n",
      "Epoch 14/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.2538 - val_loss: 2.8540\n",
      "Epoch 15/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.2472 - val_loss: 2.8490\n",
      "Epoch 16/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.1752 - val_loss: 2.8231\n",
      "Epoch 17/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.0722 - val_loss: 2.8070\n",
      "Epoch 18/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.0346 - val_loss: 2.8050\n",
      "Epoch 19/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 2.9343 - val_loss: 2.9784\n",
      "Epoch 20/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.0186 - val_loss: 3.1563\n",
      "Epoch 21/40\n",
      "499/499 [==============================] - 5s 10ms/step - loss: 2.9806 - val_loss: 2.9321\n",
      "Epoch 00021: early stopping\n",
      "appceleratorstudio, 1753, 583\n",
      "Train on 1753 samples, validate on 583 samples\n",
      "Epoch 1/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 4.4131 - val_loss: 3.7461\n",
      "Epoch 2/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 4.1779 - val_loss: 2.6320\n",
      "Epoch 3/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 2.3611 - val_loss: 1.3762\n",
      "Epoch 4/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0446 - val_loss: 1.4689\n",
      "Epoch 5/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0491 - val_loss: 1.3995\n",
      "Epoch 6/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0332 - val_loss: 1.6939\n",
      "Epoch 7/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0377 - val_loss: 1.4478\n",
      "Epoch 8/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0218 - val_loss: 1.4551\n",
      "Epoch 9/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.9925 - val_loss: 1.6458\n",
      "Epoch 10/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.9941 - val_loss: 1.6091\n",
      "Epoch 11/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.9781 - val_loss: 1.5619\n",
      "Epoch 12/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.9570 - val_loss: 1.6756\n",
      "Epoch 13/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.9245 - val_loss: 1.8677\n",
      "Epoch 14/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.8731 - val_loss: 1.4570\n",
      "Epoch 15/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.7336 - val_loss: 2.0154\n",
      "Epoch 00015: early stopping\n",
      "mesos, 1008, 336\n",
      "Train on 1008 samples, validate on 336 samples\n",
      "Epoch 1/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.8416 - val_loss: 1.5560\n",
      "Epoch 2/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.8201 - val_loss: 1.5322\n",
      "Epoch 3/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.7279 - val_loss: 1.3180\n",
      "Epoch 4/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.3092 - val_loss: 1.1524\n",
      "Epoch 5/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.2339 - val_loss: 1.1463\n",
      "Epoch 6/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.2081 - val_loss: 1.1267\n",
      "Epoch 7/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1787 - val_loss: 1.1253\n",
      "Epoch 8/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1824 - val_loss: 1.1472\n",
      "Epoch 9/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1559 - val_loss: 1.1138\n",
      "Epoch 10/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1401 - val_loss: 1.1081\n",
      "Epoch 11/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1149 - val_loss: 1.1239\n",
      "Epoch 12/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.0651 - val_loss: 1.1723\n",
      "Epoch 13/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.0051 - val_loss: 1.2488\n",
      "Epoch 14/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.9633 - val_loss: 1.2455\n",
      "Epoch 15/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.9228 - val_loss: 1.2308\n",
      "Epoch 16/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.8844 - val_loss: 1.1524\n",
      "Epoch 17/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.8379 - val_loss: 1.2016\n",
      "Epoch 18/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.7611 - val_loss: 1.2351\n",
      "Epoch 19/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.7117 - val_loss: 1.2547\n",
      "Epoch 20/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.6510 - val_loss: 1.2368\n",
      "Epoch 21/40\n",
      "1008/1008 [==============================] - 10s 9ms/step - loss: 0.6053 - val_loss: 1.3520\n",
      "Epoch 22/40\n",
      "1008/1008 [==============================] - 10s 10ms/step - loss: 0.5874 - val_loss: 1.3360\n",
      "Epoch 00022: early stopping\n",
      "springxd, 2116, 705\n",
      "Train on 2116 samples, validate on 705 samples\n",
      "Epoch 1/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 2.4869 - val_loss: 2.5344\n",
      "Epoch 2/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 2.0810 - val_loss: 1.8795\n",
      "Epoch 3/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.8216 - val_loss: 1.8187\n",
      "Epoch 4/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.7806 - val_loss: 1.7821\n",
      "Epoch 5/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.7687 - val_loss: 1.7841\n",
      "Epoch 6/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.7551 - val_loss: 1.7955\n",
      "Epoch 7/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.7149 - val_loss: 1.7509\n",
      "Epoch 8/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.6721 - val_loss: 1.7446\n",
      "Epoch 9/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.5682 - val_loss: 1.7583\n",
      "Epoch 10/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.5029 - val_loss: 1.8234\n",
      "Epoch 11/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.4318 - val_loss: 1.7158\n",
      "Epoch 12/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.3727 - val_loss: 1.7915\n",
      "Epoch 13/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.3029 - val_loss: 1.8259\n",
      "Epoch 14/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.2516 - val_loss: 1.7579\n",
      "Epoch 15/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.2063 - val_loss: 1.7385\n",
      "Epoch 16/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.0882 - val_loss: 1.8469\n",
      "Epoch 17/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.0441 - val_loss: 1.8192\n",
      "Epoch 18/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.9930 - val_loss: 1.7759\n",
      "Epoch 19/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.9723 - val_loss: 1.8507\n",
      "Epoch 20/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.9281 - val_loss: 1.9668\n",
      "Epoch 21/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.8816 - val_loss: 1.7494\n",
      "Epoch 22/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.8212 - val_loss: 1.8456\n",
      "Epoch 23/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.7915 - val_loss: 1.7891\n",
      "Epoch 00023: early stopping\n",
      "mulestudio, 440, 146\n",
      "Train on 440 samples, validate on 146 samples\n",
      "Epoch 1/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.3766 - val_loss: 5.6517\n",
      "Epoch 2/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.3642 - val_loss: 5.6383\n",
      "Epoch 3/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.3510 - val_loss: 5.6242\n",
      "Epoch 4/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.3372 - val_loss: 5.6087\n",
      "Epoch 5/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.3211 - val_loss: 5.5877\n",
      "Epoch 6/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.2910 - val_loss: 5.5373\n",
      "Epoch 7/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.2160 - val_loss: 5.3976\n",
      "Epoch 8/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 3.9949 - val_loss: 5.0151\n",
      "Epoch 9/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 3.4806 - val_loss: 4.1912\n",
      "Epoch 10/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.7876 - val_loss: 3.4334\n",
      "Epoch 11/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5901 - val_loss: 3.2784\n",
      "Epoch 12/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5296 - val_loss: 3.3948\n",
      "Epoch 13/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5182 - val_loss: 3.2842\n",
      "Epoch 14/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4869 - val_loss: 3.3415\n",
      "Epoch 15/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.4888 - val_loss: 3.2652\n",
      "Epoch 16/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4596 - val_loss: 3.2389\n",
      "Epoch 17/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4481 - val_loss: 3.2943\n",
      "Epoch 18/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4005 - val_loss: 3.2707\n",
      "Epoch 19/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4328 - val_loss: 3.2384\n",
      "Epoch 20/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4208 - val_loss: 3.2291\n",
      "Epoch 21/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.3665 - val_loss: 3.2162\n",
      "Epoch 22/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.3792 - val_loss: 3.2220\n",
      "Epoch 23/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.3454 - val_loss: 3.2448\n",
      "Epoch 24/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.3711 - val_loss: 3.2177\n",
      "Epoch 25/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.2891 - val_loss: 3.2233\n",
      "Epoch 26/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.2585 - val_loss: 3.2044\n",
      "Epoch 27/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.2341 - val_loss: 3.1753\n",
      "Epoch 28/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.1975 - val_loss: 3.2633\n",
      "Epoch 29/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.1114 - val_loss: 3.3025\n",
      "Epoch 30/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.0177 - val_loss: 3.2745\n",
      "Epoch 31/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.9996 - val_loss: 3.1732\n",
      "Epoch 32/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.9427 - val_loss: 3.3748\n",
      "Epoch 33/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.8288 - val_loss: 3.4015\n",
      "Epoch 34/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.7703 - val_loss: 3.4229\n",
      "Epoch 35/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.6464 - val_loss: 3.5355\n",
      "Epoch 36/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.6636 - val_loss: 3.3447\n",
      "Epoch 37/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.5126 - val_loss: 3.3773\n",
      "Epoch 38/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.4833 - val_loss: 3.6074\n",
      "Epoch 39/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.4370 - val_loss: 3.5003\n",
      "Epoch 40/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.3022 - val_loss: 3.4157\n",
      "moodle, 700, 233\n",
      "Train on 700 samples, validate on 233 samples\n",
      "Epoch 1/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.8438 - val_loss: 13.9640\n",
      "Epoch 2/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.8139 - val_loss: 13.9216\n",
      "Epoch 3/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.7279 - val_loss: 13.7174\n",
      "Epoch 4/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.2531 - val_loss: 12.6734\n",
      "Epoch 5/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 10.7853 - val_loss: 10.3608\n",
      "Epoch 6/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 9.7470 - val_loss: 9.9007\n",
      "Epoch 7/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.6008 - val_loss: 9.8803\n",
      "Epoch 8/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.5627 - val_loss: 9.9088\n",
      "Epoch 9/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.5454 - val_loss: 9.9905\n",
      "Epoch 10/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.4784 - val_loss: 9.9711\n",
      "Epoch 11/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.4271 - val_loss: 9.9580\n",
      "Epoch 12/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.3254 - val_loss: 9.8178\n",
      "Epoch 13/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.9740 - val_loss: 9.6047\n",
      "Epoch 14/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.7039 - val_loss: 9.6440\n",
      "Epoch 15/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.4171 - val_loss: 9.1383\n",
      "Epoch 16/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 7.8603 - val_loss: 8.9584\n",
      "Epoch 17/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 7.4298 - val_loss: 8.8431\n",
      "Epoch 18/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 7.3274 - val_loss: 8.8889\n",
      "Epoch 19/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 6.8294 - val_loss: 9.3268\n",
      "Epoch 20/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 6.7664 - val_loss: 8.8932\n",
      "Epoch 21/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 6.5061 - val_loss: 9.1719\n",
      "Epoch 22/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 6.5326 - val_loss: 9.1522\n",
      "Epoch 23/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 6.2042 - val_loss: 8.7948\n",
      "Epoch 24/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 6.0142 - val_loss: 9.1787\n",
      "Epoch 25/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 6.2528 - val_loss: 10.0943\n",
      "Epoch 26/40\n",
      "700/700 [==============================] - 7s 10ms/step - loss: 7.1302 - val_loss: 9.4727\n",
      "Epoch 27/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 6.5139 - val_loss: 9.1013\n",
      "Epoch 28/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 6s 9ms/step - loss: 6.2813 - val_loss: 9.4654\n",
      "Epoch 29/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 5.9057 - val_loss: 9.8109\n",
      "Epoch 30/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 5.4512 - val_loss: 9.6397\n",
      "Epoch 31/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 4.7072 - val_loss: 9.0840\n",
      "Epoch 32/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 4.3067 - val_loss: 9.4391\n",
      "Epoch 33/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 4.1677 - val_loss: 9.4855\n",
      "Epoch 34/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 4.0849 - val_loss: 9.4347\n",
      "Epoch 35/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 3.9516 - val_loss: 9.3526\n",
      "Epoch 00035: early stopping\n",
      "jirasoftware, 212, 70\n",
      "Train on 212 samples, validate on 70 samples\n",
      "Epoch 1/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4695 - val_loss: 2.0960\n",
      "Epoch 2/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4641 - val_loss: 2.0919\n",
      "Epoch 3/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4582 - val_loss: 2.0877\n",
      "Epoch 4/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4525 - val_loss: 2.0833\n",
      "Epoch 5/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4462 - val_loss: 2.0787\n",
      "Epoch 6/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4398 - val_loss: 2.0737\n",
      "Epoch 7/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4326 - val_loss: 2.0678\n",
      "Epoch 8/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4232 - val_loss: 2.0592\n",
      "Epoch 9/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4081 - val_loss: 2.0438\n",
      "Epoch 10/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.3809 - val_loss: 2.0150\n",
      "Epoch 11/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.3310 - val_loss: 1.9656\n",
      "Epoch 12/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.2462 - val_loss: 1.8814\n",
      "Epoch 13/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.1059 - val_loss: 1.7402\n",
      "Epoch 14/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.8734 - val_loss: 1.5259\n",
      "Epoch 15/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.5945 - val_loss: 1.4793\n",
      "Epoch 16/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.3442 - val_loss: 1.5698\n",
      "Epoch 17/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.2434 - val_loss: 1.8432\n",
      "Epoch 18/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1597 - val_loss: 2.0384\n",
      "Epoch 19/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.2129 - val_loss: 2.1920\n",
      "Epoch 20/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1683 - val_loss: 2.0812\n",
      "Epoch 21/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1618 - val_loss: 2.0134\n",
      "Epoch 22/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1225 - val_loss: 2.0033\n",
      "Epoch 23/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1911 - val_loss: 2.0041\n",
      "Epoch 24/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1879 - val_loss: 2.0169\n",
      "Epoch 25/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1879 - val_loss: 2.0211\n",
      "Epoch 26/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1513 - val_loss: 1.9905\n",
      "Epoch 27/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1374 - val_loss: 1.9852\n",
      "Epoch 00027: early stopping\n",
      "duracloud, 400, 133\n",
      "Train on 400 samples, validate on 133 samples\n",
      "Epoch 1/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9277 - val_loss: 0.6994\n",
      "Epoch 2/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9276 - val_loss: 0.6992\n",
      "Epoch 3/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 4/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 5/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 6/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 7/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 8/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 9/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 10/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 11/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 12/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 13/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 14/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 00014: early stopping\n",
      "titanium, 1351, 450\n",
      "Train on 1351 samples, validate on 450 samples\n",
      "Epoch 1/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 5.0871 - val_loss: 4.4955\n",
      "Epoch 2/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.8647 - val_loss: 3.6545\n",
      "Epoch 3/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.4243 - val_loss: 2.3397\n",
      "Epoch 4/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1281 - val_loss: 2.2834\n",
      "Epoch 5/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1346 - val_loss: 2.2897\n",
      "Epoch 6/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1433 - val_loss: 2.3614\n",
      "Epoch 7/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1322 - val_loss: 2.3166\n",
      "Epoch 8/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1248 - val_loss: 2.3070\n",
      "Epoch 9/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.1151 - val_loss: 2.3140\n",
      "Epoch 10/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.1045 - val_loss: 2.3091\n",
      "Epoch 11/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.1103 - val_loss: 2.3170\n",
      "Epoch 12/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.1019 - val_loss: 2.3231\n",
      "Epoch 13/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.0754 - val_loss: 2.4120\n",
      "Epoch 14/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.0823 - val_loss: 2.3635\n",
      "Epoch 15/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.0396 - val_loss: 2.3232\n",
      "Epoch 16/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.9991 - val_loss: 2.3540\n",
      "Epoch 00016: early stopping\n",
      "aptanastudio, 499, 165\n",
      "Train on 499 samples, validate on 165 samples\n",
      "Epoch 1/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.1485 - val_loss: 7.3702\n",
      "Epoch 2/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.1356 - val_loss: 7.3507\n",
      "Epoch 3/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.1208 - val_loss: 7.3264\n",
      "Epoch 4/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.0969 - val_loss: 7.2747\n",
      "Epoch 5/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.0329 - val_loss: 7.1225\n",
      "Epoch 6/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 5.8472 - val_loss: 6.6678\n",
      "Epoch 7/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 5.3551 - val_loss: 5.4892\n",
      "Epoch 8/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 4.4746 - val_loss: 3.5772\n",
      "Epoch 9/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.6786 - val_loss: 2.6963\n",
      "Epoch 10/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.3431 - val_loss: 2.9545\n",
      "Epoch 11/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.3256 - val_loss: 2.7900\n",
      "Epoch 12/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.2788 - val_loss: 2.8445\n",
      "Epoch 13/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499/499 [==============================] - 4s 9ms/step - loss: 3.3026 - val_loss: 2.7300\n",
      "Epoch 14/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.2183 - val_loss: 2.9129\n",
      "Epoch 15/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.1203 - val_loss: 3.1174\n",
      "Epoch 16/40\n",
      "499/499 [==============================] - 5s 9ms/step - loss: 3.0137 - val_loss: 3.0331\n",
      "Epoch 17/40\n",
      "499/499 [==============================] - 5s 9ms/step - loss: 2.9308 - val_loss: 3.0174\n",
      "Epoch 18/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 2.9145 - val_loss: 2.9122\n",
      "Epoch 19/40\n",
      "499/499 [==============================] - 5s 9ms/step - loss: 2.9691 - val_loss: 3.1118\n",
      "Epoch 20/40\n",
      "499/499 [==============================] - 5s 9ms/step - loss: 2.7989 - val_loss: 3.0657\n",
      "Epoch 21/40\n",
      "499/499 [==============================] - 5s 9ms/step - loss: 2.7250 - val_loss: 3.4429\n",
      "Epoch 00021: early stopping\n",
      "appceleratorstudio, 1753, 583\n",
      "Train on 1753 samples, validate on 583 samples\n",
      "Epoch 1/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 4.3984 - val_loss: 3.6317\n",
      "Epoch 2/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 3.0770 - val_loss: 1.5810\n",
      "Epoch 3/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 2.0778 - val_loss: 1.5592\n",
      "Epoch 4/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 2.0709 - val_loss: 1.6266\n",
      "Epoch 5/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 2.0579 - val_loss: 1.4314\n",
      "Epoch 6/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 2.0273 - val_loss: 1.5564\n",
      "Epoch 7/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0496 - val_loss: 1.5741\n",
      "Epoch 8/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0315 - val_loss: 1.5742\n",
      "Epoch 9/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 2.0442 - val_loss: 1.4188\n",
      "Epoch 10/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0266 - val_loss: 1.5188\n",
      "Epoch 11/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0201 - val_loss: 1.6772\n",
      "Epoch 12/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.9764 - val_loss: 1.4160\n",
      "Epoch 13/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.9526 - val_loss: 1.4860\n",
      "Epoch 14/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.8522 - val_loss: 2.0696\n",
      "Epoch 15/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.7968 - val_loss: 1.8100\n",
      "Epoch 16/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.6351 - val_loss: 1.8479\n",
      "Epoch 17/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.5516 - val_loss: 1.7890\n",
      "Epoch 18/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.4779 - val_loss: 1.8346\n",
      "Epoch 19/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.4146 - val_loss: 1.9864\n",
      "Epoch 20/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.3641 - val_loss: 1.9137\n",
      "Epoch 21/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.3156 - val_loss: 1.7313\n",
      "Epoch 22/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.3192 - val_loss: 1.6500\n",
      "Epoch 23/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.2111 - val_loss: 1.8710\n",
      "Epoch 24/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.1757 - val_loss: 1.7822\n",
      "Epoch 00024: early stopping\n",
      "mesos, 1008, 336\n",
      "Train on 1008 samples, validate on 336 samples\n",
      "Epoch 1/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.8421 - val_loss: 1.5570\n",
      "Epoch 2/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.8209 - val_loss: 1.5302\n",
      "Epoch 3/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.7144 - val_loss: 1.2831\n",
      "Epoch 4/40\n",
      "1008/1008 [==============================] - 8s 8ms/step - loss: 1.2900 - val_loss: 1.1481\n",
      "Epoch 5/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.2261 - val_loss: 1.1450\n",
      "Epoch 6/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1930 - val_loss: 1.1530\n",
      "Epoch 7/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1787 - val_loss: 1.1188\n",
      "Epoch 8/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1686 - val_loss: 1.1223\n",
      "Epoch 9/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1679 - val_loss: 1.1731\n",
      "Epoch 10/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1587 - val_loss: 1.1112\n",
      "Epoch 11/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1041 - val_loss: 1.1495\n",
      "Epoch 12/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.0740 - val_loss: 1.1293\n",
      "Epoch 13/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.0341 - val_loss: 1.1955\n",
      "Epoch 14/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.0028 - val_loss: 1.1166\n",
      "Epoch 15/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.9518 - val_loss: 1.1538\n",
      "Epoch 16/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.9031 - val_loss: 1.2168\n",
      "Epoch 17/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.8646 - val_loss: 1.2163\n",
      "Epoch 18/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.8379 - val_loss: 1.3505\n",
      "Epoch 19/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.7915 - val_loss: 1.2214\n",
      "Epoch 20/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.7166 - val_loss: 1.2348\n",
      "Epoch 21/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.6914 - val_loss: 1.2790\n",
      "Epoch 22/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.6618 - val_loss: 1.3859\n",
      "Epoch 00022: early stopping\n",
      "springxd, 2116, 705\n",
      "Train on 2116 samples, validate on 705 samples\n",
      "Epoch 1/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 2.4848 - val_loss: 2.5101\n",
      "Epoch 2/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.9957 - val_loss: 1.8421\n",
      "Epoch 3/40\n",
      "2116/2116 [==============================] - 18s 8ms/step - loss: 1.8242 - val_loss: 1.8022\n",
      "Epoch 4/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.8100 - val_loss: 1.7768\n",
      "Epoch 5/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.7631 - val_loss: 1.8082\n",
      "Epoch 6/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.7459 - val_loss: 1.8071\n",
      "Epoch 7/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.7175 - val_loss: 1.7667\n",
      "Epoch 8/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.6600 - val_loss: 1.7719\n",
      "Epoch 9/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.6202 - val_loss: 1.8817\n",
      "Epoch 10/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.5846 - val_loss: 1.7536\n",
      "Epoch 11/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.5066 - val_loss: 1.7161\n",
      "Epoch 12/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.4616 - val_loss: 1.8372\n",
      "Epoch 13/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.4275 - val_loss: 1.7193\n",
      "Epoch 14/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.3623 - val_loss: 1.7943\n",
      "Epoch 15/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.3284 - val_loss: 1.9253\n",
      "Epoch 16/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.4102 - val_loss: 1.7601\n",
      "Epoch 17/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.2562 - val_loss: 1.7727\n",
      "Epoch 18/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.1994 - val_loss: 1.8458\n",
      "Epoch 19/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.1238 - val_loss: 1.7648\n",
      "Epoch 20/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.0863 - val_loss: 1.8631\n",
      "Epoch 21/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.0273 - val_loss: 1.8293\n",
      "Epoch 22/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.0221 - val_loss: 1.9334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.9352 - val_loss: 1.9379\n",
      "Epoch 00023: early stopping\n",
      "mulestudio, 440, 146\n",
      "Train on 440 samples, validate on 146 samples\n",
      "Epoch 1/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.3761 - val_loss: 5.6509\n",
      "Epoch 2/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.3628 - val_loss: 5.6360\n",
      "Epoch 3/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.3475 - val_loss: 5.6171\n",
      "Epoch 4/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.3230 - val_loss: 5.5780\n",
      "Epoch 5/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.2614 - val_loss: 5.4655\n",
      "Epoch 6/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.0809 - val_loss: 5.1455\n",
      "Epoch 7/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 3.6113 - val_loss: 4.3855\n",
      "Epoch 8/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.8698 - val_loss: 3.5095\n",
      "Epoch 9/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5653 - val_loss: 3.2917\n",
      "Epoch 10/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.5046 - val_loss: 3.3997\n",
      "Epoch 11/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.5160 - val_loss: 3.3206\n",
      "Epoch 12/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.5303 - val_loss: 3.3170\n",
      "Epoch 13/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.5181 - val_loss: 3.3049\n",
      "Epoch 14/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.5029 - val_loss: 3.3054\n",
      "Epoch 15/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.5204 - val_loss: 3.3110\n",
      "Epoch 16/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4747 - val_loss: 3.2579\n",
      "Epoch 17/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4327 - val_loss: 3.2876\n",
      "Epoch 18/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4445 - val_loss: 3.2943\n",
      "Epoch 19/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4290 - val_loss: 3.2120\n",
      "Epoch 20/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.3657 - val_loss: 3.3121\n",
      "Epoch 21/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.5085 - val_loss: 3.2349\n",
      "Epoch 22/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.3954 - val_loss: 3.3477\n",
      "Epoch 23/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.3872 - val_loss: 3.2597\n",
      "Epoch 24/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.3501 - val_loss: 3.3438\n",
      "Epoch 25/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.3058 - val_loss: 3.2384\n",
      "Epoch 26/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.1916 - val_loss: 3.4201\n",
      "Epoch 27/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.1853 - val_loss: 3.3200\n",
      "Epoch 28/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.0833 - val_loss: 3.3618\n",
      "Epoch 29/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.0322 - val_loss: 3.5016\n",
      "Epoch 30/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.9202 - val_loss: 3.3980\n",
      "Epoch 31/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 1.8525 - val_loss: 3.3929\n",
      "Epoch 00031: early stopping\n",
      "moodle, 700, 233\n",
      "Train on 700 samples, validate on 233 samples\n",
      "Epoch 1/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.8444 - val_loss: 13.9651\n",
      "Epoch 2/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.8168 - val_loss: 13.9304\n",
      "Epoch 3/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.7633 - val_loss: 13.8221\n",
      "Epoch 4/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 12.5238 - val_loss: 13.3122\n",
      "Epoch 5/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 11.6143 - val_loss: 11.5956\n",
      "Epoch 6/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 10.0524 - val_loss: 9.8809\n",
      "Epoch 7/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 9.6439 - val_loss: 9.8867\n",
      "Epoch 8/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.5448 - val_loss: 9.8960\n",
      "Epoch 9/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.4394 - val_loss: 9.8921\n",
      "Epoch 10/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.5021 - val_loss: 9.8813\n",
      "Epoch 11/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.4657 - val_loss: 9.8930\n",
      "Epoch 12/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.3903 - val_loss: 9.8926\n",
      "Epoch 13/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.4084 - val_loss: 9.9212\n",
      "Epoch 14/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.2965 - val_loss: 9.8905\n",
      "Epoch 15/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.0233 - val_loss: 9.7228\n",
      "Epoch 16/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.6194 - val_loss: 9.5690\n",
      "Epoch 17/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.1690 - val_loss: 9.7187\n",
      "Epoch 18/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.2839 - val_loss: 9.8141\n",
      "Epoch 19/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 7.7996 - val_loss: 9.5150\n",
      "Epoch 20/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 7.0403 - val_loss: 9.6111\n",
      "Epoch 21/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 6.7399 - val_loss: 9.7245\n",
      "Epoch 22/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 6.2932 - val_loss: 9.5955\n",
      "Epoch 23/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 6.0143 - val_loss: 9.8977\n",
      "Epoch 24/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 5.5816 - val_loss: 9.7908\n",
      "Epoch 25/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 5.0999 - val_loss: 9.5239\n",
      "Epoch 26/40\n",
      "700/700 [==============================] - 7s 9ms/step - loss: 4.7176 - val_loss: 9.7653\n",
      "Epoch 27/40\n",
      "700/700 [==============================] - 7s 9ms/step - loss: 4.4341 - val_loss: 9.7780\n",
      "Epoch 28/40\n",
      "700/700 [==============================] - 7s 10ms/step - loss: 4.1942 - val_loss: 9.5504\n",
      "Epoch 29/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 3.7638 - val_loss: 9.5730\n",
      "Epoch 30/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 3.6930 - val_loss: 9.6113\n",
      "Epoch 31/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 3.3782 - val_loss: 9.5588\n",
      "Epoch 00031: early stopping\n",
      "jirasoftware, 212, 70\n",
      "Train on 212 samples, validate on 70 samples\n",
      "Epoch 1/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4698 - val_loss: 2.0962\n",
      "Epoch 2/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4641 - val_loss: 2.0921\n",
      "Epoch 3/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4585 - val_loss: 2.0879\n",
      "Epoch 4/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4528 - val_loss: 2.0835\n",
      "Epoch 5/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4467 - val_loss: 2.0791\n",
      "Epoch 6/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.4404 - val_loss: 2.0745\n",
      "Epoch 7/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4341 - val_loss: 2.0697\n",
      "Epoch 8/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4275 - val_loss: 2.0646\n",
      "Epoch 9/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4199 - val_loss: 2.0588\n",
      "Epoch 10/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.4114 - val_loss: 2.0511\n",
      "Epoch 11/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.3988 - val_loss: 2.0393\n",
      "Epoch 12/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.3785 - val_loss: 2.0200\n",
      "Epoch 13/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.3460 - val_loss: 1.9889\n",
      "Epoch 14/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 3.2937 - val_loss: 1.9383\n",
      "Epoch 15/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 3.2073 - val_loss: 1.8564\n",
      "Epoch 16/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212/212 [==============================] - 2s 9ms/step - loss: 3.0669 - val_loss: 1.7259\n",
      "Epoch 17/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.8610 - val_loss: 1.5280\n",
      "Epoch 18/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.6077 - val_loss: 1.4867\n",
      "Epoch 19/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.4137 - val_loss: 1.4870\n",
      "Epoch 20/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.3107 - val_loss: 1.7228\n",
      "Epoch 21/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.2254 - val_loss: 1.9259\n",
      "Epoch 22/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1662 - val_loss: 2.0561\n",
      "Epoch 23/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1983 - val_loss: 2.0794\n",
      "Epoch 24/40\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 2.1722 - val_loss: 1.9760\n",
      "Epoch 25/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.2042 - val_loss: 1.9127\n",
      "Epoch 26/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1874 - val_loss: 1.9689\n",
      "Epoch 27/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1732 - val_loss: 2.0185\n",
      "Epoch 28/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1317 - val_loss: 2.0757\n",
      "Epoch 29/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1458 - val_loss: 1.9463\n",
      "Epoch 30/40\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 2.1106 - val_loss: 2.0063\n",
      "Epoch 00030: early stopping\n",
      "duracloud, 400, 133\n",
      "Train on 400 samples, validate on 133 samples\n",
      "Epoch 1/40\n",
      "400/400 [==============================] - 3s 9ms/step - loss: 0.9276 - val_loss: 0.6993\n",
      "Epoch 2/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 3/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 4/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 5/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 6/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 7/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 8/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 9/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 10/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 11/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 12/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 13/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 14/40\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.9275 - val_loss: 0.6992\n",
      "Epoch 00014: early stopping\n",
      "titanium, 1351, 450\n",
      "Train on 1351 samples, validate on 450 samples\n",
      "Epoch 1/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 5.0882 - val_loss: 4.4997\n",
      "Epoch 2/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 4.9510 - val_loss: 3.9989\n",
      "Epoch 3/40\n",
      "1351/1351 [==============================] - 11s 8ms/step - loss: 3.6315 - val_loss: 2.4562\n",
      "Epoch 4/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.1253 - val_loss: 2.3130\n",
      "Epoch 5/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.1275 - val_loss: 2.2894\n",
      "Epoch 6/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.1363 - val_loss: 2.3718\n",
      "Epoch 7/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.1318 - val_loss: 2.2923\n",
      "Epoch 8/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.1298 - val_loss: 2.3095\n",
      "Epoch 9/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.1217 - val_loss: 2.3654\n",
      "Epoch 10/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.1010 - val_loss: 2.3270\n",
      "Epoch 11/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.1087 - val_loss: 2.3472\n",
      "Epoch 12/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.0752 - val_loss: 2.3261\n",
      "Epoch 13/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.0330 - val_loss: 2.4654\n",
      "Epoch 14/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 3.0271 - val_loss: 2.3128\n",
      "Epoch 15/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.9508 - val_loss: 2.3043\n",
      "Epoch 16/40\n",
      "1351/1351 [==============================] - 12s 9ms/step - loss: 2.7948 - val_loss: 2.3370\n",
      "Epoch 17/40\n",
      "1351/1351 [==============================] - 13s 9ms/step - loss: 2.6334 - val_loss: 2.3706\n",
      "Epoch 00017: early stopping\n",
      "aptanastudio, 499, 165\n",
      "Train on 499 samples, validate on 165 samples\n",
      "Epoch 1/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.1488 - val_loss: 7.3703\n",
      "Epoch 2/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.1357 - val_loss: 7.3502\n",
      "Epoch 3/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 6.1197 - val_loss: 7.3228\n",
      "Epoch 4/40\n",
      "499/499 [==============================] - 5s 9ms/step - loss: 6.0899 - val_loss: 7.2470\n",
      "Epoch 5/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 5.9804 - val_loss: 6.9548\n",
      "Epoch 6/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 5.6191 - val_loss: 6.0093\n",
      "Epoch 7/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 4.7551 - val_loss: 3.9177\n",
      "Epoch 8/40\n",
      "499/499 [==============================] - 4s 8ms/step - loss: 3.8231 - val_loss: 2.6645\n",
      "Epoch 9/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.6064 - val_loss: 3.2532\n",
      "Epoch 10/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.3718 - val_loss: 2.7899\n",
      "Epoch 11/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.2810 - val_loss: 2.7665\n",
      "Epoch 12/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.3079 - val_loss: 3.0353\n",
      "Epoch 13/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.2854 - val_loss: 2.8604\n",
      "Epoch 14/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.2779 - val_loss: 3.1642\n",
      "Epoch 15/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.2108 - val_loss: 2.8834\n",
      "Epoch 16/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.2426 - val_loss: 2.9032\n",
      "Epoch 17/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.1293 - val_loss: 2.8351\n",
      "Epoch 18/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.0819 - val_loss: 2.8530\n",
      "Epoch 19/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.1696 - val_loss: 3.0483\n",
      "Epoch 20/40\n",
      "499/499 [==============================] - 4s 9ms/step - loss: 3.0792 - val_loss: 2.8446\n",
      "Epoch 00020: early stopping\n",
      "appceleratorstudio, 1753, 583\n",
      "Train on 1753 samples, validate on 583 samples\n",
      "Epoch 1/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 4.3976 - val_loss: 3.6245\n",
      "Epoch 2/40\n",
      "1753/1753 [==============================] - 15s 8ms/step - loss: 3.0283 - val_loss: 2.2191\n",
      "Epoch 3/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0489 - val_loss: 1.5266\n",
      "Epoch 4/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0646 - val_loss: 1.4816\n",
      "Epoch 5/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0614 - val_loss: 1.4625\n",
      "Epoch 6/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0430 - val_loss: 1.3978\n",
      "Epoch 7/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0263 - val_loss: 1.3880\n",
      "Epoch 8/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0355 - val_loss: 1.5207\n",
      "Epoch 9/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0279 - val_loss: 1.4480\n",
      "Epoch 10/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0192 - val_loss: 1.4901\n",
      "Epoch 11/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 2.0185 - val_loss: 1.5190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.9895 - val_loss: 1.5072\n",
      "Epoch 13/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.9488 - val_loss: 1.4140\n",
      "Epoch 14/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.8787 - val_loss: 1.5228\n",
      "Epoch 15/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.8287 - val_loss: 1.6884\n",
      "Epoch 16/40\n",
      "1753/1753 [==============================] - 15s 9ms/step - loss: 1.7170 - val_loss: 1.4884\n",
      "Epoch 17/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.6364 - val_loss: 1.8973\n",
      "Epoch 18/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.5837 - val_loss: 1.9490\n",
      "Epoch 19/40\n",
      "1753/1753 [==============================] - 16s 9ms/step - loss: 1.4975 - val_loss: 1.8753\n",
      "Epoch 00019: early stopping\n",
      "mesos, 1008, 336\n",
      "Train on 1008 samples, validate on 336 samples\n",
      "Epoch 1/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.8419 - val_loss: 1.5568\n",
      "Epoch 2/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.8230 - val_loss: 1.5383\n",
      "Epoch 3/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.7684 - val_loss: 1.4172\n",
      "Epoch 4/40\n",
      "1008/1008 [==============================] - 9s 8ms/step - loss: 1.3928 - val_loss: 1.1543\n",
      "Epoch 5/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.2371 - val_loss: 1.1502\n",
      "Epoch 6/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.2254 - val_loss: 1.1297\n",
      "Epoch 7/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1896 - val_loss: 1.1209\n",
      "Epoch 8/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1768 - val_loss: 1.1219\n",
      "Epoch 9/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1531 - val_loss: 1.1109\n",
      "Epoch 10/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1436 - val_loss: 1.1090\n",
      "Epoch 11/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1088 - val_loss: 1.1090\n",
      "Epoch 12/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.0977 - val_loss: 1.1373\n",
      "Epoch 13/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.1172 - val_loss: 1.0953\n",
      "Epoch 14/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.0361 - val_loss: 1.1374\n",
      "Epoch 15/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.0366 - val_loss: 1.0955\n",
      "Epoch 16/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.0293 - val_loss: 1.2619\n",
      "Epoch 17/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 1.0164 - val_loss: 1.1341\n",
      "Epoch 18/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.9611 - val_loss: 1.2189\n",
      "Epoch 19/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.9082 - val_loss: 1.1910\n",
      "Epoch 20/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.8787 - val_loss: 1.1174\n",
      "Epoch 21/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.8585 - val_loss: 1.1421\n",
      "Epoch 22/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.8368 - val_loss: 1.1662\n",
      "Epoch 23/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.7800 - val_loss: 1.1867\n",
      "Epoch 24/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.6918 - val_loss: 1.2510\n",
      "Epoch 25/40\n",
      "1008/1008 [==============================] - 9s 9ms/step - loss: 0.6812 - val_loss: 1.2739\n",
      "Epoch 00025: early stopping\n",
      "springxd, 2116, 705\n",
      "Train on 2116 samples, validate on 705 samples\n",
      "Epoch 1/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 2.4883 - val_loss: 2.5544\n",
      "Epoch 2/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 2.2151 - val_loss: 1.8574\n",
      "Epoch 3/40\n",
      "2116/2116 [==============================] - 18s 9ms/step - loss: 1.8267 - val_loss: 1.7800\n",
      "Epoch 4/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.7736 - val_loss: 1.7846\n",
      "Epoch 5/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.7597 - val_loss: 1.7665\n",
      "Epoch 6/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.7216 - val_loss: 1.7994\n",
      "Epoch 7/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.6901 - val_loss: 1.8250\n",
      "Epoch 8/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.6499 - val_loss: 1.8220\n",
      "Epoch 9/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.6656 - val_loss: 1.7489\n",
      "Epoch 10/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.5747 - val_loss: 1.8244\n",
      "Epoch 11/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.5788 - val_loss: 1.7719\n",
      "Epoch 12/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.5045 - val_loss: 1.7409\n",
      "Epoch 13/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.4825 - val_loss: 1.8136\n",
      "Epoch 14/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.4179 - val_loss: 1.7639\n",
      "Epoch 15/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.3645 - val_loss: 1.8076\n",
      "Epoch 16/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.3079 - val_loss: 1.7575\n",
      "Epoch 17/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.2534 - val_loss: 1.7467\n",
      "Epoch 18/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.2233 - val_loss: 1.7713\n",
      "Epoch 19/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.1959 - val_loss: 1.7627\n",
      "Epoch 20/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.1012 - val_loss: 1.7578\n",
      "Epoch 21/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.0646 - val_loss: 1.8072\n",
      "Epoch 22/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 1.0447 - val_loss: 1.8919\n",
      "Epoch 23/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.9922 - val_loss: 1.7909\n",
      "Epoch 24/40\n",
      "2116/2116 [==============================] - 19s 9ms/step - loss: 0.9259 - val_loss: 1.7752\n",
      "Epoch 00024: early stopping\n",
      "mulestudio, 440, 146\n",
      "Train on 440 samples, validate on 146 samples\n",
      "Epoch 1/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.3764 - val_loss: 5.6516\n",
      "Epoch 2/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 4.3641 - val_loss: 5.6384\n",
      "Epoch 3/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.3512 - val_loss: 5.6239\n",
      "Epoch 4/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.3366 - val_loss: 5.6060\n",
      "Epoch 5/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.3122 - val_loss: 5.5617\n",
      "Epoch 6/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 4.2331 - val_loss: 5.4105\n",
      "Epoch 7/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 3.9718 - val_loss: 4.9251\n",
      "Epoch 8/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 3.3235 - val_loss: 3.9189\n",
      "Epoch 9/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.6626 - val_loss: 3.2886\n",
      "Epoch 10/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.5419 - val_loss: 3.4036\n",
      "Epoch 11/40\n",
      "440/440 [==============================] - 4s 8ms/step - loss: 2.5250 - val_loss: 3.2833\n",
      "Epoch 12/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4922 - val_loss: 3.3362\n",
      "Epoch 13/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.5400 - val_loss: 3.2938\n",
      "Epoch 14/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4687 - val_loss: 3.3453\n",
      "Epoch 15/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4808 - val_loss: 3.3006\n",
      "Epoch 16/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4710 - val_loss: 3.2846\n",
      "Epoch 17/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4559 - val_loss: 3.3200\n",
      "Epoch 18/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4597 - val_loss: 3.3221\n",
      "Epoch 19/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4917 - val_loss: 3.3177\n",
      "Epoch 20/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.4304 - val_loss: 3.2834\n",
      "Epoch 21/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440/440 [==============================] - 4s 9ms/step - loss: 2.3921 - val_loss: 3.3340\n",
      "Epoch 22/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.3421 - val_loss: 3.2924\n",
      "Epoch 23/40\n",
      "440/440 [==============================] - 4s 9ms/step - loss: 2.3184 - val_loss: 3.3477\n",
      "Epoch 00023: early stopping\n",
      "moodle, 700, 233\n",
      "Train on 700 samples, validate on 233 samples\n",
      "Epoch 1/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.8446 - val_loss: 13.9660\n",
      "Epoch 2/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.8171 - val_loss: 13.9286\n",
      "Epoch 3/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.7379 - val_loss: 13.7277\n",
      "Epoch 4/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 12.2145 - val_loss: 12.5212\n",
      "Epoch 5/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 10.5480 - val_loss: 10.0951\n",
      "Epoch 6/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.5953 - val_loss: 9.9132\n",
      "Epoch 7/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.5905 - val_loss: 9.8793\n",
      "Epoch 8/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.5186 - val_loss: 9.8884\n",
      "Epoch 9/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.4563 - val_loss: 9.8770\n",
      "Epoch 10/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.4255 - val_loss: 9.8846\n",
      "Epoch 11/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.2893 - val_loss: 9.8943\n",
      "Epoch 12/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.2251 - val_loss: 9.9683\n",
      "Epoch 13/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.1134 - val_loss: 10.0456\n",
      "Epoch 14/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 9.0488 - val_loss: 9.9987\n",
      "Epoch 15/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.6923 - val_loss: 9.9300\n",
      "Epoch 16/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.6978 - val_loss: 9.7128\n",
      "Epoch 17/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.1995 - val_loss: 9.5365\n",
      "Epoch 18/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 8.0885 - val_loss: 9.6532\n",
      "Epoch 19/40\n",
      "700/700 [==============================] - 7s 9ms/step - loss: 7.6456 - val_loss: 9.3453\n",
      "Epoch 20/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 7.6247 - val_loss: 9.8548\n",
      "Epoch 21/40\n",
      "352/700 [==============>...............] - ETA: 2s - loss: 6.8818"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-392-50268722af40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0msave_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_data_path\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_weights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mlog_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCSVLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_data_path\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mhist_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstory_points_clip\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstory_points_clip\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msave_best\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0msave_to_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist_data_path\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdeepse_baseline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.95\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/theano/scan_module/scan_op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[1;32m    961\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[1;32m    962\u001b[0m                  allow_gc=allow_gc):\n\u001b[0;32m--> 963\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/theano/scan_module/scan_op.py\u001b[0m in \u001b[0;36mp\u001b[0;34m(node, args, outs)\u001b[0m\n\u001b[1;32m    950\u001b[0m                                                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m                                                 \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m                                                 self, node)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mscan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/theano/tensor/type.py\u001b[0m in \u001b[0;36mvalue_zeros\u001b[0;34m(self, shape)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mvalue_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m         \"\"\"\n\u001b[1;32m    554\u001b[0m         \u001b[0mCreate\u001b[0m \u001b[0man\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0mndarray\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mof\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"1280697e-938a-43c2-9f72-4248a5942802\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"1280697e-938a-43c2-9f72-4248a5942802\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell Execution Has Finished!!\", \"autonotify_after\": \"10\", \"autonotify_output\": false};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "while len(rerodar) > 0 and i < 1000:\n",
    "    i += 1\n",
    "    project = rerodar.pop()\n",
    "    story_words, story_points = ler_csv_texto_tokenizado(train_data_path % project, nlp.tokenizer)\n",
    "    dic = load_pickle(dic_data_path % project_repos[project])\n",
    "    x_train, x_val, x_test = converte_tokens_treino(story_words, dic)\n",
    "    y_train = story_points[:x_train.shape[0]].reshape((-1, 1))\n",
    "    y_val = story_points[x_train.shape[0]:x_train.shape[0]+x_val.shape[0]].reshape((-1, 1))\n",
    "    y_test = story_points[x_train.shape[0] + x_val.shape[0]:].reshape((-1, 1))\n",
    "\n",
    "    print_log_out(\"%s, %d, %d\" % (project, x_train.shape[0], x_val.shape[0]))\n",
    "\n",
    "    mod_train = create_train_model(len(dic))\n",
    "    mod_emb.load_weights(model_pre_data_path % project_repos[project])\n",
    "    initialize_train_model(mod_train, mod_emb.get_layer('vetorizacao').get_weights(), np.median(np.clip(y_train, 1, story_points_clip[project])))\n",
    "\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=12, min_delta=0)\n",
    "    save_best = keras.callbacks.ModelCheckpoint(model_data_path % project, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)\n",
    "    log_csv = keras.callbacks.CSVLogger(log_data_path % project)\n",
    "    hist_train = mod_train.fit(x_train, np.clip(y_train, 1, story_points_clip[project]), epochs=40, validation_data=(x_val, np.clip(y_val, 1, story_points_clip[project])), callbacks=[save_best, log_csv, early_stopping])\n",
    "    save_to_pickle(hist_train.history, hist_data_path % project)\n",
    "    if min(hist_train.history['val_loss'])/deepse_baseline[project] > 0.95:\n",
    "        rerodar.insert(0, project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"5e0f961e-cfaf-4a04-bf03-f32844537b2e\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"5e0f961e-cfaf-4a04-bf03-f32844537b2e\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell Execution Has Finished!!\", \"autonotify_after\": \"10\", \"autonotify_output\": false};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "project = 'datamanagement'\n",
    "story_words, story_points = ler_csv_texto_tokenizado(train_data_path % project, nlp.tokenizer)\n",
    "dic = load_pickle(dic_data_path % project_repos[project])\n",
    "x_train, x_val, x_test = converte_tokens_treino(story_words, dic)\n",
    "y_train = story_points[:x_train.shape[0]].reshape((-1, 1))\n",
    "y_val = story_points[x_train.shape[0]:x_train.shape[0]+x_val.shape[0]].reshape((-1, 1))\n",
    "y_test = story_points[x_train.shape[0] + x_val.shape[0]:].reshape((-1, 1))\n",
    "mod_train = create_train_model(len(dic))\n",
    "mod_train.load_weights(model_data_path % project)\n",
    "val_pred = mod_train.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1600x1000 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figura = plt.figure(figsize=(8, 5), dpi=200)\n",
    "plt.xlabel(\"Predicted Story Points\")\n",
    "plt.ylabel(\"True story points clipped\")\n",
    "plt.title(\"%s User Stories\" % project_name[project])\n",
    "sns.regplot(val_pred.ravel(), y_val.clip(1, 21).ravel())\n",
    "plt.plot()\n",
    "figura.savefig(\"results/figures/\"+project+\"-vs-true.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 233 samples\n",
      "Epoch 1/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 1.8371 - val_loss: 1.9356\n",
      "Epoch 2/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 1.8371 - val_loss: 1.9356\n",
      "Epoch 3/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 1.8371 - val_loss: 1.9356\n",
      "Epoch 4/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 1.8371 - val_loss: 1.9356\n",
      "Epoch 5/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 1.8371 - val_loss: 1.9356\n",
      "Epoch 6/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 1.8371 - val_loss: 1.9356\n",
      "Epoch 7/40\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 1.8371 - val_loss: 1.9356\n",
      "Epoch 8/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 1.8371 - val_loss: 1.9356\n",
      "Epoch 9/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 1.8371 - val_loss: 1.9356\n",
      "Epoch 10/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 1.8371 - val_loss: 1.9356\n",
      "Epoch 11/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 1.8371 - val_loss: 1.9356\n",
      "Epoch 12/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 1.8371 - val_loss: 1.9356\n",
      "Epoch 13/40\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 1.8371 - val_loss: 1.9356\n",
      "Epoch 00013: early stopping\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"7cfed4b9-5fb4-4893-9932-1f4f9ae96230\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"7cfed4b9-5fb4-4893-9932-1f4f9ae96230\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell Execution Has Finished!!\", \"autonotify_after\": \"10\", \"autonotify_output\": false};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "initialize_train_model(mod_train, mod_emb.get_layer('vetorizacao').get_weights(), 0)\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=12, min_delta=0)\n",
    "save_best = keras.callbacks.ModelCheckpoint(model_data_path % project, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)\n",
    "log_csv = keras.callbacks.CSVLogger(log_data_path % project)\n",
    "hist_train = mod_train.fit(x_train, np.clip(y_train, 1, story_points_clip[project]), epochs=40, validation_data=(x_val, np.clip(y_val, 1, story_points_clip[project])), callbacks=[save_best, log_csv, early_stopping])\n",
    "save_to_pickle(hist_train.history, hist_data_path % project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'talendesb'"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.828571"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs(np.median(y_train)-y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[92.],\n",
       "       [92.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [ 5.],\n",
       "       [92.],\n",
       "       [92.],\n",
       "       [ 4.],\n",
       "       [ 0.],\n",
       "       [32.],\n",
       "       [12.],\n",
       "       [32.],\n",
       "       [92.],\n",
       "       [92.],\n",
       "       [ 6.],\n",
       "       [ 5.],\n",
       "       [32.],\n",
       "       [32.],\n",
       "       [32.],\n",
       "       [12.],\n",
       "       [ 5.],\n",
       "       [32.],\n",
       "       [ 0.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [12.],\n",
       "       [ 3.],\n",
       "       [92.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 6.],\n",
       "       [12.],\n",
       "       [ 3.],\n",
       "       [ 0.],\n",
       "       [92.],\n",
       "       [12.],\n",
       "       [32.],\n",
       "       [ 5.],\n",
       "       [ 4.],\n",
       "       [12.],\n",
       "       [ 5.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [ 0.],\n",
       "       [ 5.],\n",
       "       [32.],\n",
       "       [32.],\n",
       "       [ 3.],\n",
       "       [ 5.],\n",
       "       [92.],\n",
       "       [ 0.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [92.],\n",
       "       [92.],\n",
       "       [12.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 6.],\n",
       "       [ 6.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [92.],\n",
       "       [ 3.],\n",
       "       [ 0.],\n",
       "       [ 5.],\n",
       "       [ 4.],\n",
       "       [ 0.],\n",
       "       [ 7.],\n",
       "       [ 0.],\n",
       "       [12.],\n",
       "       [ 5.],\n",
       "       [ 0.],\n",
       "       [ 5.],\n",
       "       [92.],\n",
       "       [12.],\n",
       "       [ 0.],\n",
       "       [32.],\n",
       "       [ 7.],\n",
       "       [ 5.],\n",
       "       [12.],\n",
       "       [32.],\n",
       "       [12.],\n",
       "       [32.],\n",
       "       [ 7.],\n",
       "       [ 3.],\n",
       "       [ 0.],\n",
       "       [ 5.],\n",
       "       [ 3.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 5.],\n",
       "       [ 6.],\n",
       "       [ 5.],\n",
       "       [ 0.],\n",
       "       [ 6.],\n",
       "       [ 5.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 6.],\n",
       "       [ 0.],\n",
       "       [ 3.],\n",
       "       [ 5.],\n",
       "       [12.],\n",
       "       [ 0.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [ 5.],\n",
       "       [12.],\n",
       "       [ 5.],\n",
       "       [92.],\n",
       "       [92.],\n",
       "       [32.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [12.],\n",
       "       [ 3.],\n",
       "       [92.],\n",
       "       [ 5.],\n",
       "       [12.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 5.],\n",
       "       [ 0.],\n",
       "       [ 5.],\n",
       "       [32.],\n",
       "       [ 0.],\n",
       "       [ 5.],\n",
       "       [32.],\n",
       "       [ 5.],\n",
       "       [ 6.],\n",
       "       [ 5.],\n",
       "       [12.],\n",
       "       [ 3.],\n",
       "       [ 6.],\n",
       "       [32.],\n",
       "       [ 5.],\n",
       "       [ 0.],\n",
       "       [32.],\n",
       "       [ 5.],\n",
       "       [12.],\n",
       "       [32.],\n",
       "       [ 5.],\n",
       "       [92.],\n",
       "       [ 5.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 5.],\n",
       "       [32.],\n",
       "       [ 3.],\n",
       "       [ 0.],\n",
       "       [ 3.],\n",
       "       [ 5.],\n",
       "       [32.],\n",
       "       [ 6.],\n",
       "       [ 0.],\n",
       "       [92.],\n",
       "       [ 5.],\n",
       "       [92.],\n",
       "       [ 6.],\n",
       "       [32.],\n",
       "       [ 5.],\n",
       "       [ 3.],\n",
       "       [12.],\n",
       "       [ 3.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 5.],\n",
       "       [ 6.],\n",
       "       [ 3.],\n",
       "       [ 5.],\n",
       "       [92.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [ 3.],\n",
       "       [ 0.],\n",
       "       [92.],\n",
       "       [ 0.],\n",
       "       [32.],\n",
       "       [12.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 3.],\n",
       "       [12.],\n",
       "       [ 3.],\n",
       "       [ 5.],\n",
       "       [12.],\n",
       "       [ 5.],\n",
       "       [32.],\n",
       "       [ 5.],\n",
       "       [92.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [ 3.],\n",
       "       [ 3.],\n",
       "       [52.],\n",
       "       [32.],\n",
       "       [ 3.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [12.],\n",
       "       [92.],\n",
       "       [ 5.],\n",
       "       [32.],\n",
       "       [12.],\n",
       "       [32.],\n",
       "       [12.],\n",
       "       [ 0.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [ 0.],\n",
       "       [32.],\n",
       "       [12.],\n",
       "       [32.],\n",
       "       [ 3.],\n",
       "       [12.],\n",
       "       [32.],\n",
       "       [ 5.],\n",
       "       [ 3.],\n",
       "       [12.],\n",
       "       [32.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [ 5.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [32.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [ 5.],\n",
       "       [32.],\n",
       "       [32.],\n",
       "       [32.],\n",
       "       [32.],\n",
       "       [32.],\n",
       "       [32.],\n",
       "       [32.],\n",
       "       [32.],\n",
       "       [32.],\n",
       "       [92.],\n",
       "       [32.],\n",
       "       [ 6.],\n",
       "       [ 0.],\n",
       "       [ 3.],\n",
       "       [ 3.],\n",
       "       [ 0.],\n",
       "       [32.],\n",
       "       [ 5.],\n",
       "       [ 3.],\n",
       "       [ 3.],\n",
       "       [32.],\n",
       "       [ 0.],\n",
       "       [ 5.],\n",
       "       [ 3.],\n",
       "       [ 3.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [92.],\n",
       "       [ 5.],\n",
       "       [32.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [12.],\n",
       "       [ 3.],\n",
       "       [ 0.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [ 0.],\n",
       "       [32.],\n",
       "       [ 6.],\n",
       "       [ 5.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [22.],\n",
       "       [32.],\n",
       "       [12.],\n",
       "       [ 5.],\n",
       "       [ 0.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [ 0.],\n",
       "       [12.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [12.],\n",
       "       [ 0.],\n",
       "       [32.],\n",
       "       [ 0.],\n",
       "       [ 5.],\n",
       "       [ 3.],\n",
       "       [92.],\n",
       "       [ 5.],\n",
       "       [ 0.],\n",
       "       [32.],\n",
       "       [12.],\n",
       "       [ 5.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [12.],\n",
       "       [ 0.],\n",
       "       [32.],\n",
       "       [ 0.],\n",
       "       [ 4.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 3.],\n",
       "       [12.],\n",
       "       [ 7.],\n",
       "       [92.],\n",
       "       [ 0.],\n",
       "       [ 6.],\n",
       "       [ 5.],\n",
       "       [44.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 6.],\n",
       "       [ 0.],\n",
       "       [ 6.],\n",
       "       [ 3.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 6.],\n",
       "       [ 3.],\n",
       "       [ 3.],\n",
       "       [ 3.],\n",
       "       [ 5.],\n",
       "       [ 4.],\n",
       "       [ 5.],\n",
       "       [ 6.],\n",
       "       [ 5.],\n",
       "       [ 0.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 0.],\n",
       "       [ 3.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [32.],\n",
       "       [ 0.],\n",
       "       [12.],\n",
       "       [ 3.],\n",
       "       [ 5.],\n",
       "       [ 0.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [12.],\n",
       "       [32.],\n",
       "       [12.],\n",
       "       [32.],\n",
       "       [92.],\n",
       "       [ 3.],\n",
       "       [ 6.],\n",
       "       [ 5.],\n",
       "       [12.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 3.],\n",
       "       [12.],\n",
       "       [ 7.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 7.],\n",
       "       [ 6.],\n",
       "       [ 5.],\n",
       "       [12.],\n",
       "       [ 6.],\n",
       "       [ 7.],\n",
       "       [12.],\n",
       "       [ 7.],\n",
       "       [92.],\n",
       "       [12.],\n",
       "       [ 0.],\n",
       "       [ 7.],\n",
       "       [ 6.],\n",
       "       [ 6.],\n",
       "       [92.],\n",
       "       [ 5.],\n",
       "       [ 6.],\n",
       "       [32.],\n",
       "       [ 6.],\n",
       "       [ 0.],\n",
       "       [ 5.],\n",
       "       [ 6.],\n",
       "       [ 3.],\n",
       "       [ 0.],\n",
       "       [ 7.],\n",
       "       [12.],\n",
       "       [ 0.],\n",
       "       [ 5.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 4.],\n",
       "       [ 5.],\n",
       "       [ 3.],\n",
       "       [92.],\n",
       "       [92.],\n",
       "       [ 6.],\n",
       "       [92.],\n",
       "       [ 3.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [12.],\n",
       "       [32.],\n",
       "       [32.],\n",
       "       [ 6.],\n",
       "       [ 3.],\n",
       "       [12.],\n",
       "       [ 4.],\n",
       "       [ 0.],\n",
       "       [ 6.],\n",
       "       [ 6.],\n",
       "       [ 5.],\n",
       "       [ 6.],\n",
       "       [16.],\n",
       "       [ 3.],\n",
       "       [ 3.],\n",
       "       [ 7.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 6.],\n",
       "       [ 3.],\n",
       "       [32.],\n",
       "       [ 3.],\n",
       "       [ 3.],\n",
       "       [12.],\n",
       "       [ 5.],\n",
       "       [ 6.],\n",
       "       [ 5.],\n",
       "       [12.],\n",
       "       [ 7.],\n",
       "       [12.],\n",
       "       [ 0.],\n",
       "       [ 5.],\n",
       "       [ 4.],\n",
       "       [ 5.],\n",
       "       [ 7.],\n",
       "       [ 6.],\n",
       "       [32.],\n",
       "       [32.],\n",
       "       [ 3.],\n",
       "       [ 6.],\n",
       "       [ 3.],\n",
       "       [ 6.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 6.],\n",
       "       [92.],\n",
       "       [ 5.],\n",
       "       [ 0.],\n",
       "       [ 5.],\n",
       "       [ 6.],\n",
       "       [ 6.],\n",
       "       [ 7.],\n",
       "       [ 6.],\n",
       "       [ 5.],\n",
       "       [12.],\n",
       "       [ 7.],\n",
       "       [ 3.],\n",
       "       [ 0.],\n",
       "       [ 5.],\n",
       "       [ 6.],\n",
       "       [ 0.],\n",
       "       [ 6.],\n",
       "       [ 0.],\n",
       "       [ 3.],\n",
       "       [ 5.],\n",
       "       [ 0.],\n",
       "       [ 4.],\n",
       "       [ 5.],\n",
       "       [ 3.],\n",
       "       [ 3.],\n",
       "       [ 3.],\n",
       "       [12.],\n",
       "       [ 0.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [ 3.],\n",
       "       [ 6.],\n",
       "       [ 6.],\n",
       "       [32.],\n",
       "       [12.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [33.],\n",
       "       [ 7.],\n",
       "       [ 3.],\n",
       "       [12.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 3.],\n",
       "       [ 5.],\n",
       "       [ 6.],\n",
       "       [ 5.],\n",
       "       [ 7.],\n",
       "       [ 5.],\n",
       "       [ 6.],\n",
       "       [ 5.],\n",
       "       [ 6.],\n",
       "       [ 3.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 7.],\n",
       "       [ 6.],\n",
       "       [ 6.],\n",
       "       [12.],\n",
       "       [ 3.],\n",
       "       [ 5.],\n",
       "       [ 3.],\n",
       "       [ 7.],\n",
       "       [ 7.],\n",
       "       [ 3.],\n",
       "       [ 5.],\n",
       "       [ 0.],\n",
       "       [ 5.],\n",
       "       [ 6.],\n",
       "       [ 3.],\n",
       "       [ 0.],\n",
       "       [ 3.],\n",
       "       [ 5.],\n",
       "       [12.],\n",
       "       [ 0.],\n",
       "       [ 3.],\n",
       "       [ 0.],\n",
       "       [12.],\n",
       "       [ 3.],\n",
       "       [ 5.],\n",
       "       [ 7.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [12.],\n",
       "       [ 5.],\n",
       "       [ 6.],\n",
       "       [ 3.],\n",
       "       [32.],\n",
       "       [12.],\n",
       "       [ 3.],\n",
       "       [ 0.],\n",
       "       [ 6.],\n",
       "       [ 5.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [92.],\n",
       "       [ 0.],\n",
       "       [ 3.],\n",
       "       [ 3.],\n",
       "       [92.],\n",
       "       [ 5.],\n",
       "       [ 3.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 0.],\n",
       "       [32.],\n",
       "       [ 0.],\n",
       "       [12.],\n",
       "       [ 5.],\n",
       "       [ 0.],\n",
       "       [ 4.],\n",
       "       [ 2.],\n",
       "       [ 3.],\n",
       "       [ 0.],\n",
       "       [ 3.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 0.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 6.],\n",
       "       [ 6.],\n",
       "       [ 6.],\n",
       "       [ 5.],\n",
       "       [32.],\n",
       "       [12.],\n",
       "       [ 3.],\n",
       "       [ 3.],\n",
       "       [ 3.],\n",
       "       [ 6.],\n",
       "       [12.],\n",
       "       [ 0.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 0.],\n",
       "       [ 5.],\n",
       "       [92.],\n",
       "       [ 6.],\n",
       "       [ 3.],\n",
       "       [ 3.],\n",
       "       [ 3.],\n",
       "       [ 0.],\n",
       "       [ 5.],\n",
       "       [32.],\n",
       "       [12.],\n",
       "       [32.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [ 5.],\n",
       "       [ 3.],\n",
       "       [ 5.],\n",
       "       [ 3.],\n",
       "       [ 5.],\n",
       "       [ 3.],\n",
       "       [ 3.],\n",
       "       [ 5.],\n",
       "       [ 4.],\n",
       "       [ 0.],\n",
       "       [32.],\n",
       "       [ 4.],\n",
       "       [92.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 0.],\n",
       "       [ 3.],\n",
       "       [12.],\n",
       "       [ 6.],\n",
       "       [ 3.],\n",
       "       [ 5.],\n",
       "       [ 6.],\n",
       "       [ 6.],\n",
       "       [ 3.],\n",
       "       [ 6.],\n",
       "       [ 6.],\n",
       "       [ 6.],\n",
       "       [ 6.],\n",
       "       [ 4.],\n",
       "       [12.],\n",
       "       [ 6.],\n",
       "       [ 6.],\n",
       "       [ 6.],\n",
       "       [ 6.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [ 3.],\n",
       "       [ 6.],\n",
       "       [12.],\n",
       "       [ 5.],\n",
       "       [ 4.],\n",
       "       [ 3.],\n",
       "       [ 3.],\n",
       "       [ 3.],\n",
       "       [ 3.],\n",
       "       [ 0.],\n",
       "       [ 5.],\n",
       "       [ 3.],\n",
       "       [ 5.],\n",
       "       [ 6.],\n",
       "       [ 0.],\n",
       "       [12.],\n",
       "       [92.],\n",
       "       [ 0.],\n",
       "       [ 3.],\n",
       "       [ 5.],\n",
       "       [ 0.],\n",
       "       [ 6.],\n",
       "       [12.],\n",
       "       [32.],\n",
       "       [32.],\n",
       "       [ 5.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [32.],\n",
       "       [ 0.],\n",
       "       [12.],\n",
       "       [ 3.],\n",
       "       [ 3.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 4.]], dtype=float32)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(np.median(y_train)-y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_view = keras.models.Model(inputs=mod_train.inputs, outputs=[l.output for l in mod_train.layers[-8:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = mod_view.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.14467707,  0.23685238,  0.20907314, ..., -0.32219583,\n",
       "          0.29074582, -0.17047694],\n",
       "        [-0.33806506,  0.12037657, -0.00831316, ...,  0.10898098,\n",
       "          0.2249496 , -0.03225243],\n",
       "        [-0.17766905,  0.22341484,  0.34362593, ..., -0.13149364,\n",
       "          0.42171258, -0.41371283],\n",
       "        ...,\n",
       "        [-0.3271362 ,  0.3220314 ,  0.0252365 , ..., -0.29262614,\n",
       "         -0.04274324, -0.03021637],\n",
       "        [-0.08314551, -0.33722562,  0.03482156, ...,  0.05930808,\n",
       "          0.24999262, -0.23202918],\n",
       "        [-0.0263191 ,  0.22709176,  0.23832202, ..., -0.3469512 ,\n",
       "          0.22751883, -0.01288723]], dtype=float32),\n",
       " array([[-0.14467707,  0.23685238,  0.20907314, ..., -0.32219583,\n",
       "          0.29074582, -0.17047694],\n",
       "        [-0.33806506,  0.12037657, -0.00831316, ...,  0.10898098,\n",
       "          0.2249496 , -0.03225243],\n",
       "        [-0.17766905,  0.22341484,  0.34362593, ..., -0.13149364,\n",
       "          0.42171258, -0.41371283],\n",
       "        ...,\n",
       "        [-0.3271362 ,  0.3220314 ,  0.0252365 , ..., -0.29262614,\n",
       "         -0.04274324, -0.03021637],\n",
       "        [-0.08314551, -0.33722562,  0.03482156, ...,  0.05930808,\n",
       "          0.24999262, -0.23202918],\n",
       "        [-0.0263191 ,  0.22709176,  0.23832202, ..., -0.3469512 ,\n",
       "          0.22751883, -0.01288723]], dtype=float32),\n",
       " array([[0.06630167, 0.03850487, 0.01676571, ..., 0.01333141, 0.        ,\n",
       "         0.04750503],\n",
       "        [0.        , 0.        , 0.02211805, ..., 0.        , 0.0530115 ,\n",
       "         0.        ],\n",
       "        [0.07718627, 0.04242678, 0.03428956, ..., 0.02154081, 0.03211224,\n",
       "         0.01348259],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.02645495, ..., 0.        , 0.        ,\n",
       "         0.02160238],\n",
       "        [0.00601609, 0.        , 0.        , ..., 0.01812596, 0.        ,\n",
       "         0.        ],\n",
       "        [0.03258604, 0.01622452, 0.01178108, ..., 0.00663078, 0.        ,\n",
       "         0.05566054]], dtype=float32),\n",
       " array([[0.06630167, 0.03850487, 0.01676571, ..., 0.01333141, 0.        ,\n",
       "         0.04750503],\n",
       "        [0.        , 0.        , 0.02211805, ..., 0.        , 0.0530115 ,\n",
       "         0.        ],\n",
       "        [0.07718627, 0.04242678, 0.03428956, ..., 0.02154081, 0.03211224,\n",
       "         0.01348259],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.02645495, ..., 0.        , 0.        ,\n",
       "         0.02160238],\n",
       "        [0.00601609, 0.        , 0.        , ..., 0.01812596, 0.        ,\n",
       "         0.        ],\n",
       "        [0.03258604, 0.01622452, 0.01178108, ..., 0.00663078, 0.        ,\n",
       "         0.05566054]], dtype=float32),\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " array([[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "         0.0000000e+00, 3.0843123e-05],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "         0.0000000e+00, 1.4080113e-05],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        ...,\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "         0.0000000e+00, 2.0774823e-05],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "         0.0000000e+00, 2.5344492e-05]], dtype=float32),\n",
       " array([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]], dtype=float32)]"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.recurrent.LSTM at 0x7f3bc0f88828>,\n",
       " <keras.layers.core.Dropout at 0x7f3ba43495f8>,\n",
       " <__main__.CamadaHipercubo at 0x7f3a8da2dd30>,\n",
       " <keras.layers.core.Dropout at 0x7f3bc0d6b710>,\n",
       " <__main__.CamadaHipercubo at 0x7f3bc0d6b208>,\n",
       " <__main__.CamadaHipercubo at 0x7f3ba4d35470>,\n",
       " <__main__.CamadaHipercubo at 0x7f3b716138d0>]"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_train.layers[-8:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12072.0"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.01158899, -0.03165118, -0.01472145, ..., -0.03753223,\n",
       "         -0.0183831 ,  0.03914304],\n",
       "        [ 0.16900912,  0.00520417,  0.30961126, ..., -0.29867357,\n",
       "         -0.09086336, -0.27886   ],\n",
       "        [ 0.12684323, -0.00819551, -0.47751638, ..., -0.5539134 ,\n",
       "          0.09783418,  1.1602142 ],\n",
       "        ...,\n",
       "        [-0.16045798,  2.2415278 , -1.594621  , ..., -2.0644898 ,\n",
       "          0.52367055, -0.5228918 ],\n",
       "        [-1.0635546 , -2.665689  ,  0.51050216, ..., -3.9606671 ,\n",
       "          1.3807639 , -0.524296  ],\n",
       "        [ 1.8221983 , -0.5494846 ,  0.29670298, ..., -1.0804262 ,\n",
       "          1.2936594 , -0.944587  ]], dtype=float32),\n",
       " array([[ 6.4449599e-03,  8.2292818e-02,  7.5516000e-02, ...,\n",
       "          1.0827334e-01,  6.0835830e-03,  6.7105897e-02],\n",
       "        [-8.7636620e-02,  1.2118631e-01,  4.1706558e-02, ...,\n",
       "         -1.0539040e-01, -4.7594115e-02, -3.8659345e-02],\n",
       "        [ 6.0473181e-02, -2.4698034e-02,  4.8264809e-02, ...,\n",
       "         -5.0183110e-02,  5.0813414e-02, -6.6307381e-02],\n",
       "        ...,\n",
       "        [ 1.0290567e-01, -1.3516164e-01, -6.2627830e-02, ...,\n",
       "         -4.6780404e-02,  5.9871335e-02,  7.9365104e-02],\n",
       "        [ 1.3434698e-04,  1.1287434e-01,  1.3439830e-01, ...,\n",
       "         -8.1019565e-02, -3.3483624e-03, -1.6447380e-02],\n",
       "        [-4.5323279e-02,  9.7264372e-02, -1.2949914e-01, ...,\n",
       "         -1.8399432e-02, -5.4613072e-02, -7.7241279e-02]], dtype=float32),\n",
       " array([[ 0.0513906 ,  0.03671016,  0.00352332, ...,  0.02269876,\n",
       "          0.11297096, -0.02759799],\n",
       "        [-0.0846251 ,  0.05511091, -0.06429237, ...,  0.03067883,\n",
       "          0.04379601,  0.06914884],\n",
       "        [-0.07368883, -0.01650875,  0.00062856, ..., -0.07553037,\n",
       "          0.03195083, -0.02168508],\n",
       "        ...,\n",
       "        [ 0.02566341, -0.00660698, -0.03617902, ..., -0.03482486,\n",
       "         -0.05483424,  0.03206326],\n",
       "        [ 0.14103413, -0.02587899, -0.01443759, ..., -0.07555373,\n",
       "         -0.01021839, -0.03910029],\n",
       "        [ 0.00869076, -0.06054616, -0.07044671, ...,  0.00246477,\n",
       "          0.12457461,  0.03298557]], dtype=float32),\n",
       " array([ 7.69715043e-05,  2.45793199e-04, -7.09511631e-04,  2.58345768e-04,\n",
       "         2.09912469e-04,  1.75424502e-04,  2.14603700e-04,  2.24488394e-04,\n",
       "        -7.17306757e-05, -1.47556435e-04, -4.22381127e-04, -2.15348118e-04,\n",
       "        -5.56329287e-05,  2.81284621e-04, -3.98978969e-04, -5.60314103e-04,\n",
       "        -5.71925135e-04,  4.08307620e-04, -3.00426327e-04,  3.45741602e-04,\n",
       "         8.99621155e-05, -4.98275913e-04, -9.09046721e-05, -6.13670447e-04,\n",
       "         1.73559762e-04, -8.56990591e-05, -7.00808887e-05, -9.12076939e-05,\n",
       "        -1.42134741e-04, -5.94447134e-04, -1.57300819e-04, -3.26141708e-05,\n",
       "        -1.97574424e-04,  4.38272575e-04, -2.15154549e-04, -2.82278255e-04,\n",
       "        -2.93849530e-06,  3.27489077e-04,  3.01155378e-04,  5.17091394e-05,\n",
       "        -2.15652210e-04, -2.09909587e-04, -1.09545756e-04,  1.11923211e-04,\n",
       "         5.97647704e-05,  1.22805268e-05, -4.03436570e-04, -1.29195498e-04,\n",
       "         1.80171744e-04, -2.12912666e-04,  3.08599876e-04,  1.58333292e-04,\n",
       "         8.29303099e-06, -1.05479630e-04,  2.03428499e-04,  5.25079085e-04,\n",
       "         1.34237140e-04, -2.89109128e-04, -4.19328389e-05, -6.89690132e-05,\n",
       "        -7.11246248e-05, -5.41695481e-05, -9.73702845e-05,  7.25131540e-05,\n",
       "         1.00113118e+00,  1.00026464e+00,  9.99102950e-01,  1.00021029e+00,\n",
       "         1.00004566e+00,  1.00038683e+00,  1.00032556e+00,  1.00090778e+00,\n",
       "         1.00000787e+00,  9.99710500e-01,  9.99044418e-01,  9.99285281e-01,\n",
       "         9.99934375e-01,  1.00070763e+00,  9.98650551e-01,  9.99896884e-01,\n",
       "         9.99655128e-01,  1.00075734e+00,  9.98776138e-01,  9.99923944e-01,\n",
       "         1.00041175e+00,  9.98972833e-01,  9.99980867e-01,  9.98916447e-01,\n",
       "         1.00038564e+00,  1.00029302e+00,  1.00046110e+00,  9.99832749e-01,\n",
       "         9.99834538e-01,  9.99160409e-01,  9.99952734e-01,  1.00003505e+00,\n",
       "         9.99899626e-01,  1.00065351e+00,  9.99342859e-01,  9.99928951e-01,\n",
       "         1.00030208e+00,  1.00038016e+00,  9.99848247e-01,  1.00003016e+00,\n",
       "         1.00020194e+00,  1.00000823e+00,  9.99868035e-01,  1.00002551e+00,\n",
       "         1.00023746e+00,  9.99864399e-01,  9.99234021e-01,  9.99800980e-01,\n",
       "         1.00029933e+00,  9.99611259e-01,  1.00050187e+00,  1.00023305e+00,\n",
       "         1.00028336e+00,  9.99799550e-01,  9.99838889e-01,  1.00065124e+00,\n",
       "         1.00002086e+00,  9.99678254e-01,  1.00028574e+00,  1.00002432e+00,\n",
       "         9.99977946e-01,  9.99927163e-01,  9.99879420e-01,  1.00006413e+00,\n",
       "        -2.00605369e-03,  5.54505270e-04,  2.56636646e-03, -2.11112341e-03,\n",
       "        -1.39662949e-03,  1.72953831e-03, -4.49731160e-04,  3.79835867e-04,\n",
       "         1.20949931e-03, -2.59182067e-04,  6.94410584e-04,  4.27740961e-05,\n",
       "         2.72697094e-03,  1.79065124e-03, -1.08482805e-03, -2.07916647e-03,\n",
       "         1.09350600e-03, -3.58193327e-04,  3.26857925e-03, -2.90678669e-04,\n",
       "        -2.06791633e-03,  6.30388560e-04, -2.83681834e-03, -2.58568372e-03,\n",
       "        -3.02783796e-04,  1.80490059e-03, -6.96795269e-06, -2.38743098e-03,\n",
       "         6.27694884e-04, -8.54137121e-04, -1.05328835e-03,  1.17668416e-03,\n",
       "        -1.08032906e-03, -1.65967169e-04,  1.96883339e-03, -1.44264475e-03,\n",
       "        -2.82647228e-03, -3.93560855e-03, -3.19226459e-03,  4.81883792e-04,\n",
       "         1.82814151e-03, -4.44651989e-04,  4.13632806e-04,  2.36610445e-04,\n",
       "         1.68588478e-03, -8.12223763e-04, -9.62367340e-04, -2.43534945e-04,\n",
       "         5.33543644e-04,  6.42018276e-04,  2.71378714e-03,  5.79048821e-04,\n",
       "         5.36110660e-04, -1.89263315e-03, -3.42126982e-03,  2.16309167e-03,\n",
       "        -1.45282294e-03,  1.81957346e-03, -2.49259640e-03, -9.33425501e-04,\n",
       "         3.56941047e-04,  1.19310361e-03, -4.93893691e-04, -1.88382517e-04,\n",
       "        -8.33457889e-05,  2.20545408e-04, -6.76387164e-04,  5.84555790e-04,\n",
       "         1.36670642e-04,  6.08230330e-05,  4.58613562e-04,  6.66060828e-07,\n",
       "        -3.06820468e-04, -2.31880054e-04, -4.50889725e-04, -4.52977925e-04,\n",
       "        -3.32336458e-05,  4.32629051e-04, -4.39508265e-04, -6.33487885e-04,\n",
       "        -9.65865620e-04,  6.11470954e-04, -5.81593777e-04,  7.50726380e-04,\n",
       "         1.78531103e-04, -5.59952634e-04,  4.45110694e-04, -4.75627836e-04,\n",
       "         2.69103708e-04, -1.22617668e-04,  2.86515249e-04, -2.22786213e-04,\n",
       "        -9.61933401e-05, -6.12202566e-04, -2.25817610e-04, -2.04180804e-04,\n",
       "        -6.80704215e-06,  6.79837889e-04, -2.36329332e-04, -3.06177681e-04,\n",
       "        -3.62856081e-05,  5.59269218e-04,  6.99932425e-05,  2.45082541e-04,\n",
       "        -1.40279881e-04, -4.15758113e-04, -1.17906035e-04,  1.82705262e-04,\n",
       "        -3.33322096e-05, -3.29597278e-05, -5.73815254e-04, -3.99723540e-05,\n",
       "         3.80631682e-04, -3.21182742e-04,  3.94129311e-04,  2.42535622e-04,\n",
       "        -5.45734692e-05, -1.10061526e-04,  2.39825677e-04,  5.13774808e-04,\n",
       "         1.37118070e-04, -5.30433783e-04,  7.01352983e-05, -1.37706054e-04,\n",
       "        -5.58671818e-05, -4.46983577e-05, -8.36472682e-05,  1.11347857e-04],\n",
       "       dtype=float32),\n",
       " array([[ 0.04138889,  0.03454556,  0.01716433, ...,  0.04102676,\n",
       "         -0.04474944, -0.03314541],\n",
       "        [-0.00830514, -0.03436746,  0.01861186, ...,  0.01198286,\n",
       "         -0.03691435, -0.03695964],\n",
       "        [-0.02386566,  0.0464119 , -0.00181332, ...,  0.03326914,\n",
       "         -0.03207027, -0.04889462],\n",
       "        ...,\n",
       "        [ 0.03541485, -0.04436934,  0.0128362 , ..., -0.00778174,\n",
       "          0.02462394,  0.04154707],\n",
       "        [-0.04807448,  0.03497528,  0.00059439, ..., -0.03780019,\n",
       "         -0.03909423,  0.04684223],\n",
       "        [ 0.03368167,  0.04293358,  0.00510783, ...,  0.01289455,\n",
       "          0.04002964,  0.00238938]], dtype=float32),\n",
       " array([ 0.0045666 , -0.00439938, -0.00911814, -0.00343449, -0.00103622,\n",
       "         0.00464954,  0.0148483 , -0.00167773,  0.00041592, -0.01366732,\n",
       "         0.01090867, -0.00850603,  0.00788983, -0.0077764 , -0.00105298,\n",
       "        -0.01164894,  0.00377734,  0.00534238,  0.00040804,  0.00085278,\n",
       "        -0.00261952, -0.00448126, -0.00027111, -0.00131951, -0.00574327,\n",
       "        -0.00271263,  0.00150442, -0.00307768, -0.00126533, -0.00602104,\n",
       "         0.        ,  0.        ], dtype=float32),\n",
       " array([[-0.00544959,  0.01240814,  0.01391624,  0.00308199,  0.03437656,\n",
       "          0.02785914, -0.03615288, -0.0374839 ,  0.01574482, -0.02625002,\n",
       "          0.0411246 ,  0.01248778,  0.00449843, -0.01135133, -0.00621366,\n",
       "         -0.0279483 ],\n",
       "        [ 0.02108847,  0.01721209, -0.00590987, -0.02122739, -0.04254001,\n",
       "         -0.01459832, -0.0117842 ,  0.02867216,  0.01834833, -0.02249318,\n",
       "          0.02929559, -0.00541428, -0.03583447, -0.05005755,  0.02769975,\n",
       "          0.04231009],\n",
       "        [ 0.020003  , -0.01360477, -0.03704457,  0.00512314, -0.01773616,\n",
       "         -0.01834152, -0.03502091,  0.03942188,  0.00445508, -0.01575754,\n",
       "         -0.02844423,  0.03695802, -0.01824634, -0.04452132, -0.00752876,\n",
       "          0.03541603],\n",
       "        [ 0.02901061, -0.00737521, -0.01908059,  0.04110609,  0.01203655,\n",
       "          0.00266936, -0.04175038,  0.01505067, -0.04431176, -0.0254351 ,\n",
       "         -0.02347251, -0.01483108, -0.00235441,  0.04034487,  0.03117786,\n",
       "          0.04931075],\n",
       "        [-0.04660264,  0.0088801 ,  0.00944246,  0.00039876, -0.03603719,\n",
       "          0.02522514, -0.04593103,  0.02392982,  0.04520161,  0.02977788,\n",
       "          0.01515395,  0.00826618,  0.02966383, -0.04284441,  0.0309312 ,\n",
       "          0.01354494],\n",
       "        [-0.01874013, -0.01853918, -0.03195895,  0.0468667 ,  0.02873562,\n",
       "          0.02412281, -0.03967906, -0.02400512,  0.03298892,  0.01824594,\n",
       "          0.02049065, -0.03671159,  0.0337509 ,  0.0050595 , -0.00624491,\n",
       "          0.0295139 ],\n",
       "        [-0.02688572, -0.0291087 ,  0.03148683,  0.03142381,  0.03941901,\n",
       "          0.038812  ,  0.04652618, -0.00323069, -0.04410329,  0.00695951,\n",
       "          0.00498733, -0.03688245, -0.02448275,  0.02104469,  0.0155888 ,\n",
       "         -0.02337624],\n",
       "        [ 0.01593869,  0.00907219, -0.02119645,  0.04087617,  0.03411654,\n",
       "          0.01586195, -0.05280299, -0.03654949,  0.0245943 ,  0.02312761,\n",
       "         -0.03524511,  0.02727493, -0.0082067 , -0.02961941,  0.0299595 ,\n",
       "          0.0019242 ],\n",
       "        [-0.04526234,  0.00858485, -0.04773048, -0.0092898 , -0.04255633,\n",
       "         -0.02437071,  0.05145631, -0.02641982, -0.01765158,  0.00995534,\n",
       "          0.00621663,  0.03981574, -0.03657717,  0.04309297, -0.02756293,\n",
       "          0.01165967],\n",
       "        [ 0.01048664, -0.00667016, -0.03962965,  0.00832301,  0.0012306 ,\n",
       "         -0.052037  , -0.02019282,  0.02879184, -0.00759229,  0.0273823 ,\n",
       "          0.01653745,  0.04303108,  0.0396724 ,  0.03025341,  0.04821834,\n",
       "         -0.02534646],\n",
       "        [-0.01708687, -0.02974115, -0.0436489 ,  0.04708449, -0.044154  ,\n",
       "         -0.02927773,  0.04428418, -0.00409059, -0.04489565, -0.01497619,\n",
       "         -0.03086684,  0.02123943,  0.01433954, -0.017124  , -0.01021234,\n",
       "         -0.04185103],\n",
       "        [ 0.0440666 , -0.03327297, -0.01291497, -0.0021877 ,  0.04195691,\n",
       "         -0.02212012,  0.03430995, -0.03067275, -0.04076737, -0.02371429,\n",
       "         -0.04363119, -0.05001532, -0.04530939,  0.00768029, -0.04844931,\n",
       "          0.03233556],\n",
       "        [-0.04385429, -0.04134559,  0.00431676,  0.01090062,  0.01982751,\n",
       "          0.03872953, -0.00723548,  0.01926934, -0.00352803,  0.04882706,\n",
       "         -0.04559388, -0.04764831, -0.02317408, -0.0209605 , -0.02642679,\n",
       "          0.02886167],\n",
       "        [ 0.02280375, -0.00545137, -0.00363361, -0.03581221,  0.02125754,\n",
       "          0.00039287,  0.04024711, -0.00063682,  0.04841305,  0.04090496,\n",
       "          0.03755037, -0.02556828,  0.03697206, -0.04653963, -0.0091299 ,\n",
       "         -0.0308149 ],\n",
       "        [ 0.02146738,  0.03594621, -0.04800299, -0.02825927, -0.03022351,\n",
       "          0.00882816, -0.03731615, -0.02623947, -0.02598776,  0.02547603,\n",
       "         -0.00391807,  0.00547366,  0.0369205 , -0.04902062, -0.00343941,\n",
       "          0.02955022],\n",
       "        [-0.01300657, -0.04560187,  0.03941232, -0.00757181,  0.03257878,\n",
       "         -0.04295954,  0.02235414, -0.03950943,  0.02851704,  0.0193179 ,\n",
       "          0.00920198, -0.03768816, -0.01553845, -0.01692089,  0.03116097,\n",
       "          0.02530025],\n",
       "        [-0.02079432,  0.01853238, -0.03107457,  0.04826939, -0.02369231,\n",
       "          0.03051766, -0.02746088, -0.04299657,  0.00169111,  0.01368812,\n",
       "          0.00933047, -0.01406857, -0.02247455, -0.01036932,  0.00937863,\n",
       "         -0.01608022],\n",
       "        [ 0.03434196,  0.02940859,  0.04601071, -0.01121718,  0.03107221,\n",
       "          0.00660308, -0.00704719, -0.02174176, -0.02749306, -0.01647106,\n",
       "          0.01425233,  0.0050238 , -0.04658772,  0.01851481, -0.01246863,\n",
       "          0.00679197],\n",
       "        [-0.02970767,  0.03507049, -0.02621341, -0.00833353, -0.03300782,\n",
       "         -0.01527776,  0.01736788,  0.01042551, -0.00118242, -0.04647774,\n",
       "         -0.02493834,  0.00391013,  0.02425338, -0.05279804, -0.01946974,\n",
       "         -0.01063735],\n",
       "        [ 0.0226148 , -0.02651599, -0.04918431,  0.02731219, -0.00106185,\n",
       "          0.01902574, -0.0041379 ,  0.038628  ,  0.02587034,  0.00518013,\n",
       "          0.02571317, -0.03933671,  0.04147352,  0.02235644, -0.03862432,\n",
       "          0.01470645],\n",
       "        [ 0.01027807,  0.02679202,  0.04269627,  0.00704247, -0.0266307 ,\n",
       "          0.00402477, -0.00476516, -0.01997831,  0.02964527, -0.03659149,\n",
       "          0.03843772,  0.04449812, -0.03735575,  0.00513898,  0.00110613,\n",
       "         -0.04951219],\n",
       "        [ 0.03137044,  0.01591144, -0.03871166,  0.00509522,  0.02233725,\n",
       "         -0.00480888, -0.00595841, -0.00509007,  0.03099317, -0.00486747,\n",
       "         -0.04982336, -0.00011948,  0.00594901,  0.04748663, -0.04342213,\n",
       "         -0.04928479],\n",
       "        [-0.0322497 , -0.03631769,  0.01763561, -0.03278489,  0.02769888,\n",
       "          0.01910394, -0.01569215,  0.0087778 , -0.04899795,  0.01096057,\n",
       "         -0.00970279, -0.02157343, -0.00926216,  0.02991468, -0.01702737,\n",
       "         -0.01056542],\n",
       "        [ 0.02716414,  0.02556759,  0.04411042,  0.0041069 , -0.02560034,\n",
       "          0.04166908,  0.02510706, -0.00907139, -0.02386159,  0.04754549,\n",
       "         -0.00638753, -0.01587912,  0.00483895,  0.00097817, -0.04399801,\n",
       "         -0.04395499],\n",
       "        [-0.03364445,  0.02000539,  0.02835721, -0.01591641, -0.0049982 ,\n",
       "         -0.03473194,  0.03932798, -0.03792623, -0.04979188, -0.04579005,\n",
       "          0.00315533, -0.0399699 , -0.00747518, -0.00727285, -0.02108022,\n",
       "         -0.04765035],\n",
       "        [ 0.02720615, -0.03841579, -0.03771504, -0.01745451, -0.01822485,\n",
       "          0.04555094,  0.02789156, -0.0170642 ,  0.03824855,  0.03868508,\n",
       "         -0.01722327,  0.01699357, -0.02369502, -0.04527686, -0.03586261,\n",
       "          0.01591326],\n",
       "        [ 0.04689289, -0.02624609,  0.02602066, -0.01483677,  0.02943022,\n",
       "          0.03135666, -0.01370641, -0.00838367,  0.04648549,  0.02993424,\n",
       "         -0.02089971, -0.02837433,  0.04521525, -0.00213178,  0.03461318,\n",
       "         -0.03479216],\n",
       "        [ 0.01644038,  0.03652409,  0.03239178, -0.01408377,  0.03279155,\n",
       "         -0.03056935, -0.00339884,  0.0372458 ,  0.00715617,  0.03062384,\n",
       "         -0.03796216, -0.0156193 ,  0.00129185,  0.03358825, -0.01209727,\n",
       "          0.02329655],\n",
       "        [-0.01987274,  0.01837071, -0.00104582, -0.0434714 , -0.0010737 ,\n",
       "         -0.02726611,  0.02654044, -0.00673376,  0.0359832 , -0.04539036,\n",
       "          0.04749114, -0.02497214,  0.0455911 , -0.01246232, -0.0189253 ,\n",
       "         -0.02734175],\n",
       "        [-0.03895961, -0.00388891,  0.01184697, -0.04431531,  0.01806721,\n",
       "         -0.02374497, -0.04574023, -0.01512855, -0.03976823,  0.00601912,\n",
       "         -0.0168763 , -0.0347403 , -0.01829886,  0.01112655, -0.02318162,\n",
       "         -0.01139989],\n",
       "        [-0.02681899, -0.02565149, -0.02448812,  0.03628296,  0.03829372,\n",
       "          0.02655992,  0.04783054,  0.04225145,  0.0068621 ,  0.00901373,\n",
       "         -0.02075555, -0.00021593, -0.03984097, -0.03120703,  0.0024175 ,\n",
       "         -0.03436069],\n",
       "        [ 0.01589736,  0.04327976, -0.03159271,  0.0358121 ,  0.00550816,\n",
       "         -0.04103298, -0.03902562, -0.04189579, -0.0497682 , -0.0276955 ,\n",
       "         -0.00252209, -0.00307821, -0.04073215, -0.04233434,  0.04727802,\n",
       "         -0.01151634]], dtype=float32),\n",
       " array([-0.00988262, -0.00221659, -0.00669937,  0.00421146, -0.00447457,\n",
       "         0.01045783, -0.00074112, -0.00219077, -0.00080647, -0.00897898,\n",
       "         0.0115913 , -0.00569713, -0.00708443, -0.00609325, -0.00807062,\n",
       "        -0.00844324], dtype=float32),\n",
       " array([[ 0.01137585,  0.0074685 , -0.00864737,  0.03360623,  0.02628894,\n",
       "          0.01305339, -0.04916001,  0.00330458],\n",
       "        [ 0.00801726,  0.012609  , -0.00016841, -0.02816236,  0.04407588,\n",
       "         -0.03500395, -0.02546785, -0.002059  ],\n",
       "        [ 0.01641132,  0.02981563,  0.01224352,  0.02463848,  0.01859259,\n",
       "          0.02020414, -0.01561319, -0.02272642],\n",
       "        [-0.02577113, -0.0422122 ,  0.01382026,  0.01043959,  0.00495092,\n",
       "         -0.00715963, -0.02573348,  0.00957777],\n",
       "        [-0.00645009, -0.02930464,  0.03300241, -0.00892612, -0.02445102,\n",
       "          0.0454546 ,  0.01932675,  0.00972667],\n",
       "        [-0.03038691,  0.01882417,  0.00394482, -0.04643853, -0.03329025,\n",
       "          0.0240776 , -0.02632113, -0.00248488],\n",
       "        [-0.03173869,  0.05041295,  0.04002353, -0.03370159,  0.03236394,\n",
       "         -0.02131427,  0.02326064, -0.03960909],\n",
       "        [-0.0213331 , -0.0358126 , -0.00668265,  0.04148779,  0.03160945,\n",
       "          0.0504621 ,  0.03489485, -0.01769752],\n",
       "        [-0.01084228, -0.02255945, -0.0357592 , -0.02168734,  0.01378153,\n",
       "         -0.03849534,  0.01320862, -0.03549837],\n",
       "        [-0.03875748, -0.00176149, -0.03289173, -0.00676319, -0.00637926,\n",
       "          0.01262469, -0.02205546, -0.03574955],\n",
       "        [-0.04359388,  0.03318933,  0.02595212, -0.01389465, -0.03890079,\n",
       "         -0.00996421,  0.02775146, -0.00873888],\n",
       "        [ 0.01687887,  0.01860165,  0.01054635,  0.01512348, -0.04578081,\n",
       "         -0.03848651,  0.02883685, -0.00946533],\n",
       "        [-0.04761949,  0.0061893 ,  0.02430651, -0.01781044, -0.01145047,\n",
       "          0.03402453, -0.02349322, -0.04498701],\n",
       "        [-0.01121902,  0.01724093,  0.01800717,  0.04735551, -0.04905587,\n",
       "          0.01035691,  0.0415708 ,  0.04615117],\n",
       "        [ 0.04245812, -0.04993805,  0.03529812, -0.02341243, -0.02080949,\n",
       "         -0.02003086, -0.03883085, -0.04022747],\n",
       "        [ 0.0332309 , -0.00300046,  0.01039641,  0.01021981, -0.03213291,\n",
       "          0.02986334, -0.0356456 ,  0.03565646]], dtype=float32),\n",
       " array([-0.006261  , -0.0059564 , -0.00106521, -0.00595836, -0.00119794,\n",
       "        -0.00589964,  0.        ,  0.        ], dtype=float32),\n",
       " array([[ 0.022541  ,  0.00239933, -0.01657121, -0.00123598],\n",
       "        [-0.03970781,  0.04157895,  0.0360693 ,  0.00186005],\n",
       "        [ 0.00968436,  0.02071245,  0.02495631, -0.05079424],\n",
       "        [-0.03322499,  0.04335141, -0.04615487, -0.03428536],\n",
       "        [ 0.00842043, -0.00826244, -0.02775849, -0.05081223],\n",
       "        [ 0.00439046, -0.00347906, -0.00598512, -0.00424137],\n",
       "        [-0.01707181, -0.02963223, -0.02948178,  0.04135457],\n",
       "        [ 0.00382651,  0.03967459, -0.02500116,  0.02022438]],\n",
       "       dtype=float32),\n",
       " array([-0.00658358, -0.00596072, -0.00550911, -0.00563945], dtype=float32),\n",
       " array([[-0.31402135],\n",
       "        [-0.6455648 ],\n",
       "        [ 0.36301562],\n",
       "        [ 0.9168884 ]], dtype=float32),\n",
       " array([3.8540668], dtype=float32)]"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_train.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = mod_train.layers[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.get_output_at?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.get_output_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Elemwise{mul,no_inplace}.0"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_train.layers[-2].get_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 469,   60,   23, ...,    0,    0,    0],\n",
       "       [ 405,   19,   67, ...,    0,    0,    0],\n",
       "       [ 839,  663,  276, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   1,   15,    1, ...,    0,    0,    0],\n",
       "       [  67,    1, 1010, ...,    0,    0,    0],\n",
       "       [1310, 1260,   23, ...,    0,    0,    0]], dtype=int16)"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.append(43322)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.insert(0, 443)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[443, 1, 2, 0, 43322]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerodar = ['mesos', 'aptanastudio', 'titanium', 'duracloud', 'jirasoftware', 'moodle',\n",
    "           'mulestudio','springxd','talendesb']\n",
    "perto = ['mule','talenddataquality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mesos',\n",
       " 'appceleratorstudio',\n",
       " 'aptanastudio',\n",
       " 'titanium',\n",
       " 'duracloud',\n",
       " 'jirasoftware',\n",
       " 'moodle',\n",
       " 'mule',\n",
       " 'mulestudio',\n",
       " 'springxd',\n",
       " 'talendesb']"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rerodar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesos\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usergrid\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appceleratorstudio\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aptanastudio\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xd8VFXe+PHPN5lJ711aAqKhBKUEBEGlWAB7b1hAV/fRXXWfXR/1t6v7uPs829zio2tDcVfF3lZ3RUVUBFeKAem9BAgtkN7r+f1xBgyQwCSZlsz3/XrNa+7ce+6935lMvvfOOeeeK8YYlFJKdX8h/g5AKaWUb2jCV0qpIKEJXymlgoQmfKWUChKa8JVSKkhowldKqSChCV8pQET+LiL/42bZfBE5t7PbUcrXNOErpVSQ0ISvlFJBQhO+6jJcVSn3i8gqEakSkVkiki4iH4tIhYjME5HEFuUvEZG1IlIqIvNFZGCLZcNEZLlrvTeBiKP2dZGIrHCt+42InNbBmH8gIltEpFhEPhSRHq75IiJ/EZFCESkXkdUikuNaNlVE1rli2y0iP+vQB6bUUTThq67mSuA84FTgYuBj4P8Bqdjv8z0AInIq8Dpwn2vZHOCfIhImImHAP4BXgCTgbdd2ca07DHgRuBNIBp4DPhSR8PYEKiITgd8C1wAnATuAN1yLzwfOdr2PeFeZIteyWcCdxphYIAf4oj37VaotmvBVV/OkMWa/MWY3sBBYYoz5zhhTC7wPDHOVuxb4yBjzmTGmAfgjEAmcCYwGnMDjxpgGY8w7wLct9nEH8JwxZokxpskY8xJQ51qvPW4EXjTGLDfG1AEPAWNEJAtoAGKBAYAYY9YbY/a61msABolInDGmxBizvJ37VapVmvBVV7O/xXRNK69jXNM9sGfUABhjmoFdQE/Xst3myJEDd7SYzgR+6qrOKRWRUqC3a732ODqGSuxZfE9jzBfAX4GngEIRmSkica6iVwJTgR0i8pWIjGnnfpVqlSZ81V3twSZuwNaZY5P2bmAv0NM175A+LaZ3Af9rjElo8YgyxrzeyRiisVVEuwGMMU8YY0YAg7BVO/e75n9rjLkUSMNWPb3Vzv0q1SpN+Kq7egu4UEQmiYgT+Cm2WuYbYBHQCNwjIk4RuQIY1WLd54EfisgZrsbVaBG5UERi2xnD68B0ERnqqv//DbYKKl9ERrq27wSqgFqg2dXGcKOIxLuqosqB5k58DkodpglfdUvGmI3ANOBJ4CC2gfdiY0y9MaYeuAK4FSjG1ve/12LdPOAH2CqXEmCLq2x7Y5gHPAy8i/1VcTJwnWtxHPbAUoKt9ikCHnMtuwnIF5Fy4IfYtgClOk30BihKKRUc9AxfKaWChCZ8pZQKEprwlVIqSGjCV0qpIOHwdwAtpaSkmKysLH+HoZRSXcayZcsOGmNS3SkbUAk/KyuLvLw8f4ehlFJdhojsOHEpS6t0lFIqSGjCV0qpIKEJXymlgkRA1eG3pqGhgYKCAmpra/0dildFRETQq1cvnE6nv0NRSnVTAZ/wCwoKiI2NJSsriyMHN+w+jDEUFRVRUFBA3759/R2OUqqbCvgqndraWpKTk7ttsgcQEZKTk7v9rxillH8FfMIHunWyPyQY3qNSyr8CvkrHLRV7AQEJhZAQ13MoSMiR8yQENLEqpYJU90j4lYVg3LxHhLRxQAgJBXHY55Dvn0vLK3jtjXe46+6723XAmDp1Kq+99hoJCQmdeGNKKeU53SPhZ5wGxoBpsom/2fVsmo6adj23nG5uhsYGW665ETjy/gClu/bw9FNPcNeVZwFy+GDQ2AyOsHD7WkLBEQ7OKHBGgIQwZ84cv3wUSinVlu6R8EVcZ94eaJJobgbTePgA8OC9v2brjt0MnXwTToeDiPAwEhPi2LBpK5sWzeGym29n15591NbVce9t13PHtKvAGUHWiPPIWziPyromplx6JePGjeObb76hZ8+efPDBB0RGRnY+VqWUaoculfAf/eda1u0p9+g2B/WI45cXD/5+RkgIEAah9uXvHvsza9ZvYsWqNcyfP58LL7yQNWvWHO4++eJr75CUmEhNZRkjR4/hymuuIzks1P6qqNgNVTVs3ryZ15/6Dc8/9jDXzPgx7775GtNunu7al1JK+UaXSviBYNSoUUf0lX/iiSd4//33AdhVsIfN+ypJHp0DoU5IyQbHQfpm9mboaUOgppQRA7PIX7cc9o0ARwSERYEzEiK0rl8p5V1dKuEfcSbuJ9HR0Yen58+fz7x581i0aBFRUVGMHz/+yL70jnCIiCc8MhpS+oMxhMafRE1ZCcSkQX011JRCdRFU7IOGRj+8I6VUsNA6hROIjY2loqKi1WVlZWUkJiYSFRXFhg0bWLx48fE3Jq5GX2ckxPWwB4GMIZCabedXFcL839t2BKWU8rAudYbvD8nJyYwdO5acnBwiIyNJT08/vGzy5Mk8++yzDBw4kOzsbEaPHt3+HYjY3j0pp8KuIvj0N7BrCVzxPEQne/CdKKWCnRhjTlzKR3Jzc83RN0BZv349AwcO9FNEvrV+/XoGVi2Cjx+A6DS45iXolevvsJRSAUxElhlj3EoUWqUTaHJnwG1zbQ+eFyfDkufsNQZKKdVJmvADUY9hcOcC6D8JPv4veGc61LXejqCUUu7ShB+oIhPhutfh3P+GdR/AzAmwf52/o1JKdWGa8ANZSAiM+wnc/CHUlsHzE2HlG/6OSinVRXkt4YtItoisaPEoF5H7vLW/bq3vWfDDhdBzOLx/J/zzPmjQsfOVUu3jtYRvjNlojBlqjBkKjACqgfe9tb9uLzbDnumPvQ+W/Q1ePB9K8v0dlVKqC/FVlc4kYKsxZoeP9ucxpaWlPP300x1a9/HHH6e6utpzwYQ64LxH4fo3bLJ/7mzY+LHntq+U6tZ8lfCvA15vbYGI3CEieSKSd+DAAR+F476ASviHZE+BO76CxCx4/Tr47JfQpMMyKKWOz+tX2opIGHAJ8FBry40xM4GZYC+88nY87fXggw+ydetWhg4dynnnnUdaWhpvvfUWdXV1XH755Tz66KNUVVVxzTXXUFBQQFNTEw8//DD79+9nz549TJgwgZSUFL788kvPBpbUF2bMhU8ehH8/Do21MOX3nt2HUqpb8cXQClOA5caY/Z3e0scPwr7VnY+opYwhMOV3bS7+3e9+x5o1a1ixYgVz587lnXfeYenSpRhjuOSSS1iwYAEHDhygR48efPTRR4AdYyc+Pp4///nPfPnll6SkpHg25kOcEXDx49BQA8tfgQk/h4g47+xLKdXl+aJK53raqM7paubOncvcuXMZNmwYw4cPZ8OGDWzevJkhQ4bw2Wef8cADD7Bw4ULi4+N9G9ioH0BDFax+27f7VUp1KV49wxeRaOA84E6PbPA4Z+K+YIzhoYce4s47j307y5cvZ86cOfziF79g0qRJPPLII74LrOcISB9ie+/kztAbtSulWuXVM3xjTJUxJtkYU+bN/XhTy+GRL7jgAl588UUqKysB2L17N4WFhezZs4eoqCimTZvG/fffz/Lly49Z16tEIPdWW921e7n396eU6pJ0eOQTaDk88pQpU7jhhhsYM2YMADExMcyePZstW7Zw//33ExISgtPp5JlnngHgjjvuYPLkyfTo0cPzjbZHG3INzH0E8l6EXiO8uy+lVJekwyMHkE6/1w/vgVVvwU83QKTeMlGpYKDDIwer3OnQWGOTvlJKHUUTfnfSYxicNNQ23gbQLzelVGDoEgk/kKqdvMVj7zF3OhSus7dJVEqpFgI+4UdERFBUVNStk74xhqKiIiIiIjq/sZyrICwW8v7W+W0ppbqVgO+l06tXLwoKCgjEcXY8KSIigl69enV+Q+ExcNo18N1smPxbiErq/DaVUt1CwCd8p9NJ3759/R1G15I7HfJm2ZuljLnL39EopQJEwFfpqA7IGAI9c22f/G5cFaaUah9N+N1V7gwo2gw7/u3vSJRSAUITfnc1+HIIj9fGW6XUYZrwu6uwKDj9Olj3AVQd9Hc0SqkAoAm/O8udDs0NsOJVf0eilAoAmvC7s7SB0GcMLPs7NDf7OxqllJ9pwu/uRkyH4m2Qv8DfkSil/EwTfnc36FKITLRdNJVSQU0TfnfnjIDTb4ANH0FF528rrJTqujThB4Pc6dDcCCtm+zsSpZQfacIPBimnQNZZ2nirVJDThB8sRtwKpTth6xf+jkQp5Sea8IPFwIshKtneHEUpFZQ04QcLRzgMmwYbP4byvf6ORinlB5rwg8nwW8A0wXev+DsSpZQfaMIPJsknQ7/xsOwlaG7ydzRKKR/ThB9sRkyH8gLY/Jm/I1FK+Zgm/GAz4EKISdfGW6WCkCb8YBPqtI23m+dC6S5/R6OU8iFN+MFo+C321ofLX/Z3JEopH+oWCX/N7jI27qsg/2AV+8pqKa2up7ahieZmvZ9rqxIzof8k21unqdHf0SilfMTh7wA84epnF1HT0HqvkzBHCBGOECKcoUQ4Qwk/PB1y+HW4M5RIZyhRYaFEhoUS5XQQGRZCZJiDqBbzbRmHLeN6HRlmtyEiPn7XnZQ7A964ATZ9AgMv8nc0Sikf6BYJ/+kbh1PT0ERtQxO1Dc3UNdrn2oYmahubqHNN1zW65rnKVdY1crCymbqGJmpcj+r6Juob2zfeTGiIEBfhIDE6jKSosCOfo50kRoWRFH3k/LgIh38PEqdcALE9bOOtJnylgkK3SPgTBqR5dHuNTc2HDwA19fYgUF1vDxR2upGa+u8PEDX1TZTVNFBcXU9JVT27iqtZVVBKSVUD9U2tHzwcIUJC1PcHhIEnxTE+O5XR/ZKJcIZ69P20KtQBw2+Cr/4AJfmQmOX9fSql/KpbJHxPc4SGEBsaQmyEs1PbMcZQVd9ESVU9xVX1hw8IxVX1lFTXU1zVQElVPQcr63h96U7+/k0+Ec4QxvRLZsKANMafmkaf5CgPvatWDL8ZFjxmL8Q695fe249SKiB4NeGLSALwApADGGCGMWaRN/cZSESEmHAHMeEOeicdP3HXNjSxaFsR8zcU8uXGA3y5cS2wln6p0UzITmN8diqj+iYR7vDg2X98L1u1891sGP8QOMI8t22lVMARY7zXk0VEXgIWGmNeEJEwIMoYU9pW+dzcXJOXl+e1eLoKYwzbD1Yxf+MBvtxYyJLtxdQ3NhMVFsqZJycz3nUA6JXogbP/TZ/Ca9fA1X+HwZd3fntKKZ8SkWXGmFy3ynor4YtIPLAC6Gfc3Ikm/NZV1zeyaGvR4QNAQUkNAKekxTA+O5UJ2WmM6puEI7QDvWybm+Avg6HPaJv0lVJdSqAk/KHATGAdcDqwDLjXGFN1VLk7gDsA+vTpM2LHjh1eiae7MMaw9UAV8zcWMn/jAZZuL6a+qZnczERm3TqS+MgOtDu8cSMc2AA/Xub5gJVSXtWehO/NC68cwHDgGWPMMKAKePDoQsaYmcaYXGNMbmpqqhfD6R5EhP5pMdx+Vj9m334G3z1yHr+7YggrC0q54fnFFFXWtX+jGUOgaCvUV3s+YKVUwPBmwi8ACowxS1yv38EeAJQHRYc7uG5UH2benMuWwkqunbmY/eW17dtI+mDAQOF6r8SolAoMXkv4xph9wC4RyXbNmoSt3lFeMCE7jZdmjGJvaQ1XP7uIXcXtOFtPz7HP+1d7JzilVEDw9lg6PwZeFZFVwFDgN17eX1Ab3S+ZV38wmrKaBq5+dhFbCivdWzEhE8JiYf9a7waolPIrryZ8Y8wKV/38acaYy4wxJd7cn4KhvRN4887RNDYbrn1uEWt2l514pZAQSB8E+9Z4P0CllN90i9Ey1ZEGZMTx1p2jCXeEcP3zi1m2w43jbHqOPcP34nUZSin/0oTfTfVLjeHt/ziT5Ogwbpq1hH9vOXj8FTJyoK4MyvSmKEp1V5rwu7GeCZG89cMx9E6MYvrfv2Xeuv1tFz7UcKvVOkp1W5rwu7m02AjevHM0AzNi+eHsZXy4ck8bBQcBAvs14SvVXWnCDwIJUWHMvv0Mhmcmcu8b3/HG0p3HFgqPgaS+mvCV6sY04QeJ2AgnL00fxdmnpPLge6t5YeG2Ywul52iVjlLdmCb8IBIZFsrMm0cwJSeD//loPf83bzNHjKWUngPF26C+qu2NKKW6LE34QSbcEcqT1w/jyuG9+Mu8Tfz24w3fJ/0M120L9usF0Up1R3rHqyDkCA3hsatOIzo8lJkLtlFR28j/XJZD6OEhFtZA75H+DVIp5XGa8INUSIjw6CWDiQ538Mz8rcRHOnlwcjaEx2nDrVLdlFbpBDER4YHJA7jk9B68vCifstpGO3KmNtwq1S1pwlfceU4/quubbHdNHWJBqW5LE75icI94RvdL4qVv8mlKGwT1FVCqdx5TqrvRhK8AuG1cP/aU1fJN5Ul2hlbrKNXtaMJXAEwakEZWchR/XRuGHWJBx8ZXqrvRhK8A22tn+ti+LCmopTYuS+9+pVQ3pAlfHXbViF7ERThY19xHq3SU6oY04avDosMdXD+qD1+WpkHJdqhz8xaJSqkuQRO+OsItZ2ax0fSxLwp1iAWluhNN+OoIPRIiST81F4DagpV+jkYp5Uma8NUxrhg/mnITxfa1S/wdilLKgzThq2MMy0xiV1hfGvespqlZr7hVqrvQhK9aFd17KH2b8pm3bq+/Q1FKeYgmfNWq3oNGESO1/POrxf4ORSnlIZrwVatCM4YA0LB7FWt2l/k5GqWUJ2jCV61LG4iREE5z7mLW19v9HY1SygM04avWhUUhSSczMeEA/1y5h/3ltf6OSCnVSZrwVdsycuhv8mkyhpcX5fs7GqVUJ2nCV21LH4yzfAcXZ8fw6pKd1NQ3+TsipVQnuJXwReReEYkTa5aILBeR870dnPKzdNtwe+eAOkqrG3jvuwI/B6SU6gx3z/BnGGPKgfOBROAm4Hdei0oFhowcAAaF7CSnZxwvfr2dZr0QS6kuy92EL67nqcArxpi1Leap7iquJ0TEI/vXcNu4vmw9UMVXmw/4OyqlVAe5m/CXichcbML/VERigWbvhaUCgoit1tm/lguH9CAtNpwXtYumUl2Wuwn/NuBBYKQxphpwAtNPtJKI5IvIahFZISJ5nYhT+UtGDuxfS1iIHTp54eaDbNxX4e+olFId4G7CHwNsNMaUisg04BeAu5dfTjDGDDXG5HYoQuVf6YOhoQpKtnPDqD5EOEP0LF+pLsrdhP8MUC0ipwM/BbYCL3stKhU40m3DLfvXkhgdxhXDe/H+it0crKzzb1xKqXZzN+E3GmMMcCnwV2PMU0CsG+sZYK6ILBORO1orICJ3iEieiOQdOKANggEnbSBICOy397idMbYv9Y3NvLp4p58DU0q1l7sJv0JEHsJ2x/xIREKw9fgnMs4YMxyYAtwtImcfXcAYM9MYk2uMyU1NTXU7cOUjzkhI7n/4pub902IYn53KK4t3UNeoF2Ip1ZW4m/CvBeqw/fH3Ab2Ax060kjFmt+u5EHgfGNXBOJU/pefA/tWHX942ri8HK+v4cMUePwallGovtxK+K8m/CsSLyEVArTHmuHX4IhLt6r6JiERjL9pa08l4lT9k5EDpTqi17fTj+qeQnR7LrK+3Y2v6lFJdgbtDK1wDLAWuBq4BlojIVSdYLR34WkRWutb9yBjzSWeCVX5yuOF2HQAiwoxxWWzYV8GirUV+DEwp1R4ON8v9HNsHvxBARFKBecA7ba1gjNkGnN7pCJX/HU74ayBzDACXDu3JHz7ZyKyvt3Nm/xQ/BqeUcpe7dfghh5K9S1E71lVdXVwPiEw83FMHIMIZyo2jM/l8QyHbDlT6MTillLvcTdqfiMinInKriNwKfATM8V5YKqCI2LP8fUc2wdw0OpOw0BD+9u98/8SllGoXdxtt7wdmAqe5HjONMQ94MzAVYNJzoHAdNH/fFTM1NpxLhvbgnWUFlFbX+zE4pZQ73K6WMca8a4z5T9fjfW8GpQJQRg40VENJ/hGzZ4ztS01DE68v3eWfuJRSbjtuwheRChEpb+VRISLlvgpSBYD0wfZ53+ojZg/qEceYfsnMXryDJh0rX6mAdtyEb4yJNcbEtfKINcbE+SpIFQBSB4KEHtFwe8i00ZnsLq1hwSYdGkOpQKY9bZR7nBGQcgrsX3vMovMHp5MaG87sxTv8EJhSyl2a8JX7WumpA+AMDeG6kb35YmMhBSXVfghMKeUOTfjKfemDoWwn1JQes+i6UX0Q4PWlOoqmUoFKE75yX8YQ+1y47phFPRMimTggjTe/LaC+Ue9+qVQg0oSv3HdoiIVWqnUAbhydycHKOuau2+fDoJRS7tKEr9wXmwGRSUcMldzSOaek0jspUhtvlQpQmvCV+0QO39S8NSEhwg2jMlm8rZgthXqjc6UCjSZ81T7pQ+wwyc2t3+3q6txeOEOFV5do461SgUYTvmqf9MHQWAPF21pdnBITzpSck3h3WQE19XoLRKUCiSZ81T4ZLcbGb8O00ZmU1zbyz5V6C0SlAokmfNU+qQPsEAtt9NQBGJmVyKnpMcxeoo23SgUSTfiqfRzhkHLqcc/wRYQbz8hkVUEZqwqOvUhLKeUfmvBV+x2np84hlw/vSaQzlFcXa+OtUoFCE75qv/QcKNsFNSVtFomLcHLZsB58sHI3ZTUNPgxOKdUWTfiq/Q7f1Pz4Z/k3npFJbUMz7y0v8EFQSqkT0YSv2i/DvYSf0zOe03sn8OqSnRijN0dRyt804av2i0mHqJRj7n7Vmmln9GFLYSVLthf7IDCl1PFowlftJ2IvwDpOT51DLj69B3ERDh1fR6kAoAlfdUzGEChc3+YQC4dEOEO5akRvPl27jwMVdT4KTinVGk34qmPSc6CxFoq2nrDojaP70NBkeCtvlw8CU0q1RRO+6pj0wfa5jaGSWzo5NYYzT07mtSU7aWrWxlul/EUTvuqY1GwIcZywp84h00Znsru0hq82FXo5MKVUWzThq45xhENK9nHH1GnpvEHppMaGM1uvvFXKbzThq47LyHGrpw6AMzSE60b25suNhRSUVHs5MKVUazThq45LHwzlu6HavT7214/qgwCvL9WzfKX8QRO+6jg3h1g4pEdCJBMHpPPmt7uob2z2YmBKqdZowlcdlzHEPrtZrQO2i+bByno+XbvPS0Eppdri9YQvIqEi8p2I/Mvb+1I+FpMG0aluN9wCnHNKKr2TInlVb46ilM/54gz/XmC9D/aj/CHd/YZbgJAQ4YZRmSzeVsyWwgovBqaUOppXE76I9AIuBF7w5n6UH2Xk2CEWmhrdXuWa3F44Q0W7aCrlY94+w38c+C+gzRY6EblDRPJEJO/AgQNeDkd5XHoONNVB0Ra3V0mOCWdKzkm8u7yA6nr3DxRKqc7xWsIXkYuAQmPMsuOVM8bMNMbkGmNyU1NTvRWO8pbDPXXcr9YBe+VtRW0j/1q51wtBKaVa480z/LHAJSKSD7wBTBSR2V7cn/KHlFMhxNnuhD8yK5FT02OYrY23SvmM1xK+MeYhY0wvY0wWcB3whTFmmrf2p/zEEWYvwNq5uF2riQg3npHJqoIyVhWUeik4pVRL2g9fdd6pF8CuJVBV1K7VLh/ek0hnqN4cRSkf8UnCN8bMN8Zc5It9KT/IngKmGTbPbddqcRFOLhvWgw9X7qGspsFLwSmlDtEzfNV5Jw2F2JNg45x2r3rjGZnUNjTzyqJ8vdG5Ul6mCV91ngicOhm2fgGN7buNYU7PeMb1T+GPczdxy9++ZdN+vRhLKW/RhK88I3sq1FdC/sJ2r/rirSP5xYUDWbGzhCn/t5Bf/GM1RZV6/1ulPE0TvvKMvmeDMwo2ftzuVcMcIdx+Vj/m3z+BaWf04fWluxj/x/m8sHCbjqqplAdpwlee4YyAkyfahN/Buvik6DAevTSHT+49ixGZifzPR+s5/y9f8enafVq/r5QHaMJXnpM91d4QZd+qTm3mlPRY/j59FH+fPhJHaAh3vrKMG55fwro95R4KVKngpAlfec6pFwDSoWqd1ozPTuOTe8/iV5cOZsO+ci58ciEPvruKwopaj2xfqWCjCV95TnQK9D6jQ90z2+IIDeHmMVnM/9kEZoztyzvLCpjw2Hyenr+F2oYmj+1HqWCgCV95VvYU2LsSynZ7dLPxUU4evmgQc39yNmNOTuEPn2zk3D9/xUer9mr9vlJu0oSvPCt7qn3e5JlqnaP1S43hhVtyefX2M4gJd3D3a8u55rlFrC4o88r+lOpONOErz0o5BZJO9lg9flvG9k/ho3vO4rdXDGH7wSoufeprfvnBGsprdYgGpdqiCV95loit1tm+AOq8e9VsaIhw/ag+fPGz8dw0OpOXF+9g0p++4sOVe7SaR6lWaMJXnpc9BZrq7VALPhAX4eTRS3P44O6xZMRFcM/r33HTrKVsP1jlk/0r1VVowlee13s0RCTAxk98utvTeiXwj7vH8qtLB7NyVykXPL6Ax+dt0t48SrlowleeF+qwffI3fQLNvk22oSHCzWOy+Pyn5zB5cAaPz9vM5McXsHCz3i9ZKU34yjuyp0BNMexa6pfdp8VF8MT1w5h92xmICDfNWsqPX/+OwnK9aEsFL034yjtOnmTvdevBi7A6YtwpKXx871ncd+4pfLp2H5P+9BUvfZNPU7M26qrgowlfeUdEHPQ9y+vdM90KxRnKfeeeyqf3nc3QPgn88sO1XPbUv/VeuiroaMJX3pM9FYo2w8HN/o4EgL4p0bw8YxRPXj+M/eW1XPrUv3nkgzV6e0UVNDThK+85dbJ9DoCz/ENEhItP78G8n57DLWOymO3quz9zwVZWFZTS2KTj76vuSwLpApXc3FyTl5fn7zCUJz07DsJiYUbgJP2WVheU8ciHa/hup63eiQ4LZXhmIiOzkhiZlcSwPglEOEP9HKVSbRORZcaYXHfKOrwdjApy2VNhwWNQVQTRyf6O5hhDesXz/l1j2VdWy7f5xXybX8zS7cX8Zd4mjAFnqDCkZzwj+yYxKiuJ3Mwk4qOc/g5bqQ7RM3zlXXu+g5nj4bJnYej1/o7GbWXVDSzbWczS7SV8m1/MqoJSGpqMHTkiPdb+AnAdBDLiI45Y1xhDVX0TpdX1lFY32EeNnS6rafh+fk1c+Q4fAAAVRklEQVQDZa5lzQZiIxzERjiJjXAQF+EgzjUde8yzXRYX4SQmwkFoiPjpU1KBoD1n+JrwlXcZA38eCL1GwrWv+DuaDqttaGLFrlK+3V7M0vxilu8ooareXlTWOymStNgISqvrXQm9gcbjdPuMdIaSEOUkPtJJQpSThMgwRKCitpGK2gYqahspd03XuXFP3+iwUCLDQnGEhOAIFZyhIThDBUeI6zk0BEeIne84ar4zRHCECknR4QzIiCU7I5aTU2MIc2jzXlehVToqcIjYxtvVb0NjHTjCPb+PjR9DeCxkjfP8tl0inKGM7pfM6H62WqqxqZn1eytYml/Mt9uLKa9tYEBGHPFRThJaJPL4KCeJUWGu107iIp3tahOob2ymorbh8AHg0EHBvnZN1zRS09BEY1Mzjc2GhqZmGpsMjc3NNLR4rq5vdC03h8vWNzbT2NxMcVU9DU32IOUIEfqlRpOdEWcPAun2QNArMRIRz/6aaG42lNU0EO4MISpM05G36Rm+8r5Nc+G1q2Hau9D/XM9ue98amHkOhDhg+hzoOcKz2w8S9Y3NbD9YxYZ95WzcV8HGfRVs2FfB7tKaw2Viwh2cmh7z/YEgI5YBGbEkRIUdLnMogRdV1VNcVU9RZV0b0/UUVdVTUl1PU7PBGSqc0TeZiQPSmDQwjczkaH98DF2SVumowNJQC3/oC0NvgAv/5LntNjXCrHOhdBeERdtfEHfMh7iTPLePIFdR28Cm/Tb5HzoIbNxXccS1C+lx4SREhh2RwFsTF+EgJSacpOgwkqLDSI4JJ9k1vb+8ls83FLKlsBKA/mkxTBqQxsQBaYzITMQRqlVMbdGErwLPGzfaBtyfrLXVPJ7wzZMw9xdw1YuQOhBmnQcpp9ozfWekZ/ahjmGMYX953RG/BirrGo9I4MkxYSRH2+SeEhNGYnQYTjeS9o6iKr7YUMgXGwpZvK2IhiZDXISD8dn2zP+cU1OP+EURCIwxNDUbvx2UNOGrwPPdq/DBXXDnAjjp9M5vr2grPDMWTp4A171mDyIbPrIHliFXwxUzPXdg6c4a6+CzX9qb1VzwvxCZ4O+IDqusa+TrzQf4fH0hX24s5GBlPSECuZlJTByYxqQBafRPi/F4u8KJ1DY0saqgjLwdxSzLL2HZzhJq6ps4vXcCo1y9t4b3SSA2wjfddzXhq8BTdRAe6w/jH7SPzjAGXrrY3iz97iUQ1+P7ZQv+CF/8Gs79bxj3k87tp7sr3wNv3gS780BCIb4nXPU36OVW7vCp5mbDyoJSvthQyOfrC1m3txywPaQmDUhndL8keiVG0TsxirhIh0cPAgcq6li2o5hlO0rI21HCmt1lhxu4+6VGk5uZSEy4k7wdxazdU05TsyFEYOBJcYzMSmJU3yRysxJJi404wZ46RhO+CkyzLoDGGnuW3xnLXoJ/3gMX/x+MuPXIZcbAu7fBmvfg+tftMM3qWDu+gbdugYZquOwZiD0J3p1hDwITH4Yz74GQwK0331tWY6t+1hfy9ZaDR3RfjQ130DMxkl6JkfRKjHI9R9IzwU4nRDnbPCA0Nxu2HKgkL7/EnsHvKGFHUTUAYY4QTusZz4isRHIzkxiRmUhS9JHVS1V1jXy3s5Sl+cXk5RezfGcJtQ02tqzkqMPXb4zMSiIrOcojByZN+Cowff04zPsl/GSdPZvsiPI98NQZtlroln+2Xm1TXw1/mwJFW+D2eZA2sHNxdyfGwLcvwCcPQkKmrQ5LG2CX1ZTChz+G9R/a4a0vfw5iUv0brxtq6pvYUljJ7tJqCkpqWjzs68q6xiPKR4eF0isxqsVBIZL6xmbydpSwfEcJ5bW2fHJ0GCMyE8nNSmREZhI5PeMId7RvmI2GpmbW7C5zXcVdQl5+MSXVtsE7NTacka6Dx6i+SQzuEdehA4AmfBWYDmyCp0banjojb2//+sbAGzfYe+X+xzeQfHLbZcv32Ct8nZHwgy8hKqnDYXcbDbXw0X/CilfttRGXP3dsnb0xkPcifPKQXXbFTOg33h/ReoQxhvKaRnaVVLO79MgDwW7X9KEEf0paDCMyE11J3nNn4C01Nxu2Hqjk2/ySw8N47C6tITHKyfKHz+u6CV9EIoAFQDj2Aq93jDG/PN46mvC7OWPgyRGQ1Nf2yW+vNe/BO9PhvF/D2HtOXL4gD/42FXqPgpveh9AAHQNn32qoq4Q+o73X0FxWAG9Osz2lznkQznng+FU2+9bYz/rgZjjrpzD+IXvrym7oUBfT+MgOfD8KlsH830JVoW0zGnRZu/+Ge0pr2FVczRn9OjbWVHsSvjcr6eqAicaY04GhwGQRGe3F/alAJ2Lr1LcvsL1C2qO6GObcDz2Gwei73FunVy5c8gTkL7RVGIGmsR7mPQrPngV/m2wvIFv9jr2+wJO2L4TnzoGDW+C612HCQyeun8/Isdc0DLsRFv4RXrrIHjS6ofhIZ/uT/d6V8Nq18MJE2LMcGmrg7Vvh+QmwbX67NtUjIbLDyb69vJbwjVXpeul0PQKn/kj5R/YUaKqHrV+2b71P/x/UlsIlf23fmebp19kGyG9fgG9ntW+f3nRgk71u4Os/w7BpcNHjUF9lG5yfHAZLnrOvO8MYWPwMvHyprdL6wRcwYKr764dFw6VPwRUv2F8hz4y1XV+D2f519pfSc2fDzsUw6RG4dxXctRgufRoqD9jP++XL7K+pAOPVOnwRCQWWAf2Bp4wxD7RS5g7gDoA+ffqM2LFjh9fiUQGgqREeO9kOm3z5M+6ts3kevHolnP1fMPHn7d9ncxO8fj1s/Rxu+oe99aK/HKoj//Tn4IyAi5+AQZe44my29wD+9/9BwVKITISRP4BRd7S/8bS+Gv51H6x6EwZcZHviRMR1PO6irbaKZ+9KGHUnnP9r74yLFKgObrZVN2ves+M2jb4LxtwFEfFHlmuohbxZtntwTTEMvtz2ejpee1MnBUQd/hE7EUkA3gd+bIxZ01Y5rcMPEu/dAZs/g/u3QMgJej3UVcDTY8AZBT9c2PEkU1sOL5wLVQfsmW5S345tpzMqD8CHP4JNn8DJE+0ZYVvDQOxcDP9+AjZ+BI4IOyzFmB+5lzhKdtiz0H2rYcLPbR28J7pYHrpIa8kzkHEaXP13ryaygFC8Db76gz1wOiLhjDvhzB+fuBNAbZm9EnzRU/ZzG36zvf4kNsPjIQZcwgcQkUeAamPMH9sqowk/SKx939Z3Tv8EMsccv+yc+2Hp83DbXNv42hlFW+H5ifZCrdvm2jM1X9n4iU32teVw3q/sWbs7SfjAJlj0JKx8A5oaYODFMPbeti+O2jYf3p5uf9Vc+TyceoFH3wYAG+bYq6abGuDCP8Pp13p+H/5WugsW/AFWvGYH5ht5O4y9r/2/tCr22xsALfsbhDhh9H/Yv58Hr2gOiIQvIqlAgzGmVEQigbnA740x/2prHU34QaK2HP7Qz375z/912+V2LoYXJ9uzqim/98y+t82HV66w3RKvne39i4vqq+14P3mzID0Hrnge0ge1fzsV+2y9ft4se/aYOda2TZxyvn0PxsCiv8Jnj9jxhK57zbtn32W74d3bYec3MPRGOPdRaG6wvY3qKqC+osW06/nwdCXUlbeYrrDdZ9MHf/9IG+yfawDK98LCP8Hyl+zrEbfaX0idPTMv3gZf/C+seQciEuw2R/3AI2M+BUrCPw14CQjFNg6/ZYz51fHW0YQfRF653J5F/biNv3dDLTx3ln2+axGEx3hu30tmwsf323+6SY94brtH2/MdvPsDKNpsqwEmPtz5eu+6Clj+Mix6GsoLIHWArerZNt8mk4GXwGVP++bXS1MjfPV7ewbrTn8MCbVxhcdCWIz9mx6ariu3DaJVhd+Xj0478iCQPhhSsm3bh6dVHoCv/2IPqM2NtiH9rJ9BQm/P7mfvKvj8UdgyD+J62mqe02/oVJfXgEj4HaEJP4gsfR7m/Ax+lAcppxy7/PNf2+6A096D/pM8u29j4J/32rO4K2fBkKs8u/3mJvj34/Dlb2zSuvxZ6HeOZ/fR1GAbEL95AvavAcQevMb9xPeDxu1aan+NHZHMY21CD4uB8Dg77Yg4cWyVB6BwLexv8TiwARpr7XIJheT+rgPAIPurKX0wxKTbXk1HPCqPP91Q/f2vjF1L7D5Ovx7Ovt/7bTzbF9qrzncvs7/IJj5sq+u66oVXHaEJP4iU7oLHc1q/iGrvKtuf+bRr7dmqNzTWwyuX2X+46R9Dz+Ge2W7JDnj/h7aqY/Dlto7bm1f5GgPbv7LJtE83vcylqdFWiRx9ICjtYI8+R4TtchoWbQ9IYdE26Y77SesnH95iDGz4F3z+K/vL7Z7vOlTFowlfdQ3PjoOwWJjx8ffzmhrtxSzle+1ImN5MllUHYeYEW/c8fQ7E9+n4T2tjYNVb9leLMTD1MXsNgA7R7D215VC43v7CqS52/aI4KpEfPe2MDrwrhpsaoSQfUvp3aHW9p63qGrKn2vrfqiKIdl1puPgp29f76pe8P/5NdIodUXPW+fDEMDsvLMb2rY6It1URh6Yj4tqYH2+7jC78I6x5F3qPhiueg8Qs78au7N+kzxn20ZWFOjqc7NtLE77yn+wpttFv81wYer3tNvnlb+yFQoMu9U0MGTm2i2b+QnvGWFtmH3Wu58p9cHDT9/NNU+vbCXHAxF/A2J8E3hmkUi76zVT+c9JQOw77xjm2vv7DeyA03I6m6cuqkIwc+zgRY2xD36Hk3/IAcagRUakApglf+Y+I7Q+/+m1YOhN2fG3HyvHC1YgeIfJ9XXDLu2wp1UUE7i1tVHDInmq7xn3yIPQ9x/Z/Vkp5hZ7hK//qe7Zt9AR7y0Lt1aKU12jCV/7ljIDJv7MjQ/pjQDOlgogmfOV/I27xdwRKBQWtw1dKqSChCV8ppYKEJnyllAoSmvCVUipIaMJXSqkgoQlfKaWChCZ8pZQKEprwlVIqSATUDVBE5ADQwdvYkAIc9GA4nqbxdY7G1zkaX+cEcnyZxhi37vgeUAm/M0Qkz927vviDxtc5Gl/naHydE+jxuUurdJRSKkhowldKqSDRnRL+TH8HcAIaX+dofJ2j8XVOoMfnlm5Th6+UUur4utMZvlJKqePQhK+UUkGiyyV8EZksIhtFZIuIPNjK8nARedO1fImIZPkwtt4i8qWIrBORtSJybytlxotImYiscD0e8VV8rv3ni8hq177zWlkuIvKE6/NbJSLDfRhbdovPZYWIlIvIfUeV8ennJyIvikihiKxpMS9JRD4Tkc2u58Q21r3FVWaziHjlLi9txPeYiGxw/f3eF5GENtY97nfBi/H9t4jsbvE3nNrGusf9X/difG+2iC1fRFa0sa7XPz+PM8Z0mQcQCmwF+gFhwEpg0FFl7gKedU1fB7zpw/hOAoa7pmOBTa3ENx74lx8/w3wg5TjLpwIfAwKMBpb48W+9D3tRid8+P+BsYDiwpsW8PwAPuqYfBH7fynpJwDbXc6JrOtFH8Z0POFzTv28tPne+C16M77+Bn7nx9z/u/7q34jtq+Z+AR/z1+Xn60dXO8EcBW4wx24wx9cAbwKVHlbkUeMk1/Q4wScQ3d8Y2xuw1xix3TVcA64Gevti3B10KvGysxUCCiJzkhzgmAVuNMR298tojjDELgOKjZrf8jr0EXNbKqhcAnxljio0xJcBnwGRfxGeMmWuMaXS9XAz08vR+3dXG5+cOd/7XO+148bnyxjXA657er790tYTfE9jV4nUBxybUw2VcX/oyINkn0bXgqkoaBixpZfEYEVkpIh+LyGCfBgYGmCsiy0TkjlaWu/MZ+8J1tP2P5s/PDyDdGLPXNb0PSG+lTKB8jjOwv9hac6Lvgjf9yFXl9GIbVWKB8PmdBew3xmxuY7k/P78O6WoJv0sQkRjgXeA+Y0z5UYuXY6spTgeeBP7h4/DGGWOGA1OAu0XkbB/v/4REJAy4BHi7lcX+/vyOYOxv+4Ds2ywiPwcagVfbKOKv78IzwMnAUGAvttokEF3P8c/uA/5/6WhdLeHvBnq3eN3LNa/VMiLiAOKBIp9EZ/fpxCb7V40x7x293BhTboypdE3PAZwikuKr+Iwxu13PhcD72J/OLbnzGXvbFGC5MWb/0Qv8/fm57D9UzeV6LmyljF8/RxG5FbgIuNF1UDqGG98FrzDG7DfGNBljmoHn29ivvz8/B3AF8GZbZfz1+XVGV0v43wKniEhf11ngdcCHR5X5EDjUI+Iq4Iu2vvCe5qrzmwWsN8b8uY0yGYfaFERkFPZv4JMDkohEi0jsoWls496ao4p9CNzs6q0zGihrUX3hK22eWfnz82uh5XfsFuCDVsp8CpwvIomuKovzXfO8TkQmA/8FXGKMqW6jjDvfBW/F17JN6PI29uvO/7o3nQtsMMYUtLbQn59fp/i71bi9D2wvkk3YFvyfu+b9CvvlBojAVgVsAZYC/XwY2zjsz/tVwArXYyrwQ+CHrjI/AtZiex0sBs70YXz9XPtd6Yrh0OfXMj4BnnJ9vquBXB//faOxCTy+xTy/fX7YA89eoAFbj3wbtk3oc2AzMA9IcpXNBV5ose4M1/dwCzDdh/FtwdZ/H/oOHuq11gOYc7zvgo/ie8X13VqFTeInHR2f6/Ux/+u+iM81/++HvnMtyvr88/P0Q4dWUEqpINHVqnSUUkp1kCZ8pZQKEprwlVIqSGjCV0qpIKEJXymlgoQmfKU8wDWK57/8HYdSx6MJXymlgoQmfBVURGSaiCx1jWH+nIiEikiliPxF7D0MPheRVFfZoSKyuMW48omu+f1FZJ5rALflInKya/MxIvKOayz6V301SqtS7tKEr4KGiAwErgXGGmOGAk3Ajdire/OMMYOBr4BfulZ5GXjAGHMa9srQQ/NfBZ4ydgC3M7FXaoIdHfU+YBD2SsyxXn9TSrWDw98BKOVDk4ARwLeuk+9I7MBnzXw/SNZs4D0RiQcSjDFfuea/BLztGj+lpzHmfQBjTC2Aa3tLjWvsFdddkrKAr73/tpRyjyZ8FUwEeMkY89ARM0UePqpcR8cbqWsx3YT+f6kAo1U6Kph8DlwlImlw+N60mdj/g6tcZW4AvjbGlAElInKWa/5NwFfG3smsQEQuc20jXESifPoulOogPQNRQcMYs05EfoG9S1EIdoTEu4EqYJRrWSG2nh/s0MfPuhL6NmC6a/5NwHMi8ivXNq724dtQqsN0tEwV9ESk0hgT4+84lPI2rdJRSqkgoWf4SikVJPQMXymlgoQmfKWUChKa8JVSKkhowldKqSChCV8ppYLE/wf2igGE27TwiwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "titanium\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duracloud\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bamboo\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clover\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jirasoftware\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moodle\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xd8FXW6x/HPc05Oei8EQui9SJGAgqgoWBCxK7uWdW2sd3XXsuuu3pV13bv3Xu+6xV07VlbXggUrKhaQKhiq9GaAECAhpNeT5Hf/mAFCJBBCTuaU5/16zevMmTPnzDM5MN8zv5n5jRhjUEopFbpcTheglFLKWRoESikV4jQIlFIqxGkQKKVUiNMgUEqpEKdBoJRSIU6DQKljEJGXReRPLZw3R0QmnOznKNXeNAiUUirEaRAopVSI0yBQAc9ukrlPRNaISIWIvCAi6SLyiYiUicgXIpLUaP5LRGSdiBSLyDwRGdDoteEissJ+35tAZJNlXSwiq+z3LhaRIa2s+TYR2SoiB0TkAxHJsKeLiPxdRPJFpFREvhORwfZrF4nIeru23SLy61b9wZRqQoNABYsrgfOAvsBk4BPgP4E0rH/nvwQQkb7A68Dd9muzgQ9FJFxEwoH3gFeAZOAt+3Ox3zsceBH4GZACPAt8ICIRJ1KoiJwL/C9wDdAJ2AG8Yb98PnCWvR4J9jyF9msvAD8zxsQBg4GvTmS5SjVHg0AFi8eNMfuMMbuBBcBSY8xKY0w1MAsYbs83BfjYGPO5McYL/AWIAsYApwMe4DFjjNcY8zbwbaNlTAWeNcYsNcbUG2NmADX2+07EdcCLxpgVxpga4AFgtIh0B7xAHNAfEGPMBmPMHvt9XmCgiMQbY4qMMStOcLlKHZUGgQoW+xqNVx3leaw9noH1CxwAY0wDsAvobL+22xzZE+OORuPdgF/ZzULFIlIMdLHfdyKa1lCO9au/szHmK+AJ4EkgX0Smi0i8PeuVwEXADhH5WkRGn+BylToqDQIVavKwNuiA1SaPtTHfDewBOtvTDuraaHwX8N/GmMRGQ7Qx5vWTrCEGq6lpN4Ax5p/GmBHAQKwmovvs6d8aYy4FOmA1Yc08weUqdVQaBCrUzAQmich4EfEAv8Jq3lkMLAHqgF+KiEdErgBGNXrvc8DtInKafVA3RkQmiUjcCdbwOnCTiAyzjy/8D1ZTVo6IjLQ/3wNUANVAg30M4zoRSbCbtEqBhpP4Oyh1iAaBCinGmE3A9cDjwH6sA8uTjTG1xpha4Argp8ABrOMJ7zZ6bzZwG1bTTRGw1Z73RGv4ApgGvIO1F9IL+JH9cjxW4BRhNR8VAo/ar90A5IhIKXA71rEGpU6a6I1plFIqtOkegVJKhTgNAqWUCnEaBEopFeI0CJRSKsSFOV1AS6Smppru3bs7XYZSSgWU5cuX7zfGpB1vvoAIgu7du5Odne10GUopFVBEZMfx59KmIaWUCnkaBEopFeI0CJRSKsQFxDGCo/F6veTm5lJdXe10KT4VGRlJZmYmHo/H6VKUUkHKZ0EgIi8CFwP5xpjBTV77FVY/8GnGmP2t+fzc3Fzi4uLo3r07R3YWGTyMMRQWFpKbm0uPHj2cLkcpFaR82TT0MnBh04ki0gXrLkw7T+bDq6urSUlJCdoQABARUlJSgn6vRynlLJ8FgTFmPlYPjk39HfgNcNK93QVzCBwUCuuolHJWux4jEJFLse4AtbpdNnDVJeCtAnGDyx6ajosLdGOrlAph7RYEIhKNdTPx81s4/1Sse8TStWvX48zdjOpSqDzeIQixgyEMPFHgibaHKGt6M4qLi3nttdf4+c9/fkIlXXTRRbz22mskJiae0PuUUspX2nOPoBfQAzi4N5AJrBCRUcaYvU1nNsZMB6YDZGVlta4ZKbELJHSGhgYwddBQbw2m/ofj9bVQUw5VRYff746A8OijhkNxcTFPPfXUD4Kgrq6OsLDm/6yzZ89u1aoopZSvtFsQGGO+w7rXKgAikgNktfasoRYTF7hdtHhV673grbSG2qofhkNYJCR24/7772fbtm0MGzYMj8dDZGQkSUlJbNy4kc2bN3PZZZexa9cuqqurueuuu5g6dSpwuLuM8vJyJk6cyNixY1m8eDGdO3fm/fffJyoqqu3/BkopdQy+PH30dWAckCoiucBDxpgXfLGshz9cx/q80jb9zIEZ8Tw0eZD1pN5rHWvwVkJlIRRu5ZGHp7F27VpWrVrFvHnzmDRpEmvXrj10mueLL75IcnIyVVVVjBw5kiuvvJKUlJQjlrFlyxZef/11nnvuOa655hreeecdrr/++jZdD6WUOh6fBYEx5sfHeb27r5bd5twea4iMh6hkOLAVinPAHL53+KhRo4441/+f//wns2bNAmDXrl1s2bLlB0HQo0cPhg0bBsCIESPIycnx+aoopVRTAXtlcWOHfrm3h7BwSOkDu/ZYxxXsZqOYmJhDs8ybN48vvviCJUuWEB0dzbhx4456LUBERMShcbfbTVVVle/rV0qpJrSvodZwe4jrOpiyiiooyoGqkiNeLikpISkpiejoaDZu3Mg333zjTJ1KKdUCQbFH4ISUtHTOGHsWg8dPISrCQ3rHjEOvXXjhhTzzzDMMGDCAfv36cfrppztYqVJKHZsYc9IX+PpcVlaWaXpjmg0bNjBgwACHKmrENEDRDqguhtiOENexzS9Q85t1VUoFFBFZbozJOt582jR0ssQFSd0hOgXK90LpbgiAcFVKqYO0aagtiEBCF6vLiop86wK1xK7adYVSKiBoELQVEYjPsK48LttjXbGc1N3aY1BKKT+mW6m2JGIdI4jvbHV4V1nodEVKKXVcGgS+EJNm9VPU5LRSpZTyRxoEviACUQlQWw4NdU5Xo5RSx6RB0EoHex9tVmQiYKyusJt47LHHqKys9F1xSil1AjQIWum4QeCJBpfHur6gCQ0CpZQ/0bOGWqlxN9TnnXceHTp0YObMmdTU1HD55Zfz8MMPU1Hv4ZqrbyR3fyn19fVMmzaNffv2kZeXxznnnENqaipz5851elWUUiEuOILgk/th73dt+5kdT4GJjzT78iOPPHKoG+o5c+bw9ttvs2zZMowxXHLJJcyfP5+C3TvI6JjGxx99CFGJlJSUkJCQwN/+9jfmzp1Lampq29aslFKtoE1DbWDOnDnMmTOH4cOHc+qpp7Jx40a2bNnCKaeO5PP5S/nt/fezYMECEhISnC5VKaV+IDj2CJr55V5cWUtlbT0uEVwucIvY44JbwOWyn4vgdgkuAWnF1cDGGB544AF+9rOf/eC1FV/PZvbsj3nwwQcZP348v//970/485VSypeCIwiaUeWtp6iyloYGQ0t6/3GJ4HELYS4XYW7B47YfGz33uAW3y0VcXBxlZWUAXHDBBUybNo3rrruO2NhYdu/ejcfjoa6ujuSkdK6/YiKJnXvz/IzXAA69V5uGlFL+IKiDoFNCFJ0SojDGYAzUG0NDg6HBGOoNjcYN9Q2Gunpr8DY0UO1toKy6joajdCCXEOUhNTaBM844g8GDBzNx4kSuvfZaRo8eDUBsbCyvvvoqW7du5b777sNVX4MnIpKnp1t36pw6dSoXXnghGRkZerBYKeU47Yb6OKyAaMBrP1Z56zlQUUt9gyHK4yY1LoKEKA+uYzUpHdgOtZWQPqhVHdFpN9RKqdZoaTfUQb1H0BbcLsHtcnPwppKJQHpcJEWVtewvr2XXgUr2ul2kxISTHBNOmPsox98jE6y+h7yVEB7zw9eVUspBGgSt4HIJKbERJMeEU1ZTx/6yGvaWVpNfVkNitIfU2AgiPe7Db4iwzxaqLtEgUEr5nYAOAmNMq87yaSsiQnykh/hID9XeevaX1VBU6eVARS1xkR4yk6LwuF3gDoPwWKgqtrqqPgGB0HSnlApsAXsdQWRkJIWFhX6zoYz0uMlMjqZ/xzjS4yOpqKljd1HV4RmiEqG+BrzVLf5MYwyFhYVERkb6oGKllLIE7B5BZmYmubm5FBQUOF3KUVVWe9lTVUdRXrjVTNRQD6X5sK8WIuNb/DmRkZFkZmb6sFKlVKgL2CDweDz06NHD6TKaVVNXz4WPLcAYw2f3nEVEmBue+6V1s/up85wuTymlDgnYpiF/FxHm5g+XDCKnsJLnF3xvTex/MeSthJJcZ4tTSqlGNAh86Oy+aVwwKJ3Hv9rC7uIqGDDZemHjx84WppRSjWgQ+Ni0iwcC8KeP1kNqH0jrDxs+dLgqpZQ6TIPAxzKTorljXG8+WbuXBVsKrOahHYuh8oDTpSmlFODDIBCRF0UkX0TWNpr2qIhsFJE1IjJLRBJ9tXx/cttZPemWEs1DH6zD23cSmHrY9InTZSmlFODbPYKXgQubTPscGGyMGQJsBh7w4fL9RqTHzR8mD2J7QQXPb42HhC6w8SOny1JKKcCHQWCMmQ8caDJtjjGmzn76DRAyJ8if078DEwak8/jcrVT0uAC2fQW1FU6XpZRSjh4juBlotn1ERKaKSLaIZPvrRWMn6qHJA6lvMDy3fxDUVcPWL5wuSSmlnAkCEfkdUAf8u7l5jDHTjTFZxpistLS09ivOh7okR/Mf43rx+NZUvBFJsEGbh5RSzmv3IBCRnwIXA9cZf+koqB3dfnYvMpJj+bLhVMzmT6Gu1umSlFIhrl2DQEQuBH4DXGKMqWzPZfuLSI+bhy4exFsVw5CaUshZ4HRJSqkQ58vTR18HlgD9RCRXRG4BngDigM9FZJWIPOOr5fuzCQPTcfceT6WJoHLNe06Xo5QKcQF7q8pAt6OwgvX/uJwxni0k/G4buPTaPqVU22rprSp16+OQbikxmH6TSKg/wLplevaQUso5GgQOOmfyT/ASRt43bzldilIqhGkQOCgqPomcuBH0Lfqasio9e0gp5QwNAoeFD76EbrKPpUsXOl2KUipEaRA4rOuYq2hAKF05y+lSlFIhSoPAYRLXkbzYU+hX9DWF5TVOl6OUCkEaBH7AM2gyg1w7mL8suE6RVUoFBg0CP9Bh1FUAlK7Ui8uUUu1Pg8APSEpPCmL60L9kPnnFVU6Xo5QKMRoEfsIzcDIjZRNfZn/ndClKqRCjQeAnEkdcgUsMxSvfd7oUpVSI0SDwF+mDKY3szODSBWwvKHe6GqVUCNEg8BciuAdNZoxrHZ8u3+x0NUqpEKJB4EdihlxGhNRRuOojAqFXWKVUcNAg8CddRlEVnszwikWsyyt1uhqlVIjQIPAnLjeu/pMY51rF7JXfO12NUipEaBD4mYhTLiNWqslf9RkNDdo8pJTyPQ0Cf9PjLLxhsWRVL2b5ziKnq1FKhQANAn8TFo70vYDz3cv5cOUup6tRSoUADQI/FDZoMslSxp7v5lJX3+B0OUqpIKdB4I96n0e9K5zRtUtYtK3Q6WqUUkFOg8AfRcRCr3O4MCybD1budroapVSQ0yDwU+4Bk8lgP7vWL6HaW+90OUqpIKZB4K/6TcSIi7H13zBvU77T1SilgpgGgb+KSYWuo5kUtpwPVuc5XY1SKohpEPgxGXAJvdjF1g2rKav2Ol2OUipIaRD4s/6TADjHLGPOun0OF6OUClYaBP4ssQum0zAmh2vzkFLKd3wWBCLyoojki8jaRtOSReRzEdliPyb5avnBQgZczGCzmS1bN1NYXuN0OUqpIOTLPYKXgQubTLsf+NIY0wf40n6ujqX/ZADOlWw+WrPH4WKUUsHIZ0FgjJkPHGgy+VJghj0+A7jMV8sPGmn9MCm9uSp6JX/6eD0vLfpeb1qjlGpT7X2MIN0Yc/Bn7V4gvbkZRWSqiGSLSHZBQUH7VOePRJD+FzO0fi0Te0Xx8Ifruf3V5ZRU6VlESqm2Ib78dSki3YGPjDGD7efFxpjERq8XGWOOe5wgKyvLZGdn+6xOv5ebDc+Px5z9Wz4t6c7Mb3eQGhvGz8/qQY/kSDANYOqhoR6MgYY6e/Ba0+q9jabZQ73Xep+4mgzS5NEeXB5we8AVZj26ww+PuzzgDrOeH/zsei/U19rPa+3BHm84gRDzVkFNOdSUQW2Z9VhTDrX2tIODyw0R8RARB5Hx9njj53HW8+Qe0Otc67nynbxVsGk2pPSGTsMgpZf1Hal2JSLLjTFZx5svrD2KaWSfiHQyxuwRkU6AXjLbEhmnQkJX5Ov/YyIw0QPUAJ+fxGe6wqwNvDF2kDQA/tjkJPZGPA7CY+3xWIjtYG/oY63ppgFqSq1QqLYfi3dY0w4+N3ZXHe5w6HGWdXpu34kQ38nZVQwmJbnw5X/BmjeOnO6JgY6nQMYw6DTUGlL7WT8glOPa+1v4ALgReMR+fL+dlx+YXC64+RMoygFxg7goq23g719uY2lOCaN7p3H3+f2JjYywXnfZv+AP/WJ3W+MHp7nc1i/+poyxBhqFg2mw9ioavNYv+gbv4T2M+lp7/OBrdY32GsLtPYeDewxNnh9t+UerJyyiZfO25LO8lYd/qW78GD66B7gHOo+AfhdZwZDWv22W15J6SnfDvvWQv85+XG99x/0nwbnTILGL7+toK9WlsOgxWPKktW5j74Exv4SyvbBnFexZbQ0rXgHvM9Z7wiIhfTB0PhVG/BTSB7VNLbWVUFV0+N/noT3So4yn9Ye0vm2z3ADms6YhEXkdGAekAvuAh4D3gJlAV2AHcI0xpukB5R8I+aahZhhjeG7Bdv7v0010ToziyWtP5ZTMBKfLCgzGQMFGKxA2zYbdy63pST2sDXG/idDlNCu4TlZdDeSthL3fWRv7feshfwPUlByeJ74zdBgIMWmw7l2rvtNvh7H3QlRi85/dFrxVsGeNFegZp0J4dMvfW18HK16Guf8LlfthyJRjh1hDPRRus4PBDojdy62QHjAZzvoNdBrSuvXYvxWWPg2rXrM+r6W6nwmjboN+k4JuD6WlTUM+PUbQVjQIjm35jgP84rWV7C+v5XeTBvCT0d2Q9vhVG0xK98DmT2DjbPj+a+vXYngc9Dwb+pwHvSdAQmbLPssYKNwK276CrV9CzkLwVlivRSRA+kDoMMDa8KcPssajGh0qK94Fc/8bVr9hTT/7N5B1C4SFn/x61tdBwQbYvcLaAOetsILpYLOZy2M133QdbQ+nQ3Ty0ddx82fw+TTYvxm6jYXz/8v6dX+iKg/A0mfhm6etcOw7Ec6+z9pTOx5jrL/vkidh86dWcJ9yDXQZ1WgvNPzo4y639R19+yKU7IS4DMi6CU69EeKaPY8loGgQhJiiilrunbmKuZsKGJqZwLAuiQzoFE//TvH0S48jKlwP1LVYTRlsnwdbv4AtX0BprjU9bQD0Hm8FQ9fRVrPVQVVF8P18a8O/ba61YQFI7mkdnO55jrWBje/c8qanPavh899btST1gAkPwcDLWv7+hno48L31y/vghn/Paqirsl6PTLD2ADqPsDbg4oadS6xh94rDB/XTBliB0G2Mtd6VhTDnQchZYB0MPu+/rD2ok/3xUV0CS6fDkieguhh6n2eFYJdRP5y3rtbac1ryJOxdA9EpMPJWa4jtcGLLbai3Qu3b56xgcHlg4CUw8jZrvdvqR1W9F6qKrX8r3kqrY8mYDm0T8M3QIAhBDQ2Glxfn8NGaPDbtLaOi1vqV5xLonhrDgE7xDOgYZz12iqdTQqTuORyPMVCwCbZ+bgXDjsXW3oInxjrgnNbPmrY72zqecnAvotc50Gu8dZbSyS5/65fWL+/89ZA5Es7/k7WBaqy8wD7WsO7wcYf8jYc3+mGR1gHaxhv+5J7Nb+S8VVYY7FwMO5bArmXWWVsHRafAuAestv22aD5rrKYMvn0eFj9uhU7PcXD2b60gqjwAy1+yAqN8r3XAefQdMOQa8ESd/LL3b7WWveo1a+8k/RQYdau1R1hXY23AayutR2+l9XeqrTj8vKbc2tAfMdgb/8Z/v8aikiGuI8SmW0NcOsR2tAItrqN1HKWVzYMaBCGuocGwq6iSDXtKWb+njI17Stmwt5RdB6oOzZMQ5WFw53gGZyQwMCOewZ0T6JESg8t1YuFgjKGkysv+8hqiw8NIiPIQHe4OzpCpKbeaIrZ+Dls+h+KdkDHc2lPoda61oW7rDSNYv1pXvWY1GZXtgf4XQ2I32LfWCoiKRtfaxHSwm58GWY8dh1jNTydTV0O9tayd31gbv6ybrD0KX6qtgOwXYdE/oSLfOg21YJMVbr3OhdPvsP7uvvh3VlsBa2ZaobBv7fHnP0jcVnNeVJLVpHZwvOkQFml9Z+X5VqCV7YPyRkN97eHPvPYt6Ht+q1ZDg0AdVVm1l417rWBYl2cNm/aWUVvfAEBMuJuBGfEMykhgkB0OXZKjKSirIa+4it3FVewpriavuIq8kirrsbiaqiZ3UfO4hfhIDwnRHhKijhwSozxkJkXTNSWa7ikxdIiLOOHw8QvGWL8SPZHtt8zaCljylHWGjmmwznppvNHvMAhi09qvnvZQWwkrZlhnHHUebgVA+sD2WbYxVvjlr4fwGGuvwxNjHVA/Ytwe2uIsN2OsPYiDodBxyNGP07SABoFqsdq6Brbml7M2r4T1eaWs3V3C+j2lVNY2f4vMtLgIMhKjyEiIpFNCFBmJkaTFRVBZW09JlffwUOk98nmVl9JqL43/2UWEueiWEk3X5Bi6p0TTLSWabikxdEuJJsztosZbT7W3gZq6Hz7W2I+psREM6ZJIRqg0d9XV2qcF67Ef1Tx/vaBM+aHwMBcDM+IZmBF/aFp9gyGnsIK1u0vIK64mPf7ghj+K9IQIIsJavwGqq28gr7iaHQcqyCmsZGeh9bijsIIFWwqoqWto9WenxoZzSucEhmQmMrSL9ZgaG3H8NwYaHx5gVKFHg0Adldsl9EqLpVdabJt/dpjbRdcUq2nozD5HvtbQYMgvq2FHYQU7DlRijCHS4yYizEWE/RjpcRMZ5ibCY42Hu13kFVexJreY1bklrMkt5uvNBTTYex0ZCZEMyUxkSJcEzuqTxuDOeq2FUo1p05AKShU1dazLKz0iHHYUWhcZndu/A3dP6MOQTB9fqKWUw/QYgVJNFFXU8tqynTy3YDvFlV7G9+/A3RP66tXYKmhpECjVjLJqLzMW5/Dcgu8pqfIyYUA6d0/oo01GKuhoECh1HGXVXl5elMNzC7ZTWl3HeQPTuWu8BoIKHhoESrVQabWXlxbm8PzC7ZRV13H+wHTuOa8vAzrFH//NSvmxlgZBe9+hTCm/Ex/p4a4JfVj423O5e0Iflmwv5OLHF/LM19toaPD/H0pKnawWBYGI3CUi8WJ5QURWiEjrrnlWyk8lRHm4e0JfFv7mXC4YlM4jn2zk5hnfUlhe43RpSvlUS/cIbjbGlALnA0nADVg3l1Eq6CREe3jy2lP5r8sGs3hbIRf9cwFLtxc6XZZSPtPSIDh4zf5FwCvGmHWNpikVdESEG07vxqyfjyE6PIwfP/cNj3+5hXptKlJBqKVBsFxE5mAFwWciEge0vh8ApQLEoIwEPvzFWCYPzeCvn2/mJy8uJb+s2umylGpTLQ2CW4D7gZHGmErAA9zks6qU8iOxEWE8NmUYf75yCMt3FHHRPxaycMt+p8tSqs20NAhGA5uMMcUicj3wIFBynPcoFTREhGtGduGDO8eSFO3hhheX8tc5m6ir1x1jFfhaGgRPA5UiMhT4FbAN+JfPqlLKT/VNj+P9O8/g6hGZPP7VVq59fikFZXpWkQpsLQ2COmNdeXYp8IQx5kkgzndlKeW/osPD+PNVQ/n7lKGsyS3msicXsT6v1OmylGq1lgZBmYg8gHXa6Mci4sI6TqBUyLp8eCZv3z6G+gbDlU8v5tO1e50uSalWaWkQTAFqsK4n2AtkAo/6rCqlAsTgzgl8cOcZ9OsYx+2vLueJr7YQCN22KNVYi4LA3vj/G0gQkYuBamOMHiNQCugQH8kbU0/nsmEZ/GXOZu56YxXV3uZv86mUv2lpFxPXAMuAq4FrgKUicpUvC1MqkER63Px9yjDuu6AfH6zOY8qzS9hXqtcbqMDQ0qah32FdQ3CjMeYnwChgmu/KUirwiAh3nNOb6TeMYEt+OZc8sZA1ucUtem9NXT2rdxXz3srdFFfW+rhSpY7U0nsWu4wx+Y2eF6I9lyp1VOcP6sg7/zGGW2dkc/UzS/jL1UOZPDTj0OsNDYbvCytYvauY1buKWZVbwoa8UmrtaxJ6psYw4+ZRdEmOdmoVVIhp0f0IRORRYAjwuj1pCrDGGPNbH9Z2iN6PQAWi/eU13P7KcrJ3FHHzGT2IDnezOtfa+JdW1wEQHe7mlM4JDOuSyNAuiYS7XfzqrdWEh7l46acj9SY56qS0+Y1pRORK4Az76QJjzKyTKO4e4FbAAN8BNxljmm1Q1SBQgaqmrp4HZ63lreW5uF1Cv/Q4hnVNZFimteHv3SEWt+vI/hu37CvjxheXUVLl5ZkbRnBmnzSHqleBzm/vUCYinYGFwEBjTJWIzARmG2Nebu49GgQqkBlj2Hmgkg5xkUSFu1v0nr0l1fz0pWVszS/n0auHcPnwTB9XqYJRm9yhTETKRKT0KEOZiJzMpZRhQJSIhAHRQN5JfJZSfk1E6JYS0+IQAOiYEMnM20czsnsy97y5mme+3qbXJyifOWYQGGPijDHxRxnijDGtuqGrMWY38BdgJ7AHKDHGzGnNZykVzOIjPbx880gmD83gkU828vCH6/V+CMon2v3MHxFJwuqzqAeQAcTYPZo2nW+qiGSLSHZBQUF7l6mUX4gIc/OPKcO47cwevLw4h1+8vkIvVlNtzolTQCcA3xtjCowxXuBdYEzTmYwx040xWcaYrLQ0PVimQpfLJfxu0kAenDSA2d/t5ScvLKOk0ut0WSqIOBEEO4HTRSRaRAQYD2xwoA6lAsqtZ/bk8R8PZ9WuYq56ZjF7SqqcLkkFiXYPAmPMUuBtYAXWqaMuYHp716FUIJo8NIMZN49ib0k1t7+yHK/eGEe1AUeuDjbGPGSM6W+MGWyMucEYo3f2UKqFRvdK4c9XDWF1bgmPfbHZ6XJUENBuIpQKQBNP6cSUrC48NW8bS7YVOl2OCnAaBEoFqN9PHkj3lBjunblKO6pTJ0WDQKkAFRMRxj9+NIyCshr+c9Z3esGZajUNAqUC2JDMRH59QT9mf7eXt7JznS5HBSgNAqWx+dnJAAAQrElEQVQC3NQzezKmVwp/+HAd2wvKnS5HBSANAqUCnMsl/O2aYYSHubjrjVXU1ukpperEaBAoFQQ6JkTyyBVD+G53CX/7XE8pVSdGg0CpIHHh4I78eFQXnp2/jcXb9jtdjgogGgRKBZFpFw+kR2oM9765mqIKPaVUtYwGgVJBJDo8jH/+aDiFFTU88K6eUqpaRoNAqSAzuHMC913Qj0/X7eWNb3c5XY4KABoESgWhW8f2ZGzvVP744Xq25uspperYNAiUCkIul/DXa4YS6XFxxVOLmD5/m97QRjVLg0CpIJUeH8lbt49mRLck/mf2Rib87WveX7WbBr3dpWpCg0CpINa7Qxwv3TSKV285jfhID3e9sYrLn1rE0u3aY6k6TINAqRAwtk8qH/1iLH+9eij5ZTVMmf4Nt/0rm23aJYUCJBBOL8vKyjLZ2dlOl6FUUKj21vPCwu95et42qrz1XDuqK3dN6ENqbITTpak2JiLLjTFZx5tP9wiUCjGRHjd3nNObefeN47rTuvLasp2Me3Qezy/YrtcdhCgNAqVCVGpsBH+8dDBz7jmL03ok86ePN/DLN1ZRVatnF4UaDQKlQlyvtFievzGL317Yn4/W5HHNs0vYU1LldFmqHWkQKKUQEf5jXC+euyGL7QXlXPLEIlbsLHK6LNVONAiUUodMGJjOrDvOIMrj5kfTv+Gd5XrXs1CgQaCUOkLf9Djev+MMRnRN4ldvreZ/Zm+gXi9CC2oaBEqpH0iKCedft4ziJ6O7MX3+dm6Z8S2l1V6ny1I+okGglDoqj9vFHy8dzH9fPpiFW/Zz2ZOL+H5/hdNlKR/QIFBKHdN1p3Xj1VtPo6iilkufWMjXmwucLkm1MQ0CpdRxnd4zhQ/uHEunhChufHEZt7z8LWt3lzhdlmojGgRKqRbpkhzNrDvGcN8F/cjeUcTFjy/k9leWs2lvmdOlqZOkfQ0ppU5YabWXFxZ8zwsLv6eito7JQzK4e0IfeqbFOl2aaqSlfQ05EgQikgg8DwwGDHCzMWZJc/NrECjln4oqapm+YDsvL8qhpq6eK07N5K7xfeiSHO10aQr/D4IZwAJjzPMiEg5EG2OKm5tfg0Ap/7a/vIZn5m3jlW92UN9guDqrC784tzcZiVFOlxbS/DYIRCQBWAX0NC1cuAaBUoFhX2k1T87dyuvLduIS4X+vOIUrTs10uqyQ5c/dUPcACoCXRGSliDwvIjFNZxKRqSKSLSLZBQV6uppSgSA9PpI/XjqYub8ex/Cuidw7czV/+GAd3voGp0tTx+BEEIQBpwJPG2OGAxXA/U1nMsZMN8ZkGWOy0tLS2rtGpdRJyEyK5tVbTuOWsT14eXEO1z2/lP3lNU6XpZrhRBDkArnGmKX287exgkEpFUTC3C6mXTyQx6YMY01uMZMfX8jqXc0eClQOavcgMMbsBXaJSD970nhgfXvXoZRqH5cN78zbt4/BJcLVzy5hZvYup0tSTTh1QdkvgH+LyBpgGPA/DtWhlGoHgzsn8OEvxjKqezK/eXsN095bS22dHjfwF2FOLNQYswo47pFspVTwSI4J5+WbRvLoZ5t4dv52Nuwp5anrT6VDXKTTpYU87WJCKdVuwtwuHrhoAI//eDjr8kqZ/PhCvROaH9AgUEq1u8lDM3j352OICHMz5dklzFqpd0JzkgaBUsoRAzrF88GdZzCiWxL3vLmap+ZtJRD6PgtGGgRKKcckRocz4+ZRTB6awZ8/3cRDH6zT22I6wJGDxUopdVBEmJt/TBlGRkIkz87fzr7Sav7xo+FEetxOlxYydI9AKeU4l0t44KIBPDR5IHPW7+Pa576hqKLW6bJChgaBUspv3HRGD5669lTW5pVy5dOL2XWg0umSQoIGgVLKr0w8pRP/vvU0CitqufypxXyXq7fE9DUNAqWU3xnZPZl3/mM0EWEupkxfwrxN+U6XFNQ0CJRSfql3hzhm/XwM3VNiuGVGtvZR5EMaBEopv9UhPpI3f3Y6Y3ql8Ju31/Dwh+uo9tY7XVbQ0SBQSvm1uEgPL/50JDeO7sZLi3K49IlFbNhT6nRZQUWDQCnl9zxuFw9fOpiXbhpJYUUtlz6xiOcXbKdBLz5rExoESqmAcU6/Dnx295mc3S+NP328getfWMqekiqnywp4GgRKqYCSEhvB9BtG8H9XnsKqXcVc8Pf5fLQmz+myApoGgVIq4IgIU0Z2ZfYvz6RnWix3vraSe99cRWm11+nSApIGgVIqYHVPjeHt20dz1/g+vL86j4mPLWDZ9wecLivgaBAopQJamNvFPef1ZebPRuN2CVOmL2Hae2vJL612urSAoUGglAoKI7olMfuuM7nh9G68vmwnZz06l//9ZIN2XtcCEgg3gsjKyjLZ2dlOl6GUChA7Cit47IstvLdqN7HhYdx2Vk9uHtuD2IjQ6nlfRJYbY457f3gNAqVU0Nq0t4y/fb6Jz9btIzkmnJ+P68X1p3cLmXsdaBAopZRt9a5i/jJnEwu27Cc9PoJfju/DNVld8LiDu3Vcg0AppZpYsq2Qv8zZxPIdRXRNjubOc3pzybCMoN1D0CBQSqmjMMYwb1MBj362ifV7SkmNDef607tx/endSI2NcLq8NqVBoJRSx2CMYdHWQl5YuJ25mwoID3Nx2bAMbhnbk34d45wur020NAhC6xC6UkrZRISxfVIZ2yeVrfnlvLToe95ZkcvM7FzG9k7lljN7cHafNFwucbpUn9M9AqWUshVV1PLasp38a0kO+0pr6JUWw81je3DF8EyiwgPvOII2DSmlVCvV1jUw+7s9vLDwe77bXULnxCieuX4Ep2QmOF3aCWlpEDh27pSIuEVkpYh85FQNSil1NOFhLi4b3pkP7jyD1247DWMMVz6zmLeX5zpdmk84eRLtXcAGB5evlFLHJCKM6ZXKh78YS1a3JH791mqmvbeW2roGp0trU44EgYhkApOA551YvlJKnYiU2Aj+dfMopp7Vk1e+2cG1z30TVJ3aObVH8BjwG6DZWBWRqSKSLSLZBQUF7VeZUkodRZjbxX9eNIDHfzycdXmlXPz4QpbvCI4ur9s9CETkYiDfGLP8WPMZY6YbY7KMMVlpaWntVJ1SSh3b5KEZzLpjDFHhbn40/RteWZJDIJx0cyxO7BGcAVwiIjnAG8C5IvKqA3UopVSr9O8Yzwd3jGVs71Smvb+O+95eQ7W33umyWq3dg8AY84AxJtMY0x34EfCVMeb69q5DKaVORkK0hxduHMkvx/fh7eW5XP3MEnYXVzldVqvolcVKKdVKLpdw73l9OaVzAve+uYoz/+8rOiVEkZkURdfkaLokR9Ml2R5PiiYtLgIR/7tSWS8oU0qpNpCzv4J3V+5m14FKdh2oZOeBSvLLao6YJyLMRWZSFH3T47jjnN4M7uzbC9T0ymKllHJYtbee3KIqKxyKDgfEtzlFFFXWMiWrC7++oJ/Pej3VTueUUsphkR43vTvE0rtD7BHTS6u9PP7lFl5alMPHa/Zw14Q+/GR0d8LDnDmjP7hvz6OUUn4oPtLD7yYN5LN7zmJE9yT+9PEGLnxsPnM35jtSjwaBUko5pFdaLC/fNIqXfjoSgJte/pabXlrGtoLydq1Dg0AppRx2Tv8OfHr3WTw4aQDZOUVc8Pf5/Omj9ZRWe9tl+RoESinlB8LDXNx6Zk+++vU4rhqRyQuLvuecR+exeNt+ny9bg0AppfxIWlwEj1w5hA/vHMvAjHh6pMb4fJl61pBSSvmhwZ0TeOWW09plWbpHoJRSIU6DQCmlQpwGgVJKhTgNAqWUCnEaBEopFeI0CJRSKsRpECilVIjTIFBKqRAXEPcjEJECYEcr354K+P4a7fah6+J/gmU9QNfFX53MunQzxqQdb6aACIKTISLZLbkxQyDQdfE/wbIeoOvir9pjXbRpSCmlQpwGgVJKhbhQCILpThfQhnRd/E+wrAfouvgrn69L0B8jUEopdWyhsEeglFLqGDQIlFIqxAV1EIjIhSKySUS2isj9TtdzMkQkR0S+E5FVIpLtdD0tJSIviki+iKxtNC1ZRD4XkS32Y5KTNbZUM+vyBxHZbX8vq0TkIidrbCkR6SIic0VkvYisE5G77OkB9d0cYz0C7nsRkUgRWSYiq+11edie3kNEltrbsTdFJLzNlx2sxwhExA1sBs4DcoFvgR8bY9Y7WlgriUgOkGWMCaiLZETkLKAc+JcxZrA97c/AAWPMI3ZAJxljfutknS3RzLr8ASg3xvzFydpOlIh0AjoZY1aISBywHLgM+CkB9N0cYz2uIcC+FxERIMYYUy4iHmAhcBdwL/CuMeYNEXkGWG2Mebotlx3MewSjgK3GmO3GmFrgDeBSh2sKOcaY+cCBJpMvBWbY4zOw/uP6vWbWJSAZY/YYY1bY42XABqAzAfbdHGM9Ao6xlNtPPfZggHOBt+3pPvlOgjkIOgO7Gj3PJUD/gdgMMEdElovIVKeLOUnpxpg99vheIN3JYtrAnSKyxm468uumlKMRke7AcGApAfzdNFkPCMDvRUTcIrIKyAc+B7YBxcaYOnsWn2zHgjkIgs1YY8ypwETgDruZIuAZq20ykNsnnwZ6AcOAPcBfnS3nxIhILPAOcLcxprTxa4H03RxlPQLyezHG1BtjhgGZWK0a/dtjucEcBLuBLo2eZ9rTApIxZrf9mA/MwvpHEqj22W27B9t48x2up9WMMfvs/7wNwHME0Pdit0O/A/zbGPOuPTngvpujrUcgfy8AxphiYC4wGkgUkTD7JZ9sx4I5CL4F+thH3MOBHwEfOFxTq4hIjH0gDBGJAc4H1h77XX7tA+BGe/xG4H0HazkpBzeatssJkO/FPjD5ArDBGPO3Ri8F1HfT3HoE4vciImkikmiPR2Gd6LIBKxCusmfzyXcStGcNAdinjD0GuIEXjTH/7XBJrSIiPbH2AgDCgNcCZV1E5HVgHFZXuvuAh4D3gJlAV6zuxa8xxvj9Qdhm1mUcVvODAXKAnzVqY/dbIjIWWAB8BzTYk/8Tq309YL6bY6zHjwmw70VEhmAdDHZj/UifaYz5o/3//w0gGVgJXG+MqWnTZQdzECillDq+YG4aUkop1QIaBEopFeI0CJRSKsRpECilVIjTIFBKqRCnQaCUj4nIOBH5yOk6lGqOBoFSSoU4DQKlbCJyvd0f/CoRedbuAKxcRP5u9w//pYik2fMOE5Fv7E7NZh3s1ExEeovIF3af8itEpJf98bEi8raIbBSRf9tXxCrlFzQIlAJEZAAwBTjD7vSrHrgOiAGyjTGDgK+xriYG+BfwW2PMEKyrWg9O/zfwpDFmKDAGq8MzsHrFvBsYCPQEzvD5SinVQmHHn0WpkDAeGAF8a/9Yj8LqcK0BeNOe51XgXRFJABKNMV/b02cAb9n9QXU2xswCMMZUA9ift8wYk2s/XwV0x7rxiFKO0yBQyiLADGPMA0dMFJnWZL7W9snSuG+YevT/nvIj2jSklOVL4CoR6QCH7t3bDev/yMGeH68FFhpjSoAiETnTnn4D8LV9h6xcEbnM/owIEYlu17VQqhX0V4lSgDFmvYg8iHUXOBfgBe4AKoBR9mv5WMcRwOoO+Bl7Q78duMmefgPwrIj80f6Mq9txNZRqFe19VKljEJFyY0ys03Uo5UvaNKSUUiFO9wiUUirE6R6BUkqFOA0CpZQKcRoESikV4jQIlFIqxGkQKKVUiPt/ojsWquNgKGkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datamanagement\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mule\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mulestudio\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "springxd\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "talenddataquality\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "talendesb\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['mesos',\n",
       " 'appceleratorstudio',\n",
       " 'aptanastudio',\n",
       " 'titanium',\n",
       " 'duracloud',\n",
       " 'jirasoftware',\n",
       " 'moodle',\n",
       " 'mulestudio',\n",
       " 'springxd']"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rerodar = []\n",
    "for project in project_repos.keys():\n",
    "    print(project)\n",
    "    h = load_pickle(hist_data_path % project)\n",
    "    plt.plot(h['loss'])\n",
    "    plt.plot(h['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    if min(h['val_loss']) / deepse_baseline[project] > 0.95:\n",
    "        rerodar.append(project)\n",
    "rerodar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EstimativaConstrastivaRuidosa(keras.layers.Layer):\n",
    "    def __init__(self, init='glorot_uniform', comprimento=10,\n",
    "                 dimensao_entrada=None, vocabulario=None, ruidos = 25, distribuicao_ruidos=[0.5, 0.5], semente=19, **kwargs):\n",
    "        self.init = init\n",
    "        self.comprimento = comprimento\n",
    "        self.vocabulario = vocabulario\n",
    "        self.ruidos = ruidos\n",
    "        self.distribuicao_ruidos = theano.shared(np.array(distribuicao_ruidos).astype(theano.config.floatX)) #IMP\n",
    "        self.gerador_aleatorio = theano.tensor.shared_randomstreams.RandomStreams(seed=semente) #IMP\n",
    "        self.dimensao_entrada = dimensao_entrada\n",
    "        kwargs['input_shape'] = (self.dimensao_entrada, )\n",
    "        super(EstimativaConstrastivaRuidosa, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, dims_entrada):\n",
    "        self.W = self.add_weight(name='{}_W'.format(self.name), shape=(self.vocabulario, self.dimensao_entrada), initializer=self.init, trainable=True)\n",
    "        self.b = self.add_weight(name='{}_b'.format(self.name), shape=(self.vocabulario, )                     , initializer=self.init, trainable=True)\n",
    "        super(EstimativaConstrastivaRuidosa, self).build(dims_entrada)\n",
    "\n",
    "    def compute_output_shape(self, dims_entrada):\n",
    "        return (None, self.comprimento, self.ruidos + 1)\n",
    "    \n",
    "    def compute_mask(self, input, mask=None):\n",
    "        return mask[0]\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        contexto = inputs[0] #shape: amostras * passos * dim\n",
    "        proxima_palavra = inputs[1] #shape: amostras * passos\n",
    "\n",
    "        amostras, passos = proxima_palavra.shape\n",
    "        dim_saida = self.ruidos + 1\n",
    "\n",
    "        noise_w = self.gerador_aleatorio.choice(size=(amostras, passos, self.ruidos), a=self.distribuicao_ruidos.shape[0], p=self.distribuicao_ruidos)\n",
    "        proxima_palavra = proxima_palavra.flatten().reshape([amostras, passos, 1])\n",
    "        proxima_palavra = theano.tensor.concatenate([proxima_palavra, noise_w], axis=-1) #IMP shape: amostras * passos * dim_saida\n",
    "\n",
    "        W_ = self.W[proxima_palavra.flatten()].flatten().reshape([amostras, passos, dim_saida, self.dimensao_entrada])\n",
    "        b_ = self.b[proxima_palavra.flatten()].reshape([amostras, passos, dim_saida])\n",
    "\n",
    "        s_theta = (contexto[:, :, None, :] * W_).sum(axis=-1) + b_ # dims: amostras * passos * dim_saida\n",
    "        noiseP = self.distribuicao_ruidos[proxima_palavra.flatten()].reshape([amostras, passos, dim_saida])\n",
    "        noise_score = keras.backend.log(self.ruidos * noiseP) #log(k * distribuicao_ruidos(w))\n",
    "\n",
    "        return keras.activations.sigmoid(s_theta - noise_score) # dims: amostras, passos, dim_saida\n",
    "\n",
    "def custo_estimativa_contrastiva(real, estimado):\n",
    "    custo = K.binary_crossentropy(estimado, real[:, :, 1:])\n",
    "    custo = custo.sum(axis=-1)\n",
    "    custo *= real[:, :, 0]\n",
    "    return K.sum(custo) / K.sum(real[:, :, 0])\n",
    "\n",
    "def separar_xy_mascara(sequencias, vocabulario=5000, comprimento_maximo=100):\n",
    "    novas_sequencias = [[palavra if palavra < vocabulario else 0 for p in s] for s in sequencias]\n",
    "\n",
    "    comprimentos = [min(comprimento_maximo, len(s)-1) for s in sequencias]\n",
    "    comprimento_maximo = max(comprimentos)\n",
    "    amostras = numpy.count_nonzero(comprimentos)\n",
    "\n",
    "    x = numpy.zeros((amostras, comprimento_maximo)).astype('int32')\n",
    "    y = numpy.zeros((amostras, comprimento_maximo)).astype('int32')\n",
    "    mascara = numpy.zeros((amostras, comprimento_maximo)).astype('int32')\n",
    "\n",
    "    idx = 0\n",
    "    for i, s in enumerate(sequencias):\n",
    "        l = comprimentos[i]\n",
    "        if l < 1: continue\n",
    "        mask[idx, :l] = 1\n",
    "        x[idx, :l] = s[:l]\n",
    "        y[idx, :l] = s[1 : l+1]\n",
    "        x[idx] += mask[idx]\n",
    "        y[idx] += mask[idx]\n",
    "        idx += 1\n",
    "\n",
    "    return x, y, mascara\n",
    "\n",
    "def calcular_distancias(sequencias, indice_maximo):\n",
    "    Pn = np.zeros((maxword,))\n",
    "    for s in sequencias:\n",
    "        for w in s:\n",
    "            if w >= indice_maximo: Pn[0] += 1\n",
    "            else: Pn[w] += 1\n",
    "    Pn = 1.0 * Pn / sum(Pn)\n",
    "    return Pn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelo_pretreinamento(vocabulario, dim_vetorial, comprimento, ruidos, distribuicao_ruidos):\n",
    "    entrada_atual = Input(shape=(comprimento,), dtype='int32', name='entrada_atual')\n",
    "    proxima_entrada = Input(shape=(comprimento,), dtype='int32', name='proxima_entrada')\n",
    "    vetorizado = Embedding(output_dim=dim_vetorial, input_dim=vocabulario, input_length=comprimento, mask_zero=True)(entrada_atual)\n",
    "    contexto_recorrente = LSTM(dim_vetorial, input_shape=(None, dim_vetorial), return_sequences=True)(vetorizado)\n",
    "    estimativa = EstimativaConstrastivaRuidosa(dimensao_entrada=dim_vetorial, comprimento=comprimento, vocabulario=vocabulario,\n",
    "                ruidos=ruidos, distribuicao_ruidos=distribuicao_ruidos)([contexto_recorrente, proxima_entrada])\n",
    "    return Model(inputs=[entrada_atual, proxima_entrada], outputs=estimativa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruidos = 100\n",
    "comprimento_maximo = 100\n",
    "dim_vetorial = 200\n",
    "vocabulario_maximo = 5000\n",
    "\n",
    "x_treino, y_treino, mascara_treino = separar_xy_mascara(treino, vocabulario_maximo, comprimento_maximo)\n",
    "\n",
    "vocabulario_maximo += 1\n",
    "amostras, comprimento = x_treino.shape\n",
    "Pn = calcular_distancias(treino, vocabulario_maximo)\n",
    "masc_treino = numpy.zeros((amostras, comprimento, ruidos + 2), dtype='int64')\n",
    "masc_treino[:, :, 0] = mascara_treino\n",
    "masc_treino[:, :, 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelo_pretreino = modelo_pretreinamento(vocabulario_maximo, dim_vetorial, comprimento, ruidos, Pn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_pretreino.compile(optimizer='adam', loss=custo_estimativa_contrastiva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  320/10970 [..............................] - ETA: 6:16 - loss: 16.7152"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-fab677c9a1cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistorico_pretreino\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_treino\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_treino\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasc_treino\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/theano/scan_module/scan_op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[1;32m    959\u001b[0m         \u001b[0mallow_gc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_gc\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_gc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[0m\u001b[1;32m    962\u001b[0m                  allow_gc=allow_gc):\n\u001b[1;32m    963\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "historico_pretreino = model.fit([x_treino, y_treino], masc_treino, batch_size=64, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import theano\n",
    "from theano import config\n",
    "import theano.tensor as tensor\n",
    "import theano.tensor.shared_randomstreams as RS\n",
    "\n",
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras.callbacks import *\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "class NCEContext(Layer):\n",
    "    def __init__(self, init='glorot_uniform', activation='linear',\n",
    "                 weights=None, input_dim=None, context_dim=None,\n",
    "                 W_regularizer=None, b_regularizer=None, activity_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=False, **kwargs):\n",
    "        self.init = initializers.get(init)\n",
    "        self.activation = activations.get(activation)\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.initial_weights = weights\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.context_dim = context_dim\n",
    "        if self.input_dim:\n",
    "            kwargs['input_shape'] = (self.input_dim,)\n",
    "\n",
    "        super(NCEContext, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape): #input shape: nsamples * n_context * dim\n",
    "        self.C = self.init((self.context_dim, self.input_dim),\n",
    "                           name='{}_C'.format(self.name))\n",
    "        self.trainable_weights = [self.C]\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0], self.input_dim)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        #x shape: nsamples * n_context * dim\n",
    "        #out shape: nsamples * dim\n",
    "        out = self.C[None, :, :] * x\n",
    "        out = out.sum(axis=-2)\n",
    "        return out\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'init': self.init.__name__,\n",
    "                  'activation': self.activation.__name__,\n",
    "                  'W_regularizer': self.W_regularizer.get_config() if self.W_regularizer else None,\n",
    "                  'b_regularizer': self.b_regularizer.get_config() if self.b_regularizer else None,\n",
    "                  'activity_regularizer': self.activity_regularizer.get_config() if self.activity_regularizer else None,\n",
    "                  'W_constraint': self.W_constraint.get_config() if self.W_constraint else None,\n",
    "                  'b_constraint': self.b_constraint.get_config() if self.b_constraint else None,\n",
    "                  'bias': self.bias,\n",
    "                  'input_dim': self.input_dim,\n",
    "                  'context_dim': self.context_dim}\n",
    "        base_config = super(NCEContext, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "class NCE(Layer):\n",
    "    def __init__(self, init='glorot_uniform', activation='linear',\n",
    "                 input_dim=None, vocab_size=None, n_noise = 25, Pn=[0.5, 0.5],\n",
    "                 weights=None,\n",
    "                 W_regularizer=None, b_regularizer=None, activity_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.init = init #initializers.get(init)\n",
    "        self.activation = activations.get(activation)\n",
    "        self.input_dim = input_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.n_noise = n_noise\n",
    "        self.Pn = theano.shared(numpy.array(Pn).astype(config.floatX))\n",
    "        self.rng = RS.RandomStreams(seed=SEED)\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.initial_weights = weights\n",
    "\n",
    "        if self.input_dim:\n",
    "            kwargs['input_shape'] = (self.input_dim,)\n",
    "\n",
    "        super(NCE, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(\n",
    "            name='{}_W'.format(self.name),\n",
    "            shape=(self.vocab_size, self.input_dim),\n",
    "            initializer=self.init,\n",
    "        )\n",
    "        #self.init((self.vocab_size, self.input_dim), name='{}_W'.format(self.name))\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(\n",
    "                name='{}_b'.format(self.name),\n",
    "                shape=(self.vocab_size,),\n",
    "                initializer=self.init,\n",
    "            )\n",
    "            #self.init((self.vocab_size,), name='{}_b'.format(self.name))\n",
    "            self.trainable_weights = [self.W, self.b]\n",
    "        else:\n",
    "            self.trainable_weights = [self.W]\n",
    "\n",
    "        self.regularizers = []\n",
    "        if self.W_regularizer:\n",
    "            self.W_regularizer.set_param(self.W)\n",
    "            self.regularizers.append(self.W_regularizer)\n",
    "\n",
    "        if self.bias and self.b_regularizer:\n",
    "            self.b_regularizer.set_param(self.b)\n",
    "            self.regularizers.append(self.b_regularizer)\n",
    "\n",
    "        if self.activity_regularizer:\n",
    "            self.activity_regularizer.set_layer(self)\n",
    "            self.regularizers.append(self.activity_regularizer)\n",
    "\n",
    "        self.constraints = {}\n",
    "        if self.W_constraint:\n",
    "            self.constraints[self.W] = self.W_constraint\n",
    "\n",
    "        if self.bias and self.b_constraint:\n",
    "            self.constraints[self.b] = self.b_constraint\n",
    "\n",
    "        if self.initial_weights is not None:\n",
    "            self.set_weights(self.initial_weights)\n",
    "            del self.initial_weights\n",
    "        super(NCE, self).build(input_shape)\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (None, self.n_noise + 1)\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        context = inputs[0] #shape: n_samples * dim\n",
    "        next_w = inputs[1] #shape: n_samles * 1\n",
    "\n",
    "        n_samples = next_w.shape[0]\n",
    "        n_next = self.n_noise + 1\n",
    "\n",
    "        #generate n_noise samples from noise distribution Pn.\n",
    "        noise_w = self.rng.choice(size=(n_samples, self.n_noise), a=self.Pn.shape[0], p=self.Pn)\n",
    "        next_w = tensor.concatenate([next_w, noise_w], axis=-1)\n",
    "\n",
    "        W_ = self.W[next_w.flatten()].flatten().reshape([n_samples, n_next, self.input_dim])\n",
    "        b_ = self.b[next_w.flatten()].reshape([n_samples, n_next])\n",
    "\n",
    "        # compute s_theta(w): scores of words under the model\n",
    "        s_theta = (context[:, None, :] * W_).sum(axis=-1) + b_\n",
    "        # compute the scores of words under the noise distribution: log(k * Pn(w))\n",
    "        noiseP = self.Pn[next_w.flatten()].reshape([n_samples, n_next])\n",
    "        noise_score = K.log(self.n_noise * noiseP)\n",
    "\n",
    "        # the difference in the scores of words under the model and the noise distribution\n",
    "        # shape: n_samples * n_next\n",
    "        out = s_theta - noise_score\n",
    "\n",
    "        return activations.sigmoid(out)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'init': self.init,\n",
    "                  'activation': self.activation.__name__,\n",
    "                  'W_regularizer': self.W_regularizer.get_config() if self.W_regularizer else None,\n",
    "                  'b_regularizer': self.b_regularizer.get_config() if self.b_regularizer else None,\n",
    "                  'activity_regularizer': self.activity_regularizer.get_config() if self.activity_regularizer else None,\n",
    "                  'W_constraint': self.W_constraint.get_config() if self.W_constraint else None,\n",
    "                  'b_constraint': self.b_constraint.get_config() if self.b_constraint else None,\n",
    "                  'bias': self.bias,\n",
    "                  'input_dim': self.input_dim,\n",
    "                  'vocab_size': self.vocab_size,\n",
    "                  'n_noise': self.n_noise\n",
    "                  }\n",
    "        base_config = super(NCE, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "class NCE_seq(NCE):\n",
    "    def __init__(self, input_len=10, **kwargs):\n",
    "        self.input_len = input_len\n",
    "        super(NCE_seq, self).__init__(**kwargs)\n",
    "\n",
    "    def compute_mask(self, input, mask=None):\n",
    "        return mask[0]\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (None, self.input_len, self.n_noise + 1)\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        context = inputs[0] #shape: n_samples * n_steps * dim\n",
    "        next_w = inputs[1] #shape: n_samles * n_steps\n",
    "\n",
    "        n_samples, n_steps = next_w.shape\n",
    "        n_next = self.n_noise + 1\n",
    "\n",
    "        #generate n_noise samples from noise distribution Pn.\n",
    "        noise_w = self.rng.choice(size=(n_samples, n_steps, self.n_noise), a=self.Pn.shape[0], p=self.Pn)\n",
    "        next_w = next_w.flatten().reshape([n_samples, n_steps, 1])\n",
    "        next_w = tensor.concatenate([next_w, noise_w], axis=-1) # shape: n_samples * n_steps * n_next\n",
    "\n",
    "        W_ = self.W[next_w.flatten()].flatten().reshape([n_samples, n_steps, n_next, self.input_dim])\n",
    "        b_ = self.b[next_w.flatten()].reshape([n_samples, n_steps, n_next])\n",
    "\n",
    "        # compute s_theta(w): scores of words under the model\n",
    "        # s_theta shape: n_samples * n_steps * n_next\n",
    "        s_theta = (context[:, :, None, :] * W_).sum(axis=-1) + b_\n",
    "        # compute the scores of words under the noise distribution: log(k * Pn(w))\n",
    "        noiseP = self.Pn[next_w.flatten()].reshape([n_samples, n_steps, n_next])\n",
    "        noise_score = K.log(self.n_noise * noiseP)\n",
    "\n",
    "        # the difference in the scores of words under the model and the noise distribution\n",
    "        # output shape: n_samples, n_steps, n_next\n",
    "        out = s_theta - noise_score\n",
    "\n",
    "        return activations.sigmoid(out)\n",
    "\n",
    "class NCETest(NCE):\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (None, 1)\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        context = inputs[0] # shape: n_samples * dim\n",
    "        next_w = inputs[1] # shape: n_samples * 1\n",
    "        n_samples = next_w.shape[0]\n",
    "\n",
    "        out = K.dot(context, K.transpose(self.W)) + self.b\n",
    "        out = activations.softmax(out)\n",
    "        next_w = next_w.flatten()\n",
    "        return out[tensor.arange(n_samples), next_w]\n",
    "\n",
    "class NCETest_seq(NCETest):\n",
    "    def __init__(self, input_len=10, **kwargs):\n",
    "        self.input_len = input_len\n",
    "        super(NCETest_seq, self).__init__(**kwargs)\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (None, self.input_len)\n",
    "\n",
    "    def compute_mask(self, input, mask=None):\n",
    "        return mask[0]\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        context = inputs[0] # shape: n_samples * n_steps * dim\n",
    "        next_w = inputs[1] # shape: n_samples * n_steps\n",
    "        n_samples, n_steps = next_w.shape\n",
    "        vocab_size = self.W.shape[0]\n",
    "\n",
    "        out = K.dot(context, K.transpose(self.W)) + self.b\n",
    "        out = activations.softmax(out)\n",
    "        out = out.flatten().reshape([n_samples*n_steps, vocab_size])\n",
    "        next_w = next_w.flatten()\n",
    "\n",
    "        prob = out[tensor.arange(n_samples*n_steps), next_w]\n",
    "        prob = prob.reshape([n_samples, n_steps])\n",
    "        return prob\n",
    "\n",
    "class NCETestCallback(Callback):\n",
    "    def __init__(self, data, testModel, fResult, fParams, patient=3):\n",
    "        self.testModel = testModel\n",
    "        self.fResult = fResult\n",
    "        self.fParams = fParams\n",
    "        self.patient = patient\n",
    "        self.num_patient = patient\n",
    "        self.best_epoch = 0\n",
    "        self.best_loss = 100000.0\n",
    "\n",
    "        self.do_test = False\n",
    "        if len(data) == 2 or len(data) == 4:\n",
    "            self.isSeq = 0\n",
    "            self.valid_x = data[0]\n",
    "            self.valid_y = data[1]\n",
    "            self.valid_mask = data[0]\n",
    "\n",
    "            if len(data) == 4:\n",
    "                self.do_test = True\n",
    "                self.test_x = data[2]\n",
    "                self.test_y = data[3]\n",
    "                self.test_mask = data[2]\n",
    "\n",
    "        else:\n",
    "            self.isSeq = 1\n",
    "            self.valid_x, self.valid_y, self.valid_mask = data[0], data[1], data[2]\n",
    "            if len(data) == 6:\n",
    "                self.do_test = True\n",
    "                self.test_x, self.test_y, self.test_mask = data[3], data[4], data[5]\n",
    "\n",
    "        flog = open(fResult, 'w')\n",
    "        flog.write('epoch\\ttr_loss\\tv_ppl\\n')\n",
    "        flog.close()\n",
    "        super(NCETestCallback, self).__init__()\n",
    "\n",
    "    def _compute_result(self, x, y, mask):\n",
    "        y_pred = self.testModel.predict([x, y], batch_size=30)\n",
    "        if self.isSeq:\n",
    "            per = perplexity(mask, y_pred, 1)\n",
    "        else:\n",
    "            per = perplexity(mask, y_pred, 0)\n",
    "        return per\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        weights = self.model.get_weights()\n",
    "        self.testModel.set_weights(weights)\n",
    "\n",
    "        v_per = self._compute_result(self.valid_x, self.valid_y, self.valid_mask)\n",
    "        if self.do_test:\n",
    "            t_per = self._compute_result(self.test_x, self.test_y, self.test_mask)\n",
    "\n",
    "        if self.best_loss < v_per:\n",
    "            self.patient -= 1\n",
    "\n",
    "            if self.patient == 0:\n",
    "                lr = self.model.optimizer.lr / 2.0\n",
    "                self.model.optimizer.lr = lr\n",
    "                self.patient = self.num_patient\n",
    "        else:\n",
    "            self.patient = self.num_patient\n",
    "            self.best_loss = v_per\n",
    "            self.best_epoch = epoch\n",
    "            self.model.save_weights(self.fParams, overwrite=True)\n",
    "\n",
    "        print ('validation perplexity: %.4f' % v_per)\n",
    "\n",
    "        train_loss = 0\n",
    "        if 'loss' in logs:\n",
    "            train_loss = logs['loss']\n",
    "\n",
    "        f = open(self.fResult, 'a')\n",
    "        f.write('%d\\t%.4f\\t%.4f' % (epoch, train_loss, v_per))\n",
    "        if self.do_test:\n",
    "            f.write('\\t%.4f' % t_per)\n",
    "        f.write('\\tBest at epoch %d' % self.best_epoch)\n",
    "        f.write('\\n')\n",
    "        f.close()\n",
    "\n",
    "def NCE_seq_loss(y_true, y_pred):\n",
    "    # y_true[:, :, 0]: masking matrix\n",
    "    # y_true[:, :, 1] = 1: words from data\n",
    "    # y_true[:, :, 2:] = 0: words from noise distribution\n",
    "    # y_pred: probability of the word to be from data - shape: n_samples * n_steps * (n_noise + 1)\n",
    "\n",
    "    loss = K.binary_crossentropy(y_pred, y_true[:, :, 1:])\n",
    "    loss = loss.sum(axis=-1)\n",
    "    loss *= y_true[:, :, 0] # masking matrix\n",
    "    return K.sum(loss) / K.sum(y_true[:, :, 0])\n",
    "\n",
    "def NCE_seq_loss_test(y_true, y_pred):\n",
    "    # y_pred: n_samples * n_steps - probability of next word to be the corresponding word in y_true\n",
    "    # y_true: masking matrix\n",
    "\n",
    "    loss = -tensor.log(y_pred)\n",
    "    loss *= y_true\n",
    "    loss = K.sum(loss) / K.sum(y_true)\n",
    "    return K.exp(loss)\n",
    "\n",
    "def NCE_loss(y_true, y_pred): #n_samples * n_next\n",
    "    loss = K.binary_crossentropy(y_pred, y_true)\n",
    "    loss = K.mean(loss.sum(axis=-1))\n",
    "    return loss\n",
    "\n",
    "def NCE_loss_test(y_true, y_pred): #(n_samples,)\n",
    "    loss = - tensor.log(y_pred)\n",
    "    loss = K.mean(loss)\n",
    "    loss = K.exp(loss)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def perplexity(y_true, y_pred, isSeq = 0): #(n_samples,) or (n_samples, n_steps)\n",
    "    eps = 1e-4\n",
    "    loss = - numpy.log(y_pred + eps)\n",
    "\n",
    "    if isSeq: # sequence\n",
    "        loss *= y_true\n",
    "        loss = numpy.sum(loss) / numpy.sum(y_true)\n",
    "    else:\n",
    "        loss = numpy.mean(loss)\n",
    "\n",
    "    loss = numpy.exp(loss)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def calc_dist(seqs, maxword):\n",
    "    Pn = numpy.zeros((maxword,))\n",
    "\n",
    "    for s in seqs:\n",
    "        for w in s:\n",
    "            if w >= maxword: Pn[0] += 1\n",
    "            else: Pn[w] += 1\n",
    "\n",
    "    Pn = 1.0 * Pn / sum(Pn)\n",
    "\n",
    "    return Pn\n",
    "\n",
    "def generate_noise(n_samples, n_noise, Pn):\n",
    "    noise = numpy.zeros((n_samples, n_noise), dtype='int64')\n",
    "    for i in range(n_samples):\n",
    "        noise[i] = numpy.random.choice(len(Pn), n_noise, p=Pn)\n",
    "\n",
    "    return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "\n",
    "def load(path):\n",
    "    f = gzip.open(path, 'rb')\n",
    "    train, valid, test = pickle.load(f)\n",
    "    #print path, len(train[0]), len(valid[0])\n",
    "\n",
    "    return train, valid, test\n",
    "\n",
    "def prepare_lm(seqs, vocab_size=10000, max_len=100):\n",
    "    new_seqs = []\n",
    "    for i, s in enumerate(seqs):\n",
    "        new_s = [w if w < vocab_size else 0 for w in s]\n",
    "        new_seqs.append(new_s)\n",
    "    seqs = new_seqs\n",
    "\n",
    "    lengths = [min(max_len, len(s)-1) for s in seqs]\n",
    "    maxlen = max(lengths)\n",
    "    n_samples = numpy.count_nonzero(lengths)\n",
    "\n",
    "    x = numpy.zeros((n_samples, maxlen)).astype('int64')\n",
    "    y = numpy.zeros((n_samples, maxlen)).astype('int64')\n",
    "    mask = numpy.zeros((n_samples, maxlen)).astype('int64')\n",
    "\n",
    "    idx = 0\n",
    "    for i, s in enumerate(seqs):\n",
    "        l = lengths[i]\n",
    "        if l < 1: continue\n",
    "        mask[idx, :l] = 1\n",
    "        x[idx, :l] = s[:l]\n",
    "        y[idx, :l] = s[1 : l+1]\n",
    "        x[idx] += mask[idx]\n",
    "        y[idx] += mask[idx]\n",
    "        idx += 1\n",
    "\n",
    "    return x, y, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "vocab:  5000\n",
      "Data size: Train: 67794, valid: 4869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/theano/gpuarray/dnn.py:184: UserWarning: Your cuDNN version is more recent than Theano. If you encounter problems, try updating Theano or downgrading cuDNN to a version >= v5 and <= v7.\n",
      "  warnings.warn(\"Your cuDNN version is more recent than \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_inp (InputLayer)           (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 100, 200)     1000200     main_inp[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 100, 200)     320800      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "next_inp (InputLayer)           (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "nce_seq_1 (NCE_seq)             [(None, 100, 200), ( 1005201     lstm_1[0][0]                     \n",
      "                                                                 next_inp[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,326,201\n",
      "Trainable params: 2,326,201\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      " 2350/67794 [>.............................] - ETA: 49:17 - loss: 66.8555"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-fa981655e786>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m his = model.fit([train_x, train_y], labels,\n\u001b[0;32m---> 44\u001b[0;31m           batch_size=50, epochs=20)\n\u001b[0m",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.constraints import *\n",
    "from keras.regularizers import *\n",
    "import numpy\n",
    "\n",
    "dataset = 'dados/pretreino/moodle_pretrain.pkl.gz'\n",
    "emb_dim = 200\n",
    "max_len = 100\n",
    "\n",
    "n_noise = 100\n",
    "print ('Loading data...')\n",
    "train, valid, test = load(dataset)\n",
    "valid = valid[-5000:]\n",
    "vocab_size = 5000\n",
    "\n",
    "print ('vocab: ', vocab_size)\n",
    "\n",
    "train_x, train_y, train_mask = prepare_lm(train, vocab_size, max_len)\n",
    "valid_x, valid_y, valid_mask = prepare_lm(valid, vocab_size, max_len)\n",
    "\n",
    "print ('Data size: Train: %d, valid: %d' % (len(train_x), len(valid_x)))\n",
    "\n",
    "vocab_size += 1\n",
    "n_samples, inp_len = train_x.shape\n",
    "Pn = calc_dist(train, vocab_size)\n",
    "labels = numpy.zeros((n_samples, inp_len, n_noise + 2), dtype='int64')\n",
    "labels[:, :, 0] = train_mask\n",
    "labels[:, :, 1] = 1\n",
    "\n",
    "main_inp = Input(shape=(inp_len,), dtype='int64', name='main_inp')\n",
    "next_inp = Input(shape=(inp_len,), dtype='int64', name='next_inp')\n",
    "emb_vec = Embedding(output_dim=emb_dim, input_dim=vocab_size, input_length=inp_len,\n",
    "                    #dropout=0.2,\n",
    "                    mask_zero=True)(main_inp)\n",
    "GRU_context = LSTM(emb_dim, input_shape=(None, emb_dim), return_sequences=True)(emb_vec)\n",
    "nce_out = NCE_seq(input_dim=emb_dim, input_len=inp_len, vocab_size=vocab_size, n_noise=n_noise, Pn=Pn,\n",
    "              )([GRU_context, next_inp])\n",
    "model = Model(inputs=[main_inp, next_inp], outputs=[nce_out])\n",
    "optimizer = RMSprop(lr=0.02, rho=0.99, epsilon=1e-7) #optimizer = RMSprop(lr=0.01)\n",
    "model.compile(optimizer=optimizer, loss=NCE_seq_loss)\n",
    "print(model.summary())\n",
    "his = model.fit([train_x, train_y], labels,\n",
    "          batch_size=50, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5001,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelo_treinamento(n_classes, vocab_size, inp_len, emb_dim,\n",
    "                 seq_model='lstm', nnet_model='highway', pool_mode='mean',\n",
    "                 dropout_inp=False, dropout_hid=True, emb_weight=None, hidden_layer=None):\n",
    "    if emb_weight is not None:\n",
    "        emb_weight = [emb_weight[:vocab_size]]\n",
    "    seq_dict = {'lstm': LSTM, 'gru': GRU, 'rnn': SimpleRNN}\n",
    "    nnet_dict = {'highway': create_highway, 'dense': create_dense}\n",
    "    if n_classes == -1:\n",
    "        top_act = 'linear'\n",
    "    elif n_classes == 1:\n",
    "        top_act = 'sigmoid'\n",
    "    else:\n",
    "        top_act = 'softmax'\n",
    "\n",
    "    title_inp = Input(shape=(inp_len,), dtype='int64', name='title_inp')\n",
    "    descr_inp = Input(shape=(inp_len,), dtype='int64', name='descr_inp')\n",
    "\n",
    "    title_mask = Input(shape=(inp_len,), dtype='float32', name='title_mask')\n",
    "    descr_mask = Input(shape=(inp_len,), dtype='float32', name='descr_mask')\n",
    "\n",
    "    if dropout_inp:\n",
    "        drop_rate = 0.2\n",
    "    else:\n",
    "        drop_rate = 0.0\n",
    "\n",
    "    embedding = Embedding(output_dim=emb_dim, input_dim=vocab_size, input_length=inp_len,\n",
    "                          mask_zero=True, weights=emb_weight,\n",
    "                          dropout=drop_rate)\n",
    "    seq_layer = seq_dict[seq_model](input_dim=emb_dim, output_dim=emb_dim,\n",
    "                                    return_sequences=True, dropout_U=drop_rate, dropout_W=drop_rate)\n",
    "\n",
    "    title_emb = embedding(title_inp)\n",
    "    descr_emb = embedding(descr_inp)\n",
    "\n",
    "    title_hid = seq_layer(title_emb)\n",
    "    descr_hid = seq_layer(descr_emb)\n",
    "\n",
    "    pooled_title = PoolingSeq(mode=pool_mode)([title_hid, title_mask])\n",
    "    pooled_descr = PoolingSeq(mode=pool_mode)([descr_hid, descr_mask])\n",
    "\n",
    "    hidd = Average()([pooled_title, pooled_descr])\n",
    "    if dropout_hid:\n",
    "        hidd = Dropout(0.5)(hidd)\n",
    "\n",
    "    hidd = nnet_dict[nnet_model](hidd, emb_dim, hidden_layer)\n",
    "    hidd = Dropout(0.5)(hidd)\n",
    "    top_hidd = Dense(output_dim=abs(n_classes), activation=top_act)(hidd)\n",
    "\n",
    "    model = Model(input=[title_inp, title_mask, descr_inp, descr_mask], output=top_hidd)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Average train sequence length: 238\n",
      "Average test sequence length: 230\n",
      "Adding 2-gram features\n",
      "Average train sequence length: 476\n",
      "Average test sequence length: 428\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 400)\n",
      "x_test shape: (25000, 400)\n",
      "Build model...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 45s 2ms/step - loss: 0.5862 - acc: 0.7874 - val_loss: 0.4372 - val_acc: 0.8548\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 34s 1ms/step - loss: 0.2877 - acc: 0.9276 - val_loss: 0.3030 - val_acc: 0.8904\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 34s 1ms/step - loss: 0.1432 - acc: 0.9696 - val_loss: 0.2628 - val_acc: 0.8998\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 34s 1ms/step - loss: 0.0775 - acc: 0.9871 - val_loss: 0.2441 - val_acc: 0.9030\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 34s 1ms/step - loss: 0.0437 - acc: 0.9950 - val_loss: 0.2376 - val_acc: 0.9040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa688dd99e8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#This example demonstrates the use of fasttext for text classification\n",
    "Based on Joulin et al's paper:\n",
    "[Bags of Tricks for Efficient Text Classification\n",
    "](https://arxiv.org/abs/1607.01759)\n",
    "Results on IMDB datasets with uni and bi-gram embeddings:\n",
    "Embedding|Accuracy, 5 epochs|Speed (s/epoch)|Hardware\n",
    ":--------|-----------------:|----:|:-------\n",
    "Uni-gram |            0.8813|    8|i7 CPU\n",
    "Bi-gram  |            0.9056|    2|GTx 980M GPU\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "from keras.datasets import imdb\n",
    "\n",
    "\n",
    "def create_ngram_set(input_list, ngram_value=2):\n",
    "    \"\"\"\n",
    "    Extract a set of n-grams from a list of integers.\n",
    "    >>> create_ngram_set([1, 4, 9, 4, 1, 4], ngram_value=2)\n",
    "    {(4, 9), (4, 1), (1, 4), (9, 4)}\n",
    "    >>> create_ngram_set([1, 4, 9, 4, 1, 4], ngram_value=3)\n",
    "    [(1, 4, 9), (4, 9, 4), (9, 4, 1), (4, 1, 4)]\n",
    "    \"\"\"\n",
    "    return set(zip(*[input_list[i:] for i in range(ngram_value)]))\n",
    "\n",
    "\n",
    "def add_ngram(sequences, token_indice, ngram_range=2):\n",
    "    \"\"\"\n",
    "    Augment the input list of list (sequences) by appending n-grams values.\n",
    "    Example: adding bi-gram\n",
    "    >>> sequences = [[1, 3, 4, 5], [1, 3, 7, 9, 2]]\n",
    "    >>> token_indice = {(1, 3): 1337, (9, 2): 42, (4, 5): 2017}\n",
    "    >>> add_ngram(sequences, token_indice, ngram_range=2)\n",
    "    [[1, 3, 4, 5, 1337, 2017], [1, 3, 7, 9, 2, 1337, 42]]\n",
    "    Example: adding tri-gram\n",
    "    >>> sequences = [[1, 3, 4, 5], [1, 3, 7, 9, 2]]\n",
    "    >>> token_indice = {(1, 3): 1337, (9, 2): 42, (4, 5): 2017, (7, 9, 2): 2018}\n",
    "    >>> add_ngram(sequences, token_indice, ngram_range=3)\n",
    "    [[1, 3, 4, 5, 1337, 2017], [1, 3, 7, 9, 2, 1337, 42, 2018]]\n",
    "    \"\"\"\n",
    "    new_sequences = []\n",
    "    for input_list in sequences:\n",
    "        new_list = input_list[:]\n",
    "        for ngram_value in range(2, ngram_range + 1):\n",
    "            for i in range(len(new_list) - ngram_value + 1):\n",
    "                ngram = tuple(new_list[i:i + ngram_value])\n",
    "                if ngram in token_indice:\n",
    "                    new_list.append(token_indice[ngram])\n",
    "        new_sequences.append(new_list)\n",
    "\n",
    "    return new_sequences\n",
    "\n",
    "# Set parameters:\n",
    "# ngram_range = 2 will add bi-grams features\n",
    "ngram_range = 2\n",
    "max_features = 20000\n",
    "maxlen = 400\n",
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "epochs = 5\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "print('Average train sequence length: {}'.format(\n",
    "    np.mean(list(map(len, x_train)), dtype=int)))\n",
    "print('Average test sequence length: {}'.format(\n",
    "    np.mean(list(map(len, x_test)), dtype=int)))\n",
    "\n",
    "if ngram_range > 1:\n",
    "    print('Adding {}-gram features'.format(ngram_range))\n",
    "    # Create set of unique n-gram from the training set.\n",
    "    ngram_set = set()\n",
    "    for input_list in x_train:\n",
    "        for i in range(2, ngram_range + 1):\n",
    "            set_of_ngram = create_ngram_set(input_list, ngram_value=i)\n",
    "            ngram_set.update(set_of_ngram)\n",
    "\n",
    "    # Dictionary mapping n-gram token to a unique integer.\n",
    "    # Integer values are greater than max_features in order\n",
    "    # to avoid collision with existing features.\n",
    "    start_index = max_features + 1\n",
    "    token_indice = {v: k + start_index for k, v in enumerate(ngram_set)}\n",
    "    indice_token = {token_indice[k]: k for k in token_indice}\n",
    "\n",
    "    # max_features is the highest integer that could be found in the dataset.\n",
    "    max_features = np.max(list(indice_token.keys())) + 1\n",
    "\n",
    "    # Augmenting x_train and x_test with n-grams features\n",
    "    x_train = add_ngram(x_train, token_indice, ngram_range)\n",
    "    x_test = add_ngram(x_test, token_indice, ngram_range)\n",
    "    print('Average train sequence length: {}'.format(\n",
    "        np.mean(list(map(len, x_train)), dtype=int)))\n",
    "    print('Average test sequence length: {}'.format(\n",
    "        np.mean(list(map(len, x_test)), dtype=int)))\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "# we start off with an efficient embedding layer which maps\n",
    "# our vocab indices into embedding_dims dimensions\n",
    "model.add(Embedding(max_features,\n",
    "                    embedding_dims,\n",
    "                    input_length=maxlen))\n",
    "\n",
    "# we add a GlobalAveragePooling1D, which will average the embeddings\n",
    "# of all words in the document\n",
    "model.add(GlobalAveragePooling1D())\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'numpy' from '/usr/lib64/python3.6/site-packages/numpy/__init__.py'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb.np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n",
      "Found 400000 word vectors.\n",
      "Processing text dataset\n",
      "Found 19997 texts.\n",
      "Found 174074 unique tokens.\n",
      "Shape of data tensor: (19997, 1000)\n",
      "Shape of label tensor: (19997, 20)\n",
      "Preparing embedding matrix.\n",
      "Training model.\n",
      "Train on 15998 samples, validate on 3999 samples\n",
      "Epoch 1/10\n",
      "15998/15998 [==============================] - 5s 340us/step - loss: 2.4037 - acc: 0.2187 - val_loss: 1.8067 - val_acc: 0.3768\n",
      "Epoch 2/10\n",
      "15998/15998 [==============================] - 4s 276us/step - loss: 1.5519 - acc: 0.4621 - val_loss: 1.4603 - val_acc: 0.5064\n",
      "Epoch 3/10\n",
      "15998/15998 [==============================] - 4s 276us/step - loss: 1.1902 - acc: 0.5953 - val_loss: 1.1682 - val_acc: 0.5969\n",
      "Epoch 4/10\n",
      "15998/15998 [==============================] - 4s 276us/step - loss: 0.9690 - acc: 0.6748 - val_loss: 1.0070 - val_acc: 0.6624\n",
      "Epoch 5/10\n",
      "15998/15998 [==============================] - 4s 276us/step - loss: 0.8137 - acc: 0.7250 - val_loss: 0.9541 - val_acc: 0.6784\n",
      "Epoch 6/10\n",
      "15998/15998 [==============================] - 4s 276us/step - loss: 0.6990 - acc: 0.7604 - val_loss: 1.0010 - val_acc: 0.6557\n",
      "Epoch 7/10\n",
      "15998/15998 [==============================] - 4s 276us/step - loss: 0.5930 - acc: 0.7985 - val_loss: 0.9482 - val_acc: 0.6899\n",
      "Epoch 8/10\n",
      "15998/15998 [==============================] - 4s 276us/step - loss: 0.5045 - acc: 0.8270 - val_loss: 0.8498 - val_acc: 0.7367\n",
      "Epoch 9/10\n",
      "15998/15998 [==============================] - 4s 276us/step - loss: 0.4280 - acc: 0.8572 - val_loss: 0.8620 - val_acc: 0.7339\n",
      "Epoch 10/10\n",
      "15998/15998 [==============================] - 4s 276us/step - loss: 0.3622 - acc: 0.8782 - val_loss: 0.9350 - val_acc: 0.7302\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7699e01080>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''This script loads pre-trained word embeddings (GloVe embeddings)\n",
    "into a frozen Keras Embedding layer, and uses it to\n",
    "train a text classification model on the 20 Newsgroup dataset\n",
    "(classification of newsgroup messages into 20 different categories).\n",
    "GloVe embedding data can be found at:\n",
    "http://nlp.stanford.edu/data/glove.6B.zip\n",
    "(source page: http://nlp.stanford.edu/projects/glove/)\n",
    "20 Newsgroup data can be found at:\n",
    "http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.html\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "from keras.initializers import Constant\n",
    "\n",
    "\n",
    "BASE_DIR = ''\n",
    "GLOVE_DIR = os.path.join(BASE_DIR, 'glove_en')\n",
    "TEXT_DATA_DIR = os.path.join(BASE_DIR, '20_newsgroup')\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "MAX_NUM_WORDS = 20000\n",
    "EMBEDDING_DIM = 100\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "# first, build index mapping words in the embeddings set\n",
    "# to their embedding vector\n",
    "\n",
    "print('Indexing word vectors.')\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt')) as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "# second, prepare text samples and their labels\n",
    "print('Processing text dataset')\n",
    "\n",
    "texts = []  # list of text samples\n",
    "labels_index = {}  # dictionary mapping label name to numeric id\n",
    "labels = []  # list of label ids\n",
    "for name in sorted(os.listdir(TEXT_DATA_DIR)):\n",
    "    path = os.path.join(TEXT_DATA_DIR, name)\n",
    "    if os.path.isdir(path):\n",
    "        label_id = len(labels_index)\n",
    "        labels_index[name] = label_id\n",
    "        for fname in sorted(os.listdir(path)):\n",
    "            if fname.isdigit():\n",
    "                fpath = os.path.join(path, fname)\n",
    "                args = {} if sys.version_info < (3,) else {'encoding': 'latin-1'}\n",
    "                with open(fpath, **args) as f:\n",
    "                    t = f.read()\n",
    "                    i = t.find('\\n\\n')  # skip header\n",
    "                    if 0 < i:\n",
    "                        t = t[i:]\n",
    "                    texts.append(t)\n",
    "                labels.append(label_id)\n",
    "\n",
    "print('Found %s texts.' % len(texts))\n",
    "\n",
    "# finally, vectorize the text samples into a 2D integer tensor\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "labels = to_categorical(np.asarray(labels))\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "# split the data into a training set and a validation set\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "num_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "\n",
    "x_train = data[:-num_validation_samples]\n",
    "y_train = labels[:-num_validation_samples]\n",
    "x_val = data[-num_validation_samples:]\n",
    "y_val = labels[-num_validation_samples:]\n",
    "\n",
    "print('Preparing embedding matrix.')\n",
    "\n",
    "# prepare embedding matrix\n",
    "num_words = min(MAX_NUM_WORDS, len(word_index)) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i > MAX_NUM_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "# load pre-trained word embeddings into an Embedding layer\n",
    "# note that we set trainable = False so as to keep the embeddings fixed\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            embeddings_initializer=Constant(embedding_matrix),\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)\n",
    "\n",
    "print('Training model.')\n",
    "\n",
    "# train a 1D convnet with global maxpooling\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "preds = Dense(len(labels_index), activation='softmax')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "8982 train sequences\n",
      "2246 test sequences\n",
      "46 classes\n",
      "Vectorizing sequence data...\n",
      "x_train shape: (8982, 1000)\n",
      "x_test shape: (2246, 1000)\n",
      "Convert class vector to binary class matrix (for use with categorical_crossentropy)\n",
      "y_train shape: (8982, 46)\n",
      "y_test shape: (2246, 46)\n",
      "Building model...\n",
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 1.5670 - acc: 0.6538 - val_loss: 1.1814 - val_acc: 0.7442\n",
      "Epoch 2/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.8898 - acc: 0.7982 - val_loss: 0.9999 - val_acc: 0.7798\n",
      "Epoch 3/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.6416 - acc: 0.8458 - val_loss: 0.8985 - val_acc: 0.7875\n",
      "Epoch 4/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.4929 - acc: 0.8820 - val_loss: 0.8817 - val_acc: 0.8031\n",
      "Epoch 5/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.3945 - acc: 0.9042 - val_loss: 0.8789 - val_acc: 0.7976\n",
      "Epoch 6/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.3191 - acc: 0.9209 - val_loss: 0.8845 - val_acc: 0.8131\n",
      "Epoch 7/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.2819 - acc: 0.9289 - val_loss: 0.8867 - val_acc: 0.8120\n",
      "Epoch 8/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.2442 - acc: 0.9398 - val_loss: 0.9005 - val_acc: 0.8076\n",
      "Epoch 9/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.2170 - acc: 0.9433 - val_loss: 0.9392 - val_acc: 0.7976\n",
      "Epoch 10/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1934 - acc: 0.9482 - val_loss: 0.9641 - val_acc: 0.7898\n",
      "Epoch 11/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1861 - acc: 0.9469 - val_loss: 0.9742 - val_acc: 0.7998\n",
      "Epoch 12/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1678 - acc: 0.9529 - val_loss: 1.0137 - val_acc: 0.7931\n",
      "Epoch 13/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1673 - acc: 0.9526 - val_loss: 1.0068 - val_acc: 0.7831\n",
      "Epoch 14/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1584 - acc: 0.9551 - val_loss: 1.0321 - val_acc: 0.7909\n",
      "Epoch 15/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1542 - acc: 0.9547 - val_loss: 1.0219 - val_acc: 0.7909\n",
      "Epoch 16/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1503 - acc: 0.9545 - val_loss: 1.0426 - val_acc: 0.7853\n",
      "Epoch 17/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1451 - acc: 0.9568 - val_loss: 1.0406 - val_acc: 0.7831\n",
      "Epoch 18/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1369 - acc: 0.9588 - val_loss: 1.0810 - val_acc: 0.7887\n",
      "Epoch 19/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1308 - acc: 0.9620 - val_loss: 1.1056 - val_acc: 0.7853\n",
      "Epoch 20/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1256 - acc: 0.9594 - val_loss: 1.0935 - val_acc: 0.7820\n",
      "Epoch 21/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1311 - acc: 0.9592 - val_loss: 1.1259 - val_acc: 0.7875\n",
      "Epoch 22/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1273 - acc: 0.9602 - val_loss: 1.1245 - val_acc: 0.7931\n",
      "Epoch 23/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1320 - acc: 0.9604 - val_loss: 1.1163 - val_acc: 0.7920\n",
      "Epoch 24/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1326 - acc: 0.9577 - val_loss: 1.0951 - val_acc: 0.7998\n",
      "Epoch 25/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1266 - acc: 0.9587 - val_loss: 1.1417 - val_acc: 0.7853\n",
      "Epoch 26/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1225 - acc: 0.9592 - val_loss: 1.1342 - val_acc: 0.7942\n",
      "Epoch 27/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1226 - acc: 0.9604 - val_loss: 1.1586 - val_acc: 0.7887\n",
      "Epoch 28/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1187 - acc: 0.9616 - val_loss: 1.1299 - val_acc: 0.7987\n",
      "Epoch 29/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1217 - acc: 0.9604 - val_loss: 1.1817 - val_acc: 0.7875\n",
      "Epoch 30/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1275 - acc: 0.9587 - val_loss: 1.1431 - val_acc: 0.7998\n",
      "Epoch 31/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1167 - acc: 0.9620 - val_loss: 1.1619 - val_acc: 0.7976\n",
      "Epoch 32/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1115 - acc: 0.9626 - val_loss: 1.1774 - val_acc: 0.7909\n",
      "Epoch 33/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1256 - acc: 0.9584 - val_loss: 1.1786 - val_acc: 0.7898\n",
      "Epoch 34/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1200 - acc: 0.9609 - val_loss: 1.1845 - val_acc: 0.7887\n",
      "Epoch 35/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1198 - acc: 0.9619 - val_loss: 1.2025 - val_acc: 0.7998\n",
      "Epoch 36/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1187 - acc: 0.9621 - val_loss: 1.2237 - val_acc: 0.7731\n",
      "Epoch 37/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1199 - acc: 0.9607 - val_loss: 1.2167 - val_acc: 0.7909\n",
      "Epoch 38/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1150 - acc: 0.9620 - val_loss: 1.1866 - val_acc: 0.7998\n",
      "Epoch 39/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1161 - acc: 0.9607 - val_loss: 1.2133 - val_acc: 0.7898\n",
      "Epoch 40/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1220 - acc: 0.9595 - val_loss: 1.2217 - val_acc: 0.7853\n",
      "Epoch 41/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1141 - acc: 0.9631 - val_loss: 1.2411 - val_acc: 0.7887\n",
      "Epoch 42/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1113 - acc: 0.9610 - val_loss: 1.2606 - val_acc: 0.7853\n",
      "Epoch 43/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1102 - acc: 0.9628 - val_loss: 1.2209 - val_acc: 0.7875\n",
      "Epoch 44/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1075 - acc: 0.9629 - val_loss: 1.2654 - val_acc: 0.7853\n",
      "Epoch 45/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1139 - acc: 0.9614 - val_loss: 1.2527 - val_acc: 0.7875\n",
      "Epoch 46/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1122 - acc: 0.9608 - val_loss: 1.2485 - val_acc: 0.7820\n",
      "Epoch 47/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1092 - acc: 0.9630 - val_loss: 1.2679 - val_acc: 0.7864\n",
      "Epoch 48/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1096 - acc: 0.9623 - val_loss: 1.2907 - val_acc: 0.7887\n",
      "Epoch 49/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1086 - acc: 0.9624 - val_loss: 1.2607 - val_acc: 0.7775\n",
      "Epoch 50/50\n",
      "8083/8083 [==============================] - 0s 24us/step - loss: 0.1048 - acc: 0.9634 - val_loss: 1.2892 - val_acc: 0.7831\n",
      "2246/2246 [==============================] - 0s 12us/step\n",
      "Test score: 1.2998778688408705\n",
      "Test accuracy: 0.7831700801424755\n"
     ]
    }
   ],
   "source": [
    "'''Trains and evaluate a simple MLP\n",
    "on the Reuters newswire topic classification task.\n",
    "'''\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import reuters\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "max_words = 1000\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_words,\n",
    "                                                         test_split=0.2)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "num_classes = np.max(y_train) + 1\n",
    "print(num_classes, 'classes')\n",
    "\n",
    "print('Vectorizing sequence data...')\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "x_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\n",
    "x_test = tokenizer.sequences_to_matrix(x_test, mode='binary')\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Convert class vector to binary class matrix '\n",
    "      '(for use with categorical_crossentropy)')\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "\n",
    "print('Building model...')\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "score = model.evaluate(x_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total addition questions: 50000\n",
      "Vectorization...\n",
      "Training Data:\n",
      "(45000, 7, 12)\n",
      "(45000, 4, 12)\n",
      "Validation Data:\n",
      "(5000, 7, 12)\n",
      "(5000, 4, 12)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               72192     \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 4, 128)            131584    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 4, 12)             1548      \n",
      "=================================================================\n",
      "Total params: 205,324\n",
      "Trainable params: 205,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 102us/step - loss: 1.8918 - acc: 0.3203 - val_loss: 1.7945 - val_acc: 0.3375\n",
      "Q 489+65  T 554  \u001b[91m☒\u001b[0m Q 685+99  T 784  \u001b[91m☒\u001b[0m Q 443+430 T 873  \u001b[91m☒\u001b[0m Q 81+934  T 1015 \u001b[91m☒\u001b[0m Q 423+374 T 797  \u001b[91m☒\u001b[0m Q 98+60   T 158  \u001b[91m☒\u001b[0m Q 526+89  T 615  \u001b[91m☒\u001b[0m Q 746+0   T 746  \u001b[91m☒\u001b[0m Q 10+444  T 454  \u001b[91m☒\u001b[0m Q 755+13  T 768  \u001b[91m☒\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 1.7337 - acc: 0.3593 - val_loss: 1.6606 - val_acc: 0.3797\n",
      "Q 200+78  T 278  \u001b[91m☒\u001b[0m Q 341+254 T 595  \u001b[91m☒\u001b[0m Q 22+99   T 121  \u001b[91m☒\u001b[0m Q 147+88  T 235  \u001b[91m☒\u001b[0m Q 891+246 T 1137 \u001b[91m☒\u001b[0m Q 484+570 T 1054 \u001b[91m☒\u001b[0m Q 1+453   T 454  \u001b[91m☒\u001b[0m Q 58+481  T 539  \u001b[91m☒\u001b[0m Q 553+60  T 613  \u001b[91m☒\u001b[0m Q 9+148   T 157  \u001b[91m☒\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 1.5852 - acc: 0.4074 - val_loss: 1.4965 - val_acc: 0.4399\n",
      "Q 959+13  T 972  \u001b[91m☒\u001b[0m Q 850+81  T 931  \u001b[91m☒\u001b[0m Q 817+17  T 834  \u001b[91m☒\u001b[0m Q 32+37   T 69   \u001b[91m☒\u001b[0m Q 7+564   T 571  \u001b[91m☒\u001b[0m Q 917+306 T 1223 \u001b[91m☒\u001b[0m Q 927+533 T 1460 \u001b[91m☒\u001b[0m Q 81+68   T 149  \u001b[91m☒\u001b[0m Q 893+945 T 1838 \u001b[91m☒\u001b[0m Q 877+87  T 964  \u001b[91m☒\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 1.3974 - acc: 0.4776 - val_loss: 1.3116 - val_acc: 0.5147\n",
      "Q 207+99  T 306  \u001b[91m☒\u001b[0m Q 66+8    T 74   \u001b[91m☒\u001b[0m Q 71+274  T 345  \u001b[91m☒\u001b[0m Q 10+736  T 746  \u001b[91m☒\u001b[0m Q 5+385   T 390  \u001b[91m☒\u001b[0m Q 401+708 T 1109 \u001b[91m☒\u001b[0m Q 600+709 T 1309 \u001b[91m☒\u001b[0m Q 458+85  T 543  \u001b[91m☒\u001b[0m Q 187+3   T 190  \u001b[91m☒\u001b[0m Q 82+870  T 952  \u001b[91m☒\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 1.2297 - acc: 0.5472 - val_loss: 1.1732 - val_acc: 0.5686\n",
      "Q 978+75  T 1053 \u001b[91m☒\u001b[0m Q 208+65  T 273  \u001b[91m☒\u001b[0m Q 699+670 T 1369 \u001b[91m☒\u001b[0m Q 99+182  T 281  \u001b[91m☒\u001b[0m Q 42+379  T 421  \u001b[91m☒\u001b[0m Q 622+66  T 688  \u001b[91m☒\u001b[0m Q 70+987  T 1057 \u001b[91m☒\u001b[0m Q 603+610 T 1213 \u001b[91m☒\u001b[0m Q 820+937 T 1757 \u001b[91m☒\u001b[0m Q 393+36  T 429  \u001b[91m☒\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 1.0848 - acc: 0.6054 - val_loss: 1.0308 - val_acc: 0.6301\n",
      "Q 153+367 T 520  \u001b[91m☒\u001b[0m Q 40+514  T 554  \u001b[91m☒\u001b[0m Q 50+35   T 85   \u001b[91m☒\u001b[0m Q 224+297 T 521  \u001b[91m☒\u001b[0m Q 850+411 T 1261 \u001b[91m☒\u001b[0m Q 56+13   T 69   \u001b[91m☒\u001b[0m Q 352+141 T 493  \u001b[91m☒\u001b[0m Q 79+25   T 104  \u001b[91m☒\u001b[0m Q 420+80  T 500  \u001b[91m☒\u001b[0m Q 895+468 T 1363 \u001b[91m☒\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.9858 - acc: 0.6466 - val_loss: 0.9636 - val_acc: 0.6456\n",
      "Q 931+36  T 967  \u001b[92m☑\u001b[0m Q 665+755 T 1420 \u001b[91m☒\u001b[0m Q 806+4   T 810  \u001b[91m☒\u001b[0m Q 56+21   T 77   \u001b[91m☒\u001b[0m Q 592+718 T 1310 \u001b[91m☒\u001b[0m Q 118+914 T 1032 \u001b[91m☒\u001b[0m Q 214+8   T 222  \u001b[92m☑\u001b[0m Q 687+8   T 695  \u001b[91m☒\u001b[0m Q 149+18  T 167  \u001b[91m☒\u001b[0m Q 469+605 T 1074 \u001b[91m☒\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.9069 - acc: 0.6766 - val_loss: 0.8838 - val_acc: 0.6861\n",
      "Q 180+425 T 605  \u001b[91m☒\u001b[0m Q 368+306 T 674  \u001b[91m☒\u001b[0m Q 348+21  T 369  \u001b[91m☒\u001b[0m Q 320+88  T 408  \u001b[91m☒\u001b[0m Q 3+401   T 404  \u001b[91m☒\u001b[0m Q 35+946  T 981  \u001b[91m☒\u001b[0m Q 414+820 T 1234 \u001b[91m☒\u001b[0m Q 0+891   T 891  \u001b[91m☒\u001b[0m Q 68+59   T 127  \u001b[91m☒\u001b[0m Q 21+323  T 344  \u001b[91m☒\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.8333 - acc: 0.7034 - val_loss: 0.8017 - val_acc: 0.7172\n",
      "Q 2+419   T 421  \u001b[92m☑\u001b[0m Q 108+238 T 346  \u001b[91m☒\u001b[0m Q 627+668 T 1295 \u001b[91m☒\u001b[0m Q 649+27  T 676  \u001b[91m☒\u001b[0m Q 99+411  T 510  \u001b[91m☒\u001b[0m Q 586+73  T 659  \u001b[91m☒\u001b[0m Q 638+65  T 703  \u001b[91m☒\u001b[0m Q 393+39  T 432  \u001b[91m☒\u001b[0m Q 221+642 T 863  \u001b[91m☒\u001b[0m Q 605+394 T 999  \u001b[91m☒\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.7649 - acc: 0.7300 - val_loss: 0.7401 - val_acc: 0.7435\n",
      "Q 96+968  T 1064 \u001b[91m☒\u001b[0m Q 96+100  T 196  \u001b[91m☒\u001b[0m Q 97+31   T 128  \u001b[92m☑\u001b[0m Q 96+80   T 176  \u001b[91m☒\u001b[0m Q 874+1   T 875  \u001b[92m☑\u001b[0m Q 356+171 T 527  \u001b[91m☒\u001b[0m Q 448+0   T 448  \u001b[92m☑\u001b[0m Q 457+586 T 1043 \u001b[91m☒\u001b[0m Q 939+911 T 1850 \u001b[91m☒\u001b[0m Q 369+61  T 430  \u001b[91m☒\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 0.7075 - acc: 0.7520 - val_loss: 0.7053 - val_acc: 0.7475\n",
      "Q 513+48  T 561  \u001b[92m☑\u001b[0m Q 29+70   T 99   \u001b[91m☒\u001b[0m Q 373+3   T 376  \u001b[92m☑\u001b[0m Q 88+69   T 157  \u001b[91m☒\u001b[0m Q 266+13  T 279  \u001b[91m☒\u001b[0m Q 28+94   T 122  \u001b[91m☒\u001b[0m Q 291+61  T 352  \u001b[92m☑\u001b[0m Q 842+21  T 863  \u001b[91m☒\u001b[0m Q 994+5   T 999  \u001b[91m☒\u001b[0m Q 349+21  T 370  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.6411 - acc: 0.7765 - val_loss: 0.5972 - val_acc: 0.7941\n",
      "Q 130+89  T 219  \u001b[92m☑\u001b[0m Q 9+298   T 307  \u001b[92m☑\u001b[0m Q 35+675  T 710  \u001b[92m☑\u001b[0m Q 77+796  T 873  \u001b[92m☑\u001b[0m Q 779+416 T 1195 \u001b[91m☒\u001b[0m Q 907+1   T 908  \u001b[92m☑\u001b[0m Q 779+416 T 1195 \u001b[91m☒\u001b[0m Q 34+96   T 130  \u001b[91m☒\u001b[0m Q 461+301 T 762  \u001b[91m☒\u001b[0m Q 531+3   T 534  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.5110 - acc: 0.8221 - val_loss: 0.4356 - val_acc: 0.8536\n",
      "Q 304+1   T 305  \u001b[91m☒\u001b[0m Q 172+301 T 473  \u001b[91m☒\u001b[0m Q 19+199  T 218  \u001b[91m☒\u001b[0m Q 583+26  T 609  \u001b[92m☑\u001b[0m Q 235+339 T 574  \u001b[91m☒\u001b[0m Q 6+142   T 148  \u001b[91m☒\u001b[0m Q 193+127 T 320  \u001b[91m☒\u001b[0m Q 29+293  T 322  \u001b[91m☒\u001b[0m Q 902+153 T 1055 \u001b[91m☒\u001b[0m Q 14+388  T 402  \u001b[91m☒\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.3637 - acc: 0.8866 - val_loss: 0.3101 - val_acc: 0.9121\n",
      "Q 75+315  T 390  \u001b[92m☑\u001b[0m Q 2+114   T 116  \u001b[92m☑\u001b[0m Q 750+244 T 994  \u001b[92m☑\u001b[0m Q 53+135  T 188  \u001b[92m☑\u001b[0m Q 39+590  T 629  \u001b[92m☑\u001b[0m Q 193+85  T 278  \u001b[92m☑\u001b[0m Q 712+87  T 799  \u001b[92m☑\u001b[0m Q 370+228 T 598  \u001b[92m☑\u001b[0m Q 453+37  T 490  \u001b[92m☑\u001b[0m Q 761+7   T 768  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.2601 - acc: 0.9329 - val_loss: 0.2259 - val_acc: 0.9476\n",
      "Q 31+209  T 240  \u001b[92m☑\u001b[0m Q 800+952 T 1752 \u001b[91m☒\u001b[0m Q 795+24  T 819  \u001b[92m☑\u001b[0m Q 674+668 T 1342 \u001b[92m☑\u001b[0m Q 63+85   T 148  \u001b[92m☑\u001b[0m Q 834+409 T 1243 \u001b[92m☑\u001b[0m Q 292+700 T 992  \u001b[92m☑\u001b[0m Q 8+629   T 637  \u001b[92m☑\u001b[0m Q 764+282 T 1046 \u001b[92m☑\u001b[0m Q 85+187  T 272  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.1878 - acc: 0.9603 - val_loss: 0.1780 - val_acc: 0.9577\n",
      "Q 773+511 T 1284 \u001b[92m☑\u001b[0m Q 336+527 T 863  \u001b[92m☑\u001b[0m Q 755+30  T 785  \u001b[92m☑\u001b[0m Q 32+724  T 756  \u001b[92m☑\u001b[0m Q 773+4   T 777  \u001b[92m☑\u001b[0m Q 2+42    T 44   \u001b[92m☑\u001b[0m Q 998+21  T 1019 \u001b[92m☑\u001b[0m Q 698+676 T 1374 \u001b[91m☒\u001b[0m Q 238+80  T 318  \u001b[92m☑\u001b[0m Q 73+60   T 133  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.1460 - acc: 0.9711 - val_loss: 0.1520 - val_acc: 0.9634\n",
      "Q 60+442  T 502  \u001b[92m☑\u001b[0m Q 50+563  T 613  \u001b[92m☑\u001b[0m Q 707+782 T 1489 \u001b[92m☑\u001b[0m Q 30+233  T 263  \u001b[92m☑\u001b[0m Q 48+385  T 433  \u001b[92m☑\u001b[0m Q 243+880 T 1123 \u001b[92m☑\u001b[0m Q 85+16   T 101  \u001b[92m☑\u001b[0m Q 575+76  T 651  \u001b[92m☑\u001b[0m Q 265+0   T 265  \u001b[92m☑\u001b[0m Q 46+464  T 510  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.1072 - acc: 0.9824 - val_loss: 0.1039 - val_acc: 0.9810\n",
      "Q 792+810 T 1602 \u001b[92m☑\u001b[0m Q 81+200  T 281  \u001b[92m☑\u001b[0m Q 978+66  T 1044 \u001b[92m☑\u001b[0m Q 3+983   T 986  \u001b[92m☑\u001b[0m Q 624+76  T 700  \u001b[91m☒\u001b[0m Q 91+354  T 445  \u001b[92m☑\u001b[0m Q 833+353 T 1186 \u001b[92m☑\u001b[0m Q 19+189  T 208  \u001b[92m☑\u001b[0m Q 8+750   T 758  \u001b[92m☑\u001b[0m Q 336+827 T 1163 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0884 - acc: 0.9851 - val_loss: 0.0857 - val_acc: 0.9847\n",
      "Q 483+0   T 483  \u001b[92m☑\u001b[0m Q 51+568  T 619  \u001b[92m☑\u001b[0m Q 94+86   T 180  \u001b[92m☑\u001b[0m Q 2+439   T 441  \u001b[92m☑\u001b[0m Q 64+73   T 137  \u001b[92m☑\u001b[0m Q 81+934  T 1015 \u001b[92m☑\u001b[0m Q 370+228 T 598  \u001b[92m☑\u001b[0m Q 195+339 T 534  \u001b[92m☑\u001b[0m Q 496+94  T 590  \u001b[92m☑\u001b[0m Q 92+40   T 132  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 20\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0833 - acc: 0.9836 - val_loss: 0.0663 - val_acc: 0.9899\n",
      "Q 608+3   T 611  \u001b[92m☑\u001b[0m Q 841+16  T 857  \u001b[92m☑\u001b[0m Q 92+709  T 801  \u001b[92m☑\u001b[0m Q 49+34   T 83   \u001b[92m☑\u001b[0m Q 628+5   T 633  \u001b[92m☑\u001b[0m Q 840+969 T 1809 \u001b[92m☑\u001b[0m Q 641+73  T 714  \u001b[92m☑\u001b[0m Q 714+38  T 752  \u001b[92m☑\u001b[0m Q 90+328  T 418  \u001b[92m☑\u001b[0m Q 52+956  T 1008 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 21\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0637 - acc: 0.9895 - val_loss: 0.0574 - val_acc: 0.9911\n",
      "Q 63+178  T 241  \u001b[92m☑\u001b[0m Q 447+559 T 1006 \u001b[92m☑\u001b[0m Q 13+512  T 525  \u001b[92m☑\u001b[0m Q 872+336 T 1208 \u001b[92m☑\u001b[0m Q 12+475  T 487  \u001b[92m☑\u001b[0m Q 297+86  T 383  \u001b[92m☑\u001b[0m Q 56+535  T 591  \u001b[92m☑\u001b[0m Q 268+43  T 311  \u001b[92m☑\u001b[0m Q 95+859  T 954  \u001b[92m☑\u001b[0m Q 9+776   T 785  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 22\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 0.0474 - acc: 0.9937 - val_loss: 0.0598 - val_acc: 0.9881\n",
      "Q 97+743  T 840  \u001b[91m☒\u001b[0m Q 512+488 T 1000 \u001b[91m☒\u001b[0m Q 91+4    T 95   \u001b[92m☑\u001b[0m Q 521+8   T 529  \u001b[92m☑\u001b[0m Q 9+859   T 868  \u001b[92m☑\u001b[0m Q 2+381   T 383  \u001b[92m☑\u001b[0m Q 569+17  T 586  \u001b[92m☑\u001b[0m Q 909+247 T 1156 \u001b[92m☑\u001b[0m Q 35+452  T 487  \u001b[92m☑\u001b[0m Q 368+306 T 674  \u001b[91m☒\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 23\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 0.0621 - acc: 0.9859 - val_loss: 0.0471 - val_acc: 0.9916\n",
      "Q 3+553   T 556  \u001b[92m☑\u001b[0m Q 292+515 T 807  \u001b[91m☒\u001b[0m Q 56+384  T 440  \u001b[92m☑\u001b[0m Q 215+546 T 761  \u001b[92m☑\u001b[0m Q 568+60  T 628  \u001b[92m☑\u001b[0m Q 545+46  T 591  \u001b[92m☑\u001b[0m Q 9+570   T 579  \u001b[92m☑\u001b[0m Q 113+227 T 340  \u001b[92m☑\u001b[0m Q 536+774 T 1310 \u001b[92m☑\u001b[0m Q 836+546 T 1382 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 24\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0305 - acc: 0.9973 - val_loss: 0.0330 - val_acc: 0.9952\n",
      "Q 963+54  T 1017 \u001b[92m☑\u001b[0m Q 73+944  T 1017 \u001b[92m☑\u001b[0m Q 312+82  T 394  \u001b[92m☑\u001b[0m Q 798+805 T 1603 \u001b[92m☑\u001b[0m Q 43+532  T 575  \u001b[92m☑\u001b[0m Q 97+800  T 897  \u001b[92m☑\u001b[0m Q 848+28  T 876  \u001b[92m☑\u001b[0m Q 421+20  T 441  \u001b[92m☑\u001b[0m Q 750+59  T 809  \u001b[92m☑\u001b[0m Q 1+970   T 971  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 25\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0256 - acc: 0.9978 - val_loss: 0.0312 - val_acc: 0.9948\n",
      "Q 164+19  T 183  \u001b[92m☑\u001b[0m Q 89+200  T 289  \u001b[92m☑\u001b[0m Q 35+540  T 575  \u001b[92m☑\u001b[0m Q 459+324 T 783  \u001b[92m☑\u001b[0m Q 423+62  T 485  \u001b[92m☑\u001b[0m Q 89+888  T 977  \u001b[92m☑\u001b[0m Q 90+94   T 184  \u001b[92m☑\u001b[0m Q 982+892 T 1874 \u001b[92m☑\u001b[0m Q 34+355  T 389  \u001b[92m☑\u001b[0m Q 448+0   T 448  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 26\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0476 - acc: 0.9882 - val_loss: 0.0333 - val_acc: 0.9946\n",
      "Q 482+1   T 483  \u001b[92m☑\u001b[0m Q 699+6   T 705  \u001b[92m☑\u001b[0m Q 478+16  T 494  \u001b[92m☑\u001b[0m Q 489+65  T 554  \u001b[92m☑\u001b[0m Q 6+997   T 1003 \u001b[92m☑\u001b[0m Q 18+35   T 53   \u001b[92m☑\u001b[0m Q 74+275  T 349  \u001b[92m☑\u001b[0m Q 541+924 T 1465 \u001b[92m☑\u001b[0m Q 919+555 T 1474 \u001b[92m☑\u001b[0m Q 950+712 T 1662 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 27\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0198 - acc: 0.9984 - val_loss: 0.0215 - val_acc: 0.9974\n",
      "Q 27+293  T 320  \u001b[92m☑\u001b[0m Q 625+48  T 673  \u001b[92m☑\u001b[0m Q 833+5   T 838  \u001b[92m☑\u001b[0m Q 758+733 T 1491 \u001b[92m☑\u001b[0m Q 79+84   T 163  \u001b[92m☑\u001b[0m Q 441+691 T 1132 \u001b[92m☑\u001b[0m Q 92+173  T 265  \u001b[92m☑\u001b[0m Q 558+95  T 653  \u001b[92m☑\u001b[0m Q 764+57  T 821  \u001b[92m☑\u001b[0m Q 121+29  T 150  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 28\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 0.0164 - acc: 0.9988 - val_loss: 0.0209 - val_acc: 0.9969\n",
      "Q 414+85  T 499  \u001b[92m☑\u001b[0m Q 237+202 T 439  \u001b[92m☑\u001b[0m Q 94+498  T 592  \u001b[92m☑\u001b[0m Q 451+0   T 451  \u001b[92m☑\u001b[0m Q 56+29   T 85   \u001b[92m☑\u001b[0m Q 27+55   T 82   \u001b[92m☑\u001b[0m Q 6+59    T 65   \u001b[92m☑\u001b[0m Q 350+496 T 846  \u001b[92m☑\u001b[0m Q 382+29  T 411  \u001b[92m☑\u001b[0m Q 926+89  T 1015 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 29\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0298 - acc: 0.9939 - val_loss: 0.2711 - val_acc: 0.9139\n",
      "Q 9+850   T 859  \u001b[92m☑\u001b[0m Q 10+769  T 779  \u001b[92m☑\u001b[0m Q 382+17  T 399  \u001b[92m☑\u001b[0m Q 79+478  T 557  \u001b[91m☒\u001b[0m Q 79+930  T 1009 \u001b[92m☑\u001b[0m Q 45+883  T 928  \u001b[92m☑\u001b[0m Q 0+63    T 63   \u001b[91m☒\u001b[0m Q 858+44  T 902  \u001b[92m☑\u001b[0m Q 158+494 T 652  \u001b[91m☒\u001b[0m Q 556+70  T 626  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 30\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0495 - acc: 0.9872 - val_loss: 0.0205 - val_acc: 0.9967\n",
      "Q 973+3   T 976  \u001b[92m☑\u001b[0m Q 841+44  T 885  \u001b[92m☑\u001b[0m Q 386+508 T 894  \u001b[92m☑\u001b[0m Q 384+73  T 457  \u001b[92m☑\u001b[0m Q 8+844   T 852  \u001b[92m☑\u001b[0m Q 955+64  T 1019 \u001b[92m☑\u001b[0m Q 25+289  T 314  \u001b[92m☑\u001b[0m Q 201+945 T 1146 \u001b[92m☑\u001b[0m Q 144+295 T 439  \u001b[92m☑\u001b[0m Q 19+32   T 51   \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 31\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0114 - acc: 0.9994 - val_loss: 0.0142 - val_acc: 0.9982\n",
      "Q 399+662 T 1061 \u001b[92m☑\u001b[0m Q 2+802   T 804  \u001b[92m☑\u001b[0m Q 732+55  T 787  \u001b[92m☑\u001b[0m Q 87+757  T 844  \u001b[92m☑\u001b[0m Q 45+906  T 951  \u001b[92m☑\u001b[0m Q 926+6   T 932  \u001b[92m☑\u001b[0m Q 82+967  T 1049 \u001b[92m☑\u001b[0m Q 19+474  T 493  \u001b[92m☑\u001b[0m Q 98+741  T 839  \u001b[92m☑\u001b[0m Q 22+891  T 913  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 32\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0095 - acc: 0.9995 - val_loss: 0.0133 - val_acc: 0.9980\n",
      "Q 621+54  T 675  \u001b[92m☑\u001b[0m Q 251+8   T 259  \u001b[92m☑\u001b[0m Q 116+187 T 303  \u001b[92m☑\u001b[0m Q 72+44   T 116  \u001b[92m☑\u001b[0m Q 952+42  T 994  \u001b[92m☑\u001b[0m Q 765+9   T 774  \u001b[92m☑\u001b[0m Q 101+4   T 105  \u001b[92m☑\u001b[0m Q 49+603  T 652  \u001b[92m☑\u001b[0m Q 88+783  T 871  \u001b[92m☑\u001b[0m Q 606+67  T 673  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 33\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0101 - acc: 0.9991 - val_loss: 0.0487 - val_acc: 0.9843\n",
      "Q 29+299  T 328  \u001b[92m☑\u001b[0m Q 3+401   T 404  \u001b[92m☑\u001b[0m Q 267+904 T 1171 \u001b[92m☑\u001b[0m Q 39+876  T 915  \u001b[92m☑\u001b[0m Q 279+280 T 559  \u001b[92m☑\u001b[0m Q 20+226  T 246  \u001b[92m☑\u001b[0m Q 926+6   T 932  \u001b[92m☑\u001b[0m Q 15+793  T 808  \u001b[92m☑\u001b[0m Q 280+97  T 377  \u001b[92m☑\u001b[0m Q 95+240  T 335  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 34\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0617 - acc: 0.9810 - val_loss: 0.0158 - val_acc: 0.9972\n",
      "Q 83+277  T 360  \u001b[92m☑\u001b[0m Q 314+3   T 317  \u001b[92m☑\u001b[0m Q 227+70  T 297  \u001b[92m☑\u001b[0m Q 113+81  T 194  \u001b[92m☑\u001b[0m Q 617+514 T 1131 \u001b[92m☑\u001b[0m Q 656+72  T 728  \u001b[92m☑\u001b[0m Q 918+88  T 1006 \u001b[92m☑\u001b[0m Q 872+53  T 925  \u001b[92m☑\u001b[0m Q 41+549  T 590  \u001b[92m☑\u001b[0m Q 854+753 T 1607 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 35\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0083 - acc: 0.9995 - val_loss: 0.0106 - val_acc: 0.9985\n",
      "Q 50+563  T 613  \u001b[92m☑\u001b[0m Q 97+743  T 840  \u001b[92m☑\u001b[0m Q 630+22  T 652  \u001b[92m☑\u001b[0m Q 2+99    T 101  \u001b[92m☑\u001b[0m Q 672+422 T 1094 \u001b[92m☑\u001b[0m Q 65+784  T 849  \u001b[92m☑\u001b[0m Q 730+47  T 777  \u001b[92m☑\u001b[0m Q 42+582  T 624  \u001b[92m☑\u001b[0m Q 97+31   T 128  \u001b[92m☑\u001b[0m Q 877+898 T 1775 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 36\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 0.0066 - acc: 0.9998 - val_loss: 0.0093 - val_acc: 0.9988\n",
      "Q 532+5   T 537  \u001b[92m☑\u001b[0m Q 310+929 T 1239 \u001b[92m☑\u001b[0m Q 606+8   T 614  \u001b[92m☑\u001b[0m Q 20+405  T 425  \u001b[92m☑\u001b[0m Q 8+881   T 889  \u001b[92m☑\u001b[0m Q 60+199  T 259  \u001b[92m☑\u001b[0m Q 7+175   T 182  \u001b[92m☑\u001b[0m Q 37+403  T 440  \u001b[92m☑\u001b[0m Q 73+357  T 430  \u001b[92m☑\u001b[0m Q 60+495  T 555  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 37\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0061 - acc: 0.9997 - val_loss: 0.0096 - val_acc: 0.9980\n",
      "Q 21+172  T 193  \u001b[92m☑\u001b[0m Q 761+95  T 856  \u001b[92m☑\u001b[0m Q 517+77  T 594  \u001b[92m☑\u001b[0m Q 682+74  T 756  \u001b[92m☑\u001b[0m Q 640+964 T 1604 \u001b[92m☑\u001b[0m Q 794+1   T 795  \u001b[92m☑\u001b[0m Q 750+821 T 1571 \u001b[92m☑\u001b[0m Q 63+165  T 228  \u001b[92m☑\u001b[0m Q 221+46  T 267  \u001b[92m☑\u001b[0m Q 263+98  T 361  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 38\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0411 - acc: 0.9875 - val_loss: 0.0199 - val_acc: 0.9950\n",
      "Q 223+6   T 229  \u001b[92m☑\u001b[0m Q 361+77  T 438  \u001b[92m☑\u001b[0m Q 337+1   T 338  \u001b[92m☑\u001b[0m Q 581+2   T 583  \u001b[92m☑\u001b[0m Q 75+220  T 295  \u001b[92m☑\u001b[0m Q 74+85   T 159  \u001b[92m☑\u001b[0m Q 50+900  T 950  \u001b[92m☑\u001b[0m Q 277+485 T 762  \u001b[92m☑\u001b[0m Q 466+202 T 668  \u001b[92m☑\u001b[0m Q 451+7   T 458  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 39\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0075 - acc: 0.9994 - val_loss: 0.0090 - val_acc: 0.9987\n",
      "Q 775+651 T 1426 \u001b[92m☑\u001b[0m Q 9+859   T 868  \u001b[92m☑\u001b[0m Q 2+972   T 974  \u001b[92m☑\u001b[0m Q 2+964   T 966  \u001b[92m☑\u001b[0m Q 31+496  T 527  \u001b[92m☑\u001b[0m Q 471+822 T 1293 \u001b[92m☑\u001b[0m Q 83+3    T 86   \u001b[92m☑\u001b[0m Q 25+43   T 68   \u001b[92m☑\u001b[0m Q 507+29  T 536  \u001b[92m☑\u001b[0m Q 28+512  T 540  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 40\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0048 - acc: 0.9998 - val_loss: 0.0073 - val_acc: 0.9990\n",
      "Q 7+230   T 237  \u001b[92m☑\u001b[0m Q 390+538 T 928  \u001b[92m☑\u001b[0m Q 526+89  T 615  \u001b[92m☑\u001b[0m Q 43+835  T 878  \u001b[92m☑\u001b[0m Q 54+167  T 221  \u001b[92m☑\u001b[0m Q 404+881 T 1285 \u001b[92m☑\u001b[0m Q 25+289  T 314  \u001b[92m☑\u001b[0m Q 271+588 T 859  \u001b[92m☑\u001b[0m Q 302+774 T 1076 \u001b[92m☑\u001b[0m Q 80+519  T 599  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 41\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0042 - acc: 0.9998 - val_loss: 0.0071 - val_acc: 0.9988\n",
      "Q 145+27  T 172  \u001b[92m☑\u001b[0m Q 210+656 T 866  \u001b[92m☑\u001b[0m Q 971+87  T 1058 \u001b[92m☑\u001b[0m Q 66+97   T 163  \u001b[92m☑\u001b[0m Q 81+51   T 132  \u001b[92m☑\u001b[0m Q 158+64  T 222  \u001b[92m☑\u001b[0m Q 765+53  T 818  \u001b[92m☑\u001b[0m Q 62+94   T 156  \u001b[92m☑\u001b[0m Q 212+910 T 1122 \u001b[92m☑\u001b[0m Q 937+709 T 1646 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 42\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0041 - acc: 0.9998 - val_loss: 0.0069 - val_acc: 0.9989\n",
      "Q 779+8   T 787  \u001b[92m☑\u001b[0m Q 447+559 T 1006 \u001b[92m☑\u001b[0m Q 76+259  T 335  \u001b[92m☑\u001b[0m Q 611+391 T 1002 \u001b[92m☑\u001b[0m Q 3+934   T 937  \u001b[92m☑\u001b[0m Q 599+454 T 1053 \u001b[92m☑\u001b[0m Q 281+884 T 1165 \u001b[92m☑\u001b[0m Q 2+976   T 978  \u001b[92m☑\u001b[0m Q 656+36  T 692  \u001b[92m☑\u001b[0m Q 8+690   T 698  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 43\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0038 - acc: 0.9998 - val_loss: 0.0078 - val_acc: 0.9986\n",
      "Q 12+92   T 104  \u001b[92m☑\u001b[0m Q 71+124  T 195  \u001b[92m☑\u001b[0m Q 812+372 T 1184 \u001b[92m☑\u001b[0m Q 551+74  T 625  \u001b[92m☑\u001b[0m Q 28+512  T 540  \u001b[92m☑\u001b[0m Q 112+41  T 153  \u001b[92m☑\u001b[0m Q 835+70  T 905  \u001b[92m☑\u001b[0m Q 92+168  T 260  \u001b[92m☑\u001b[0m Q 434+68  T 502  \u001b[92m☑\u001b[0m Q 955+64  T 1019 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 44\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0490 - acc: 0.9853 - val_loss: 0.0090 - val_acc: 0.9983\n",
      "Q 717+928 T 1645 \u001b[92m☑\u001b[0m Q 357+255 T 612  \u001b[92m☑\u001b[0m Q 274+962 T 1236 \u001b[92m☑\u001b[0m Q 2+802   T 804  \u001b[92m☑\u001b[0m Q 989+296 T 1285 \u001b[92m☑\u001b[0m Q 606+766 T 1372 \u001b[92m☑\u001b[0m Q 142+34  T 176  \u001b[92m☑\u001b[0m Q 119+23  T 142  \u001b[92m☑\u001b[0m Q 989+516 T 1505 \u001b[92m☑\u001b[0m Q 885+85  T 970  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 45\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0045 - acc: 0.9998 - val_loss: 0.0067 - val_acc: 0.9989\n",
      "Q 59+583  T 642  \u001b[92m☑\u001b[0m Q 5+861   T 866  \u001b[92m☑\u001b[0m Q 0+722   T 722  \u001b[92m☑\u001b[0m Q 270+687 T 957  \u001b[92m☑\u001b[0m Q 51+198  T 249  \u001b[92m☑\u001b[0m Q 9+277   T 286  \u001b[92m☑\u001b[0m Q 34+254  T 288  \u001b[92m☑\u001b[0m Q 91+346  T 437  \u001b[92m☑\u001b[0m Q 37+494  T 531  \u001b[92m☑\u001b[0m Q 40+69   T 109  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 46\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0032 - acc: 0.9999 - val_loss: 0.0055 - val_acc: 0.9991\n",
      "Q 760+714 T 1474 \u001b[92m☑\u001b[0m Q 321+21  T 342  \u001b[92m☑\u001b[0m Q 946+14  T 960  \u001b[92m☑\u001b[0m Q 1+829   T 830  \u001b[92m☑\u001b[0m Q 803+630 T 1433 \u001b[92m☑\u001b[0m Q 11+872  T 883  \u001b[92m☑\u001b[0m Q 77+796  T 873  \u001b[92m☑\u001b[0m Q 450+559 T 1009 \u001b[92m☑\u001b[0m Q 779+416 T 1195 \u001b[92m☑\u001b[0m Q 95+984  T 1079 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 47\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0029 - acc: 0.9999 - val_loss: 0.0073 - val_acc: 0.9981\n",
      "Q 228+10  T 238  \u001b[92m☑\u001b[0m Q 892+845 T 1737 \u001b[92m☑\u001b[0m Q 359+91  T 450  \u001b[92m☑\u001b[0m Q 27+105  T 132  \u001b[92m☑\u001b[0m Q 53+222  T 275  \u001b[92m☑\u001b[0m Q 812+74  T 886  \u001b[92m☑\u001b[0m Q 7+908   T 915  \u001b[92m☑\u001b[0m Q 643+498 T 1141 \u001b[92m☑\u001b[0m Q 649+13  T 662  \u001b[92m☑\u001b[0m Q 243+639 T 882  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 48\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0028 - acc: 0.9998 - val_loss: 0.0050 - val_acc: 0.9991\n",
      "Q 271+940 T 1211 \u001b[92m☑\u001b[0m Q 839+419 T 1258 \u001b[92m☑\u001b[0m Q 528+35  T 563  \u001b[92m☑\u001b[0m Q 378+7   T 385  \u001b[92m☑\u001b[0m Q 47+555  T 602  \u001b[92m☑\u001b[0m Q 414+3   T 417  \u001b[92m☑\u001b[0m Q 2+668   T 670  \u001b[92m☑\u001b[0m Q 4+227   T 231  \u001b[92m☑\u001b[0m Q 171+23  T 194  \u001b[92m☑\u001b[0m Q 700+533 T 1233 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 49\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0520 - acc: 0.9844 - val_loss: 0.0217 - val_acc: 0.9941\n",
      "Q 814+990 T 1804 \u001b[92m☑\u001b[0m Q 778+18  T 796  \u001b[92m☑\u001b[0m Q 818+2   T 820  \u001b[92m☑\u001b[0m Q 98+52   T 150  \u001b[92m☑\u001b[0m Q 5+168   T 173  \u001b[92m☑\u001b[0m Q 923+779 T 1702 \u001b[92m☑\u001b[0m Q 68+868  T 936  \u001b[92m☑\u001b[0m Q 97+693  T 790  \u001b[92m☑\u001b[0m Q 12+392  T 404  \u001b[92m☑\u001b[0m Q 5+700   T 705  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 50\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0060 - acc: 0.9992 - val_loss: 0.0058 - val_acc: 0.9992\n",
      "Q 43+919  T 962  \u001b[92m☑\u001b[0m Q 942+85  T 1027 \u001b[92m☑\u001b[0m Q 67+826  T 893  \u001b[92m☑\u001b[0m Q 92+51   T 143  \u001b[92m☑\u001b[0m Q 637+577 T 1214 \u001b[92m☑\u001b[0m Q 325+8   T 333  \u001b[92m☑\u001b[0m Q 6+197   T 203  \u001b[92m☑\u001b[0m Q 199+215 T 414  \u001b[92m☑\u001b[0m Q 163+504 T 667  \u001b[92m☑\u001b[0m Q 307+5   T 312  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 51\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 0.0027 - acc: 0.9999 - val_loss: 0.0048 - val_acc: 0.9994\n",
      "Q 6+142   T 148  \u001b[92m☑\u001b[0m Q 860+91  T 951  \u001b[92m☑\u001b[0m Q 358+814 T 1172 \u001b[92m☑\u001b[0m Q 211+31  T 242  \u001b[92m☑\u001b[0m Q 739+82  T 821  \u001b[92m☑\u001b[0m Q 841+753 T 1594 \u001b[92m☑\u001b[0m Q 36+184  T 220  \u001b[92m☑\u001b[0m Q 49+1    T 50   \u001b[92m☑\u001b[0m Q 77+644  T 721  \u001b[92m☑\u001b[0m Q 335+0   T 335  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 52\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 0.0024 - acc: 0.9999 - val_loss: 0.0042 - val_acc: 0.9994\n",
      "Q 841+73  T 914  \u001b[92m☑\u001b[0m Q 360+95  T 455  \u001b[92m☑\u001b[0m Q 294+52  T 346  \u001b[92m☑\u001b[0m Q 559+695 T 1254 \u001b[92m☑\u001b[0m Q 99+36   T 135  \u001b[92m☑\u001b[0m Q 24+273  T 297  \u001b[92m☑\u001b[0m Q 128+987 T 1115 \u001b[92m☑\u001b[0m Q 146+5   T 151  \u001b[92m☑\u001b[0m Q 325+70  T 395  \u001b[92m☑\u001b[0m Q 200+736 T 936  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 53\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0021 - acc: 0.9999 - val_loss: 0.0043 - val_acc: 0.9993\n",
      "Q 34+355  T 389  \u001b[92m☑\u001b[0m Q 961+177 T 1138 \u001b[92m☑\u001b[0m Q 43+892  T 935  \u001b[92m☑\u001b[0m Q 906+94  T 1000 \u001b[92m☑\u001b[0m Q 918+3   T 921  \u001b[92m☑\u001b[0m Q 811+447 T 1258 \u001b[92m☑\u001b[0m Q 494+899 T 1393 \u001b[92m☑\u001b[0m Q 143+945 T 1088 \u001b[92m☑\u001b[0m Q 92+268  T 360  \u001b[92m☑\u001b[0m Q 580+20  T 600  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 54\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0122 - acc: 0.9967 - val_loss: 0.2125 - val_acc: 0.9336\n",
      "Q 52+16   T 68   \u001b[92m☑\u001b[0m Q 66+8    T 74   \u001b[92m☑\u001b[0m Q 5+453   T 458  \u001b[92m☑\u001b[0m Q 985+0   T 985  \u001b[92m☑\u001b[0m Q 398+923 T 1321 \u001b[92m☑\u001b[0m Q 994+5   T 999  \u001b[92m☑\u001b[0m Q 828+876 T 1704 \u001b[92m☑\u001b[0m Q 806+4   T 810  \u001b[92m☑\u001b[0m Q 268+43  T 311  \u001b[92m☑\u001b[0m Q 73+357  T 430  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 55\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0418 - acc: 0.9877 - val_loss: 0.0058 - val_acc: 0.9990\n",
      "Q 158+64  T 222  \u001b[92m☑\u001b[0m Q 73+258  T 331  \u001b[92m☑\u001b[0m Q 106+817 T 923  \u001b[92m☑\u001b[0m Q 473+468 T 941  \u001b[92m☑\u001b[0m Q 514+136 T 650  \u001b[92m☑\u001b[0m Q 868+70  T 938  \u001b[92m☑\u001b[0m Q 4+761   T 765  \u001b[92m☑\u001b[0m Q 2+998   T 1000 \u001b[92m☑\u001b[0m Q 870+33  T 903  \u001b[92m☑\u001b[0m Q 56+29   T 85   \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 56\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0026 - acc: 0.9999 - val_loss: 0.0042 - val_acc: 0.9992\n",
      "Q 87+62   T 149  \u001b[92m☑\u001b[0m Q 66+62   T 128  \u001b[92m☑\u001b[0m Q 335+0   T 335  \u001b[92m☑\u001b[0m Q 177+13  T 190  \u001b[92m☑\u001b[0m Q 1+441   T 442  \u001b[92m☑\u001b[0m Q 478+14  T 492  \u001b[92m☑\u001b[0m Q 87+287  T 374  \u001b[92m☑\u001b[0m Q 631+4   T 635  \u001b[92m☑\u001b[0m Q 9+202   T 211  \u001b[92m☑\u001b[0m Q 387+820 T 1207 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 57\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 0.9994\n",
      "Q 266+637 T 903  \u001b[92m☑\u001b[0m Q 286+95  T 381  \u001b[92m☑\u001b[0m Q 93+266  T 359  \u001b[92m☑\u001b[0m Q 243+32  T 275  \u001b[92m☑\u001b[0m Q 529+51  T 580  \u001b[92m☑\u001b[0m Q 686+4   T 690  \u001b[92m☑\u001b[0m Q 892+366 T 1258 \u001b[92m☑\u001b[0m Q 17+728  T 745  \u001b[92m☑\u001b[0m Q 30+801  T 831  \u001b[92m☑\u001b[0m Q 96+289  T 385  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 58\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0018 - acc: 0.9999 - val_loss: 0.0035 - val_acc: 0.9994\n",
      "Q 332+7   T 339  \u001b[92m☑\u001b[0m Q 597+375 T 972  \u001b[92m☑\u001b[0m Q 16+8    T 24   \u001b[92m☑\u001b[0m Q 685+361 T 1046 \u001b[92m☑\u001b[0m Q 410+2   T 412  \u001b[92m☑\u001b[0m Q 352+409 T 761  \u001b[92m☑\u001b[0m Q 976+272 T 1248 \u001b[92m☑\u001b[0m Q 315+5   T 320  \u001b[92m☑\u001b[0m Q 15+15   T 30   \u001b[92m☑\u001b[0m Q 630+99  T 729  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 59\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0016 - acc: 0.9999 - val_loss: 0.0040 - val_acc: 0.9992\n",
      "Q 81+287  T 368  \u001b[92m☑\u001b[0m Q 79+853  T 932  \u001b[92m☑\u001b[0m Q 510+13  T 523  \u001b[92m☑\u001b[0m Q 31+674  T 705  \u001b[92m☑\u001b[0m Q 338+177 T 515  \u001b[92m☑\u001b[0m Q 119+74  T 193  \u001b[92m☑\u001b[0m Q 109+446 T 555  \u001b[92m☑\u001b[0m Q 52+114  T 166  \u001b[92m☑\u001b[0m Q 250+270 T 520  \u001b[92m☑\u001b[0m Q 38+590  T 628  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 60\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 0.0016 - acc: 0.9999 - val_loss: 0.0040 - val_acc: 0.9991\n",
      "Q 5+453   T 458  \u001b[92m☑\u001b[0m Q 88+5    T 93   \u001b[92m☑\u001b[0m Q 693+649 T 1342 \u001b[92m☑\u001b[0m Q 711+345 T 1056 \u001b[92m☑\u001b[0m Q 349+588 T 937  \u001b[92m☑\u001b[0m Q 893+221 T 1114 \u001b[92m☑\u001b[0m Q 773+511 T 1284 \u001b[92m☑\u001b[0m Q 90+901  T 991  \u001b[92m☑\u001b[0m Q 595+608 T 1203 \u001b[92m☑\u001b[0m Q 746+48  T 794  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 61\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 0.0449 - acc: 0.9860 - val_loss: 0.0068 - val_acc: 0.9987\n",
      "Q 906+53  T 959  \u001b[92m☑\u001b[0m Q 734+780 T 1514 \u001b[92m☑\u001b[0m Q 48+559  T 607  \u001b[92m☑\u001b[0m Q 679+3   T 682  \u001b[92m☑\u001b[0m Q 578+537 T 1115 \u001b[92m☑\u001b[0m Q 34+35   T 69   \u001b[92m☑\u001b[0m Q 87+62   T 149  \u001b[92m☑\u001b[0m Q 982+892 T 1874 \u001b[92m☑\u001b[0m Q 908+26  T 934  \u001b[92m☑\u001b[0m Q 540+27  T 567  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 62\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 5s 100us/step - loss: 0.0027 - acc: 0.9999 - val_loss: 0.0039 - val_acc: 0.9997\n",
      "Q 6+416   T 422  \u001b[92m☑\u001b[0m Q 243+880 T 1123 \u001b[92m☑\u001b[0m Q 280+97  T 377  \u001b[92m☑\u001b[0m Q 959+9   T 968  \u001b[92m☑\u001b[0m Q 46+49   T 95   \u001b[92m☑\u001b[0m Q 6+145   T 151  \u001b[92m☑\u001b[0m Q 19+645  T 664  \u001b[92m☑\u001b[0m Q 22+15   T 37   \u001b[92m☑\u001b[0m Q 585+973 T 1558 \u001b[92m☑\u001b[0m Q 56+515  T 571  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 63\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 0.9997\n",
      "Q 27+1    T 28   \u001b[92m☑\u001b[0m Q 616+766 T 1382 \u001b[92m☑\u001b[0m Q 621+75  T 696  \u001b[92m☑\u001b[0m Q 78+408  T 486  \u001b[92m☑\u001b[0m Q 94+186  T 280  \u001b[92m☑\u001b[0m Q 708+304 T 1012 \u001b[92m☑\u001b[0m Q 616+3   T 619  \u001b[92m☑\u001b[0m Q 891+8   T 899  \u001b[92m☑\u001b[0m Q 406+4   T 410  \u001b[92m☑\u001b[0m Q 58+629  T 687  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 64\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Q 74+871  T 945  \u001b[92m☑\u001b[0m Q 630+22  T 652  \u001b[92m☑\u001b[0m Q 234+60  T 294  \u001b[92m☑\u001b[0m Q 24+38   T 62   \u001b[92m☑\u001b[0m Q 73+6    T 79   \u001b[92m☑\u001b[0m Q 708+0   T 708  \u001b[92m☑\u001b[0m Q 495+79  T 574  \u001b[92m☑\u001b[0m Q 33+952  T 985  \u001b[92m☑\u001b[0m Q 556+70  T 626  \u001b[92m☑\u001b[0m Q 317+289 T 606  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 65\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0014 - acc: 0.9999 - val_loss: 0.0032 - val_acc: 0.9995\n",
      "Q 429+70  T 499  \u001b[92m☑\u001b[0m Q 405+16  T 421  \u001b[92m☑\u001b[0m Q 215+303 T 518  \u001b[92m☑\u001b[0m Q 68+541  T 609  \u001b[92m☑\u001b[0m Q 674+64  T 738  \u001b[92m☑\u001b[0m Q 87+885  T 972  \u001b[92m☑\u001b[0m Q 3+934   T 937  \u001b[92m☑\u001b[0m Q 337+76  T 413  \u001b[92m☑\u001b[0m Q 242+158 T 400  \u001b[92m☑\u001b[0m Q 236+457 T 693  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 66\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0266 - acc: 0.9920 - val_loss: 0.0939 - val_acc: 0.9669\n",
      "Q 509+4   T 513  \u001b[92m☑\u001b[0m Q 525+680 T 1205 \u001b[92m☑\u001b[0m Q 498+235 T 733  \u001b[92m☑\u001b[0m Q 112+41  T 153  \u001b[92m☑\u001b[0m Q 563+60  T 623  \u001b[92m☑\u001b[0m Q 936+4   T 940  \u001b[92m☑\u001b[0m Q 606+7   T 613  \u001b[92m☑\u001b[0m Q 674+64  T 738  \u001b[92m☑\u001b[0m Q 357+22  T 379  \u001b[91m☒\u001b[0m Q 977+837 T 1814 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 67\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0148 - acc: 0.9959 - val_loss: 0.0052 - val_acc: 0.9991\n",
      "Q 83+346  T 429  \u001b[92m☑\u001b[0m Q 786+378 T 1164 \u001b[92m☑\u001b[0m Q 506+53  T 559  \u001b[92m☑\u001b[0m Q 293+504 T 797  \u001b[92m☑\u001b[0m Q 6+641   T 647  \u001b[92m☑\u001b[0m Q 764+57  T 821  \u001b[92m☑\u001b[0m Q 529+55  T 584  \u001b[92m☑\u001b[0m Q 3+866   T 869  \u001b[92m☑\u001b[0m Q 8+185   T 193  \u001b[92m☑\u001b[0m Q 71+109  T 180  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 68\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 0.9994\n",
      "Q 774+807 T 1581 \u001b[92m☑\u001b[0m Q 8+394   T 402  \u001b[92m☑\u001b[0m Q 29+505  T 534  \u001b[92m☑\u001b[0m Q 995+847 T 1842 \u001b[92m☑\u001b[0m Q 652+354 T 1006 \u001b[92m☑\u001b[0m Q 48+612  T 660  \u001b[92m☑\u001b[0m Q 706+184 T 890  \u001b[92m☑\u001b[0m Q 901+63  T 964  \u001b[92m☑\u001b[0m Q 752+933 T 1685 \u001b[92m☑\u001b[0m Q 830+538 T 1368 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 69\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 0.9994\n",
      "Q 85+378  T 463  \u001b[92m☑\u001b[0m Q 534+83  T 617  \u001b[92m☑\u001b[0m Q 4+600   T 604  \u001b[92m☑\u001b[0m Q 84+428  T 512  \u001b[92m☑\u001b[0m Q 458+936 T 1394 \u001b[92m☑\u001b[0m Q 842+6   T 848  \u001b[92m☑\u001b[0m Q 233+7   T 240  \u001b[92m☑\u001b[0m Q 851+623 T 1474 \u001b[92m☑\u001b[0m Q 76+259  T 335  \u001b[92m☑\u001b[0m Q 569+6   T 575  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 70\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 0.9996\n",
      "Q 85+780  T 865  \u001b[92m☑\u001b[0m Q 928+7   T 935  \u001b[92m☑\u001b[0m Q 841+73  T 914  \u001b[92m☑\u001b[0m Q 20+24   T 44   \u001b[92m☑\u001b[0m Q 42+91   T 133  \u001b[92m☑\u001b[0m Q 607+552 T 1159 \u001b[92m☑\u001b[0m Q 639+71  T 710  \u001b[92m☑\u001b[0m Q 639+6   T 645  \u001b[92m☑\u001b[0m Q 80+687  T 767  \u001b[92m☑\u001b[0m Q 476+396 T 872  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 71\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0012 - acc: 0.9999 - val_loss: 0.0037 - val_acc: 0.9993\n",
      "Q 75+147  T 222  \u001b[92m☑\u001b[0m Q 367+56  T 423  \u001b[92m☑\u001b[0m Q 646+6   T 652  \u001b[92m☑\u001b[0m Q 30+974  T 1004 \u001b[92m☑\u001b[0m Q 229+815 T 1044 \u001b[92m☑\u001b[0m Q 677+448 T 1125 \u001b[92m☑\u001b[0m Q 300+49  T 349  \u001b[92m☑\u001b[0m Q 510+55  T 565  \u001b[92m☑\u001b[0m Q 75+330  T 405  \u001b[92m☑\u001b[0m Q 227+547 T 774  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 72\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0404 - acc: 0.9886 - val_loss: 0.0053 - val_acc: 0.9991\n",
      "Q 456+933 T 1389 \u001b[92m☑\u001b[0m Q 91+243  T 334  \u001b[92m☑\u001b[0m Q 49+194  T 243  \u001b[92m☑\u001b[0m Q 0+606   T 606  \u001b[92m☑\u001b[0m Q 0+393   T 393  \u001b[92m☑\u001b[0m Q 672+81  T 753  \u001b[92m☑\u001b[0m Q 56+17   T 73   \u001b[92m☑\u001b[0m Q 681+1   T 682  \u001b[92m☑\u001b[0m Q 668+89  T 757  \u001b[92m☑\u001b[0m Q 1+473   T 474  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 73\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 0.9997\n",
      "Q 144+26  T 170  \u001b[92m☑\u001b[0m Q 23+275  T 298  \u001b[92m☑\u001b[0m Q 325+163 T 488  \u001b[92m☑\u001b[0m Q 690+91  T 781  \u001b[92m☑\u001b[0m Q 48+947  T 995  \u001b[92m☑\u001b[0m Q 5+619   T 624  \u001b[92m☑\u001b[0m Q 690+603 T 1293 \u001b[92m☑\u001b[0m Q 9+47    T 56   \u001b[92m☑\u001b[0m Q 28+969  T 997  \u001b[92m☑\u001b[0m Q 483+32  T 515  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 74\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 0.9997\n",
      "Q 610+6   T 616  \u001b[92m☑\u001b[0m Q 173+84  T 257  \u001b[92m☑\u001b[0m Q 466+202 T 668  \u001b[92m☑\u001b[0m Q 570+1   T 571  \u001b[92m☑\u001b[0m Q 690+545 T 1235 \u001b[92m☑\u001b[0m Q 49+292  T 341  \u001b[92m☑\u001b[0m Q 97+618  T 715  \u001b[92m☑\u001b[0m Q 5+252   T 257  \u001b[92m☑\u001b[0m Q 19+915  T 934  \u001b[92m☑\u001b[0m Q 79+40   T 119  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 75\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 0.9996\n",
      "Q 866+6   T 872  \u001b[92m☑\u001b[0m Q 736+246 T 982  \u001b[92m☑\u001b[0m Q 350+515 T 865  \u001b[92m☑\u001b[0m Q 91+187  T 278  \u001b[92m☑\u001b[0m Q 2+42    T 44   \u001b[92m☑\u001b[0m Q 536+758 T 1294 \u001b[92m☑\u001b[0m Q 895+468 T 1363 \u001b[92m☑\u001b[0m Q 524+6   T 530  \u001b[92m☑\u001b[0m Q 516+75  T 591  \u001b[92m☑\u001b[0m Q 608+3   T 611  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 76\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 0.9996\n",
      "Q 560+44  T 604  \u001b[92m☑\u001b[0m Q 989+516 T 1505 \u001b[92m☑\u001b[0m Q 963+54  T 1017 \u001b[92m☑\u001b[0m Q 547+3   T 550  \u001b[92m☑\u001b[0m Q 174+816 T 990  \u001b[92m☑\u001b[0m Q 94+56   T 150  \u001b[92m☑\u001b[0m Q 353+68  T 421  \u001b[92m☑\u001b[0m Q 768+744 T 1512 \u001b[92m☑\u001b[0m Q 310+929 T 1239 \u001b[92m☑\u001b[0m Q 869+272 T 1141 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 77\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 102us/step - loss: 9.5912e-04 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 0.9991\n",
      "Q 406+92  T 498  \u001b[92m☑\u001b[0m Q 283+8   T 291  \u001b[92m☑\u001b[0m Q 847+23  T 870  \u001b[92m☑\u001b[0m Q 512+7   T 519  \u001b[92m☑\u001b[0m Q 32+52   T 84   \u001b[92m☑\u001b[0m Q 352+371 T 723  \u001b[92m☑\u001b[0m Q 6+577   T 583  \u001b[92m☑\u001b[0m Q 5+861   T 866  \u001b[92m☑\u001b[0m Q 502+24  T 526  \u001b[92m☑\u001b[0m Q 584+66  T 650  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 78\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 8.4884e-04 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 0.9993\n",
      "Q 0+367   T 367  \u001b[92m☑\u001b[0m Q 42+406  T 448  \u001b[92m☑\u001b[0m Q 599+481 T 1080 \u001b[92m☑\u001b[0m Q 750+244 T 994  \u001b[92m☑\u001b[0m Q 327+48  T 375  \u001b[92m☑\u001b[0m Q 57+40   T 97   \u001b[92m☑\u001b[0m Q 755+30  T 785  \u001b[92m☑\u001b[0m Q 287+797 T 1084 \u001b[92m☑\u001b[0m Q 995+96  T 1091 \u001b[92m☑\u001b[0m Q 68+369  T 437  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 79\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0408 - acc: 0.9875 - val_loss: 0.0273 - val_acc: 0.9907\n",
      "Q 72+86   T 158  \u001b[92m☑\u001b[0m Q 25+289  T 314  \u001b[92m☑\u001b[0m Q 19+910  T 929  \u001b[92m☑\u001b[0m Q 66+71   T 137  \u001b[92m☑\u001b[0m Q 72+53   T 125  \u001b[92m☑\u001b[0m Q 315+828 T 1143 \u001b[92m☑\u001b[0m Q 117+748 T 865  \u001b[92m☑\u001b[0m Q 381+10  T 391  \u001b[92m☑\u001b[0m Q 743+702 T 1445 \u001b[92m☑\u001b[0m Q 426+351 T 777  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 80\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0043 - acc: 0.9993 - val_loss: 0.0036 - val_acc: 0.9994\n",
      "Q 652+354 T 1006 \u001b[92m☑\u001b[0m Q 80+403  T 483  \u001b[92m☑\u001b[0m Q 878+541 T 1419 \u001b[92m☑\u001b[0m Q 76+532  T 608  \u001b[92m☑\u001b[0m Q 739+36  T 775  \u001b[92m☑\u001b[0m Q 761+95  T 856  \u001b[92m☑\u001b[0m Q 74+409  T 483  \u001b[92m☑\u001b[0m Q 284+980 T 1264 \u001b[92m☑\u001b[0m Q 3+94    T 97   \u001b[92m☑\u001b[0m Q 476+11  T 487  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 81\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 0.9995\n",
      "Q 626+37  T 663  \u001b[92m☑\u001b[0m Q 47+367  T 414  \u001b[92m☑\u001b[0m Q 670+529 T 1199 \u001b[92m☑\u001b[0m Q 627+68  T 695  \u001b[92m☑\u001b[0m Q 83+80   T 163  \u001b[92m☑\u001b[0m Q 30+912  T 942  \u001b[92m☑\u001b[0m Q 40+774  T 814  \u001b[92m☑\u001b[0m Q 61+403  T 464  \u001b[92m☑\u001b[0m Q 859+1   T 860  \u001b[92m☑\u001b[0m Q 191+97  T 288  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 82\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 0.9995\n",
      "Q 880+54  T 934  \u001b[92m☑\u001b[0m Q 433+85  T 518  \u001b[92m☑\u001b[0m Q 988+72  T 1060 \u001b[92m☑\u001b[0m Q 946+316 T 1262 \u001b[92m☑\u001b[0m Q 50+893  T 943  \u001b[92m☑\u001b[0m Q 290+629 T 919  \u001b[92m☑\u001b[0m Q 47+665  T 712  \u001b[92m☑\u001b[0m Q 39+557  T 596  \u001b[92m☑\u001b[0m Q 491+3   T 494  \u001b[92m☑\u001b[0m Q 2+381   T 383  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 83\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 8.6651e-04 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 0.9997\n",
      "Q 7+604   T 611  \u001b[92m☑\u001b[0m Q 80+18   T 98   \u001b[92m☑\u001b[0m Q 187+567 T 754  \u001b[92m☑\u001b[0m Q 484+1   T 485  \u001b[92m☑\u001b[0m Q 763+298 T 1061 \u001b[92m☑\u001b[0m Q 130+89  T 219  \u001b[92m☑\u001b[0m Q 898+197 T 1095 \u001b[92m☑\u001b[0m Q 0+326   T 326  \u001b[92m☑\u001b[0m Q 28+328  T 356  \u001b[92m☑\u001b[0m Q 547+3   T 550  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 84\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 8.1137e-04 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 0.9994\n",
      "Q 702+979 T 1681 \u001b[92m☑\u001b[0m Q 632+19  T 651  \u001b[92m☑\u001b[0m Q 30+390  T 420  \u001b[92m☑\u001b[0m Q 820+300 T 1120 \u001b[92m☑\u001b[0m Q 257+75  T 332  \u001b[92m☑\u001b[0m Q 549+92  T 641  \u001b[92m☑\u001b[0m Q 29+70   T 99   \u001b[92m☑\u001b[0m Q 841+42  T 883  \u001b[92m☑\u001b[0m Q 82+870  T 952  \u001b[92m☑\u001b[0m Q 911+38  T 949  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 85\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 7.1844e-04 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 0.9996\n",
      "Q 35+946  T 981  \u001b[92m☑\u001b[0m Q 47+845  T 892  \u001b[92m☑\u001b[0m Q 948+87  T 1035 \u001b[92m☑\u001b[0m Q 62+646  T 708  \u001b[92m☑\u001b[0m Q 405+54  T 459  \u001b[92m☑\u001b[0m Q 572+634 T 1206 \u001b[92m☑\u001b[0m Q 8+166   T 174  \u001b[92m☑\u001b[0m Q 45+56   T 101  \u001b[92m☑\u001b[0m Q 494+899 T 1393 \u001b[92m☑\u001b[0m Q 32+52   T 84   \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 86\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0012 - acc: 0.9998 - val_loss: 0.0082 - val_acc: 0.9972\n",
      "Q 227+914 T 1141 \u001b[92m☑\u001b[0m Q 639+6   T 645  \u001b[92m☑\u001b[0m Q 358+191 T 549  \u001b[92m☑\u001b[0m Q 287+797 T 1084 \u001b[92m☑\u001b[0m Q 621+54  T 675  \u001b[92m☑\u001b[0m Q 841+44  T 885  \u001b[92m☑\u001b[0m Q 253+136 T 389  \u001b[92m☑\u001b[0m Q 73+669  T 742  \u001b[92m☑\u001b[0m Q 48+947  T 995  \u001b[92m☑\u001b[0m Q 512+9   T 521  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 87\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0452 - acc: 0.9864 - val_loss: 0.0060 - val_acc: 0.9987\n",
      "Q 432+88  T 520  \u001b[92m☑\u001b[0m Q 337+0   T 337  \u001b[92m☑\u001b[0m Q 292+24  T 316  \u001b[92m☑\u001b[0m Q 393+17  T 410  \u001b[92m☑\u001b[0m Q 635+540 T 1175 \u001b[92m☑\u001b[0m Q 553+740 T 1293 \u001b[92m☑\u001b[0m Q 16+36   T 52   \u001b[92m☑\u001b[0m Q 67+150  T 217  \u001b[92m☑\u001b[0m Q 49+99   T 148  \u001b[92m☑\u001b[0m Q 303+795 T 1098 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 88\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0016 - acc: 0.9999 - val_loss: 0.0028 - val_acc: 0.9995\n",
      "Q 60+17   T 77   \u001b[92m☑\u001b[0m Q 24+227  T 251  \u001b[92m☑\u001b[0m Q 850+81  T 931  \u001b[92m☑\u001b[0m Q 127+545 T 672  \u001b[92m☑\u001b[0m Q 56+282  T 338  \u001b[92m☑\u001b[0m Q 65+662  T 727  \u001b[92m☑\u001b[0m Q 26+725  T 751  \u001b[92m☑\u001b[0m Q 549+3   T 552  \u001b[92m☑\u001b[0m Q 963+179 T 1142 \u001b[92m☑\u001b[0m Q 875+962 T 1837 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 89\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 9.6438e-04 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 0.9996\n",
      "Q 270+687 T 957  \u001b[92m☑\u001b[0m Q 67+456  T 523  \u001b[92m☑\u001b[0m Q 552+318 T 870  \u001b[92m☑\u001b[0m Q 161+7   T 168  \u001b[92m☑\u001b[0m Q 74+409  T 483  \u001b[92m☑\u001b[0m Q 61+78   T 139  \u001b[92m☑\u001b[0m Q 73+60   T 133  \u001b[92m☑\u001b[0m Q 73+260  T 333  \u001b[92m☑\u001b[0m Q 48+185  T 233  \u001b[92m☑\u001b[0m Q 690+91  T 781  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 90\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 7.8806e-04 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 0.9996\n",
      "Q 773+511 T 1284 \u001b[92m☑\u001b[0m Q 690+3   T 693  \u001b[92m☑\u001b[0m Q 52+60   T 112  \u001b[92m☑\u001b[0m Q 109+53  T 162  \u001b[92m☑\u001b[0m Q 832+81  T 913  \u001b[92m☑\u001b[0m Q 10+720  T 730  \u001b[92m☑\u001b[0m Q 96+968  T 1064 \u001b[92m☑\u001b[0m Q 1+440   T 441  \u001b[92m☑\u001b[0m Q 904+968 T 1872 \u001b[92m☑\u001b[0m Q 536+186 T 722  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 91\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 6.9665e-04 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 0.9994\n",
      "Q 9+725   T 734  \u001b[92m☑\u001b[0m Q 402+300 T 702  \u001b[92m☑\u001b[0m Q 166+87  T 253  \u001b[92m☑\u001b[0m Q 78+14   T 92   \u001b[92m☑\u001b[0m Q 227+914 T 1141 \u001b[92m☑\u001b[0m Q 673+48  T 721  \u001b[92m☑\u001b[0m Q 247+77  T 324  \u001b[92m☑\u001b[0m Q 7+118   T 125  \u001b[92m☑\u001b[0m Q 215+6   T 221  \u001b[92m☑\u001b[0m Q 96+948  T 1044 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 92\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 6.2176e-04 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 0.9995\n",
      "Q 250+299 T 549  \u001b[92m☑\u001b[0m Q 333+273 T 606  \u001b[92m☑\u001b[0m Q 8+4     T 12   \u001b[92m☑\u001b[0m Q 223+835 T 1058 \u001b[92m☑\u001b[0m Q 710+217 T 927  \u001b[92m☑\u001b[0m Q 435+7   T 442  \u001b[92m☑\u001b[0m Q 598+718 T 1316 \u001b[92m☑\u001b[0m Q 9+184   T 193  \u001b[92m☑\u001b[0m Q 36+7    T 43   \u001b[92m☑\u001b[0m Q 19+922  T 941  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 93\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 5s 101us/step - loss: 5.8933e-04 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 0.9995\n",
      "Q 1+518   T 519  \u001b[92m☑\u001b[0m Q 874+342 T 1216 \u001b[92m☑\u001b[0m Q 774+807 T 1581 \u001b[92m☑\u001b[0m Q 5+568   T 573  \u001b[92m☑\u001b[0m Q 88+65   T 153  \u001b[92m☑\u001b[0m Q 803+14  T 817  \u001b[92m☑\u001b[0m Q 622+814 T 1436 \u001b[92m☑\u001b[0m Q 227+603 T 830  \u001b[92m☑\u001b[0m Q 695+50  T 745  \u001b[92m☑\u001b[0m Q 880+54  T 934  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 94\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0130 - acc: 0.9964 - val_loss: 0.1569 - val_acc: 0.9524\n",
      "Q 59+463  T 522  \u001b[92m☑\u001b[0m Q 103+74  T 177  \u001b[92m☑\u001b[0m Q 526+398 T 924  \u001b[92m☑\u001b[0m Q 418+23  T 441  \u001b[92m☑\u001b[0m Q 275+11  T 286  \u001b[92m☑\u001b[0m Q 952+17  T 969  \u001b[92m☑\u001b[0m Q 82+112  T 194  \u001b[92m☑\u001b[0m Q 853+621 T 1474 \u001b[91m☒\u001b[0m Q 229+815 T 1044 \u001b[92m☑\u001b[0m Q 218+511 T 729  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 95\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 0.0231 - acc: 0.9932 - val_loss: 0.0040 - val_acc: 0.9994\n",
      "Q 3+933   T 936  \u001b[92m☑\u001b[0m Q 498+235 T 733  \u001b[92m☑\u001b[0m Q 596+61  T 657  \u001b[92m☑\u001b[0m Q 19+476  T 495  \u001b[92m☑\u001b[0m Q 537+0   T 537  \u001b[92m☑\u001b[0m Q 2+690   T 692  \u001b[92m☑\u001b[0m Q 33+387  T 420  \u001b[92m☑\u001b[0m Q 272+211 T 483  \u001b[92m☑\u001b[0m Q 59+42   T 101  \u001b[92m☑\u001b[0m Q 5+523   T 528  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 96\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 0.9996\n",
      "Q 491+3   T 494  \u001b[92m☑\u001b[0m Q 2+762   T 764  \u001b[92m☑\u001b[0m Q 10+829  T 839  \u001b[92m☑\u001b[0m Q 389+996 T 1385 \u001b[92m☑\u001b[0m Q 899+400 T 1299 \u001b[92m☑\u001b[0m Q 4+198   T 202  \u001b[92m☑\u001b[0m Q 8+724   T 732  \u001b[92m☑\u001b[0m Q 17+528  T 545  \u001b[92m☑\u001b[0m Q 65+153  T 218  \u001b[92m☑\u001b[0m Q 699+6   T 705  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 97\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 7.4669e-04 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 0.9996\n",
      "Q 234+12  T 246  \u001b[92m☑\u001b[0m Q 456+933 T 1389 \u001b[92m☑\u001b[0m Q 28+436  T 464  \u001b[92m☑\u001b[0m Q 66+985  T 1051 \u001b[92m☑\u001b[0m Q 842+6   T 848  \u001b[92m☑\u001b[0m Q 393+497 T 890  \u001b[92m☑\u001b[0m Q 789+16  T 805  \u001b[92m☑\u001b[0m Q 906+1   T 907  \u001b[92m☑\u001b[0m Q 290+629 T 919  \u001b[92m☑\u001b[0m Q 177+85  T 262  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 98\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 6.3131e-04 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 0.9996\n",
      "Q 38+400  T 438  \u001b[92m☑\u001b[0m Q 517+89  T 606  \u001b[92m☑\u001b[0m Q 231+11  T 242  \u001b[92m☑\u001b[0m Q 907+1   T 908  \u001b[92m☑\u001b[0m Q 72+55   T 127  \u001b[92m☑\u001b[0m Q 624+36  T 660  \u001b[92m☑\u001b[0m Q 278+473 T 751  \u001b[92m☑\u001b[0m Q 306+8   T 314  \u001b[92m☑\u001b[0m Q 803+630 T 1433 \u001b[92m☑\u001b[0m Q 80+846  T 926  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 99\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 5.6383e-04 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 0.9996\n",
      "Q 420+851 T 1271 \u001b[92m☑\u001b[0m Q 5+57    T 62   \u001b[92m☑\u001b[0m Q 637+5   T 642  \u001b[92m☑\u001b[0m Q 619+8   T 627  \u001b[92m☑\u001b[0m Q 585+497 T 1082 \u001b[92m☑\u001b[0m Q 27+24   T 51   \u001b[92m☑\u001b[0m Q 626+37  T 663  \u001b[92m☑\u001b[0m Q 121+29  T 150  \u001b[92m☑\u001b[0m Q 905+97  T 1002 \u001b[92m☑\u001b[0m Q 297+86  T 383  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 100\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 6.7258e-04 - acc: 0.9999 - val_loss: 0.0024 - val_acc: 0.9996\n",
      "Q 3+532   T 535  \u001b[92m☑\u001b[0m Q 278+473 T 751  \u001b[92m☑\u001b[0m Q 144+26  T 170  \u001b[92m☑\u001b[0m Q 394+63  T 457  \u001b[92m☑\u001b[0m Q 28+910  T 938  \u001b[92m☑\u001b[0m Q 695+50  T 745  \u001b[92m☑\u001b[0m Q 31+483  T 514  \u001b[92m☑\u001b[0m Q 2+972   T 974  \u001b[92m☑\u001b[0m Q 22+678  T 700  \u001b[92m☑\u001b[0m Q 98+137  T 235  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 101\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0194 - acc: 0.9940 - val_loss: 0.0466 - val_acc: 0.9830\n",
      "Q 383+355 T 738  \u001b[92m☑\u001b[0m Q 670+529 T 1199 \u001b[92m☑\u001b[0m Q 339+289 T 628  \u001b[92m☑\u001b[0m Q 13+929  T 942  \u001b[92m☑\u001b[0m Q 547+18  T 565  \u001b[92m☑\u001b[0m Q 396+81  T 477  \u001b[92m☑\u001b[0m Q 795+97  T 892  \u001b[92m☑\u001b[0m Q 78+408  T 486  \u001b[92m☑\u001b[0m Q 58+46   T 104  \u001b[92m☑\u001b[0m Q 10+872  T 882  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 102\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0196 - acc: 0.9945 - val_loss: 0.0037 - val_acc: 0.9993\n",
      "Q 235+50  T 285  \u001b[92m☑\u001b[0m Q 85+512  T 597  \u001b[92m☑\u001b[0m Q 954+631 T 1585 \u001b[92m☑\u001b[0m Q 3+933   T 936  \u001b[92m☑\u001b[0m Q 891+668 T 1559 \u001b[92m☑\u001b[0m Q 770+322 T 1092 \u001b[92m☑\u001b[0m Q 2+633   T 635  \u001b[92m☑\u001b[0m Q 328+71  T 399  \u001b[92m☑\u001b[0m Q 74+644  T 718  \u001b[92m☑\u001b[0m Q 117+46  T 163  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 103\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 0.9996\n",
      "Q 86+429  T 515  \u001b[92m☑\u001b[0m Q 99+182  T 281  \u001b[92m☑\u001b[0m Q 892+366 T 1258 \u001b[92m☑\u001b[0m Q 605+394 T 999  \u001b[92m☑\u001b[0m Q 238+93  T 331  \u001b[92m☑\u001b[0m Q 396+81  T 477  \u001b[92m☑\u001b[0m Q 6+835   T 841  \u001b[92m☑\u001b[0m Q 61+78   T 139  \u001b[92m☑\u001b[0m Q 740+699 T 1439 \u001b[92m☑\u001b[0m Q 63+178  T 241  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 104\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 6.8956e-04 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 0.9996\n",
      "Q 43+45   T 88   \u001b[92m☑\u001b[0m Q 83+618  T 701  \u001b[92m☑\u001b[0m Q 544+15  T 559  \u001b[92m☑\u001b[0m Q 296+241 T 537  \u001b[92m☑\u001b[0m Q 526+72  T 598  \u001b[92m☑\u001b[0m Q 67+656  T 723  \u001b[92m☑\u001b[0m Q 104+15  T 119  \u001b[92m☑\u001b[0m Q 604+260 T 864  \u001b[92m☑\u001b[0m Q 507+867 T 1374 \u001b[92m☑\u001b[0m Q 183+61  T 244  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 105\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 5.7517e-04 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 0.9997\n",
      "Q 926+8   T 934  \u001b[92m☑\u001b[0m Q 901+44  T 945  \u001b[92m☑\u001b[0m Q 26+6    T 32   \u001b[92m☑\u001b[0m Q 73+707  T 780  \u001b[92m☑\u001b[0m Q 53+22   T 75   \u001b[92m☑\u001b[0m Q 41+407  T 448  \u001b[92m☑\u001b[0m Q 11+431  T 442  \u001b[92m☑\u001b[0m Q 94+821  T 915  \u001b[92m☑\u001b[0m Q 877+206 T 1083 \u001b[92m☑\u001b[0m Q 280+97  T 377  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 106\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 5.1156e-04 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 0.9996\n",
      "Q 40+85   T 125  \u001b[92m☑\u001b[0m Q 297+742 T 1039 \u001b[92m☑\u001b[0m Q 561+69  T 630  \u001b[92m☑\u001b[0m Q 367+58  T 425  \u001b[92m☑\u001b[0m Q 851+92  T 943  \u001b[92m☑\u001b[0m Q 63+794  T 857  \u001b[92m☑\u001b[0m Q 200+736 T 936  \u001b[92m☑\u001b[0m Q 606+67  T 673  \u001b[92m☑\u001b[0m Q 192+516 T 708  \u001b[92m☑\u001b[0m Q 563+25  T 588  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 107\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 4.6194e-04 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9996\n",
      "Q 973+814 T 1787 \u001b[92m☑\u001b[0m Q 877+21  T 898  \u001b[92m☑\u001b[0m Q 260+213 T 473  \u001b[92m☑\u001b[0m Q 846+73  T 919  \u001b[92m☑\u001b[0m Q 351+718 T 1069 \u001b[92m☑\u001b[0m Q 70+986  T 1056 \u001b[92m☑\u001b[0m Q 34+86   T 120  \u001b[92m☑\u001b[0m Q 559+85  T 644  \u001b[92m☑\u001b[0m Q 85+605  T 690  \u001b[92m☑\u001b[0m Q 48+545  T 593  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 108\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 4.1488e-04 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 0.9997\n",
      "Q 83+199  T 282  \u001b[92m☑\u001b[0m Q 98+76   T 174  \u001b[92m☑\u001b[0m Q 369+476 T 845  \u001b[92m☑\u001b[0m Q 841+20  T 861  \u001b[92m☑\u001b[0m Q 1+189   T 190  \u001b[92m☑\u001b[0m Q 305+4   T 309  \u001b[92m☑\u001b[0m Q 281+884 T 1165 \u001b[92m☑\u001b[0m Q 369+61  T 430  \u001b[92m☑\u001b[0m Q 80+775  T 855  \u001b[92m☑\u001b[0m Q 441+768 T 1209 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 109\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 3.9230e-04 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 0.9994\n",
      "Q 30+170  T 200  \u001b[92m☑\u001b[0m Q 478+14  T 492  \u001b[92m☑\u001b[0m Q 665+755 T 1420 \u001b[92m☑\u001b[0m Q 672+557 T 1229 \u001b[92m☑\u001b[0m Q 57+882  T 939  \u001b[92m☑\u001b[0m Q 73+646  T 719  \u001b[92m☑\u001b[0m Q 693+649 T 1342 \u001b[92m☑\u001b[0m Q 273+63  T 336  \u001b[92m☑\u001b[0m Q 942+85  T 1027 \u001b[92m☑\u001b[0m Q 80+775  T 855  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 110\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0287 - acc: 0.9915 - val_loss: 0.0039 - val_acc: 0.9993\n",
      "Q 238+69  T 307  \u001b[92m☑\u001b[0m Q 38+704  T 742  \u001b[92m☑\u001b[0m Q 86+785  T 871  \u001b[92m☑\u001b[0m Q 441+691 T 1132 \u001b[92m☑\u001b[0m Q 904+387 T 1291 \u001b[92m☑\u001b[0m Q 3+306   T 309  \u001b[92m☑\u001b[0m Q 907+1   T 908  \u001b[92m☑\u001b[0m Q 629+741 T 1370 \u001b[92m☑\u001b[0m Q 974+41  T 1015 \u001b[92m☑\u001b[0m Q 866+6   T 872  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 111\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 0.9994\n",
      "Q 667+88  T 755  \u001b[92m☑\u001b[0m Q 873+93  T 966  \u001b[92m☑\u001b[0m Q 52+404  T 456  \u001b[92m☑\u001b[0m Q 996+75  T 1071 \u001b[92m☑\u001b[0m Q 358+814 T 1172 \u001b[92m☑\u001b[0m Q 36+40   T 76   \u001b[92m☑\u001b[0m Q 11+19   T 30   \u001b[92m☑\u001b[0m Q 888+718 T 1606 \u001b[92m☑\u001b[0m Q 2+122   T 124  \u001b[92m☑\u001b[0m Q 91+821  T 912  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 112\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 6.4008e-04 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 0.9996\n",
      "Q 24+744  T 768  \u001b[92m☑\u001b[0m Q 541+9   T 550  \u001b[92m☑\u001b[0m Q 73+944  T 1017 \u001b[92m☑\u001b[0m Q 88+446  T 534  \u001b[92m☑\u001b[0m Q 796+599 T 1395 \u001b[92m☑\u001b[0m Q 60+442  T 502  \u001b[92m☑\u001b[0m Q 778+137 T 915  \u001b[92m☑\u001b[0m Q 556+70  T 626  \u001b[92m☑\u001b[0m Q 91+858  T 949  \u001b[92m☑\u001b[0m Q 861+487 T 1348 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 113\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 5.0590e-04 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 0.9995\n",
      "Q 12+92   T 104  \u001b[92m☑\u001b[0m Q 573+696 T 1269 \u001b[92m☑\u001b[0m Q 189+74  T 263  \u001b[92m☑\u001b[0m Q 37+64   T 101  \u001b[92m☑\u001b[0m Q 335+199 T 534  \u001b[92m☑\u001b[0m Q 94+911  T 1005 \u001b[92m☑\u001b[0m Q 3+115   T 118  \u001b[92m☑\u001b[0m Q 88+15   T 103  \u001b[92m☑\u001b[0m Q 788+350 T 1138 \u001b[92m☑\u001b[0m Q 617+514 T 1131 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 114\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 4.4814e-04 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 0.9994\n",
      "Q 785+13  T 798  \u001b[92m☑\u001b[0m Q 94+56   T 150  \u001b[92m☑\u001b[0m Q 665+41  T 706  \u001b[92m☑\u001b[0m Q 317+750 T 1067 \u001b[92m☑\u001b[0m Q 828+488 T 1316 \u001b[92m☑\u001b[0m Q 884+55  T 939  \u001b[92m☑\u001b[0m Q 28+75   T 103  \u001b[92m☑\u001b[0m Q 4+372   T 376  \u001b[92m☑\u001b[0m Q 23+357  T 380  \u001b[92m☑\u001b[0m Q 367+58  T 425  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 115\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 3.9156e-04 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 0.9995\n",
      "Q 817+17  T 834  \u001b[92m☑\u001b[0m Q 812+167 T 979  \u001b[92m☑\u001b[0m Q 786+52  T 838  \u001b[92m☑\u001b[0m Q 54+167  T 221  \u001b[92m☑\u001b[0m Q 250+177 T 427  \u001b[92m☑\u001b[0m Q 43+234  T 277  \u001b[92m☑\u001b[0m Q 710+37  T 747  \u001b[92m☑\u001b[0m Q 96+80   T 176  \u001b[92m☑\u001b[0m Q 879+536 T 1415 \u001b[92m☑\u001b[0m Q 99+478  T 577  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 116\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 3.4414e-04 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 0.9995\n",
      "Q 215+983 T 1198 \u001b[91m☒\u001b[0m Q 17+415  T 432  \u001b[92m☑\u001b[0m Q 37+65   T 102  \u001b[92m☑\u001b[0m Q 19+693  T 712  \u001b[92m☑\u001b[0m Q 73+884  T 957  \u001b[92m☑\u001b[0m Q 429+465 T 894  \u001b[92m☑\u001b[0m Q 455+30  T 485  \u001b[92m☑\u001b[0m Q 809+767 T 1576 \u001b[92m☑\u001b[0m Q 3+36    T 39   \u001b[92m☑\u001b[0m Q 11+10   T 21   \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 117\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 3.0804e-04 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9996\n",
      "Q 29+590  T 619  \u001b[92m☑\u001b[0m Q 768+94  T 862  \u001b[92m☑\u001b[0m Q 137+680 T 817  \u001b[92m☑\u001b[0m Q 98+484  T 582  \u001b[92m☑\u001b[0m Q 128+987 T 1115 \u001b[92m☑\u001b[0m Q 9+800   T 809  \u001b[92m☑\u001b[0m Q 152+913 T 1065 \u001b[92m☑\u001b[0m Q 710+74  T 784  \u001b[92m☑\u001b[0m Q 66+817  T 883  \u001b[92m☑\u001b[0m Q 96+853  T 949  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 118\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 2.8470e-04 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9996\n",
      "Q 68+776  T 844  \u001b[92m☑\u001b[0m Q 72+974  T 1046 \u001b[92m☑\u001b[0m Q 96+853  T 949  \u001b[92m☑\u001b[0m Q 542+40  T 582  \u001b[92m☑\u001b[0m Q 956+3   T 959  \u001b[92m☑\u001b[0m Q 43+532  T 575  \u001b[92m☑\u001b[0m Q 280+97  T 377  \u001b[92m☑\u001b[0m Q 75+147  T 222  \u001b[92m☑\u001b[0m Q 1+518   T 519  \u001b[92m☑\u001b[0m Q 906+2   T 908  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 119\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0378 - acc: 0.9887 - val_loss: 0.0123 - val_acc: 0.9965\n",
      "Q 28+35   T 63   \u001b[92m☑\u001b[0m Q 142+34  T 176  \u001b[92m☑\u001b[0m Q 88+178  T 266  \u001b[92m☑\u001b[0m Q 414+85  T 499  \u001b[92m☑\u001b[0m Q 768+744 T 1512 \u001b[92m☑\u001b[0m Q 76+257  T 333  \u001b[92m☑\u001b[0m Q 42+91   T 133  \u001b[92m☑\u001b[0m Q 58+481  T 539  \u001b[92m☑\u001b[0m Q 959+13  T 972  \u001b[92m☑\u001b[0m Q 296+432 T 728  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 120\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0028 - acc: 0.9995 - val_loss: 0.0063 - val_acc: 0.9983\n",
      "Q 5+385   T 390  \u001b[92m☑\u001b[0m Q 975+498 T 1473 \u001b[91m☒\u001b[0m Q 714+38  T 752  \u001b[92m☑\u001b[0m Q 11+19   T 30   \u001b[92m☑\u001b[0m Q 52+25   T 77   \u001b[92m☑\u001b[0m Q 705+3   T 708  \u001b[92m☑\u001b[0m Q 91+493  T 584  \u001b[92m☑\u001b[0m Q 429+51  T 480  \u001b[92m☑\u001b[0m Q 848+894 T 1742 \u001b[92m☑\u001b[0m Q 4+600   T 604  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 121\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.0014 - acc: 0.9998 - val_loss: 0.0024 - val_acc: 0.9994\n",
      "Q 749+56  T 805  \u001b[92m☑\u001b[0m Q 22+849  T 871  \u001b[92m☑\u001b[0m Q 451+0   T 451  \u001b[92m☑\u001b[0m Q 765+70  T 835  \u001b[92m☑\u001b[0m Q 74+270  T 344  \u001b[92m☑\u001b[0m Q 468+2   T 470  \u001b[92m☑\u001b[0m Q 999+63  T 1062 \u001b[92m☑\u001b[0m Q 725+121 T 846  \u001b[92m☑\u001b[0m Q 264+68  T 332  \u001b[92m☑\u001b[0m Q 1+288   T 289  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 122\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 5.1667e-04 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 0.9994\n",
      "Q 798+805 T 1603 \u001b[92m☑\u001b[0m Q 274+52  T 326  \u001b[92m☑\u001b[0m Q 964+14  T 978  \u001b[92m☑\u001b[0m Q 271+301 T 572  \u001b[92m☑\u001b[0m Q 362+899 T 1261 \u001b[92m☑\u001b[0m Q 0+158   T 158  \u001b[92m☑\u001b[0m Q 606+7   T 613  \u001b[92m☑\u001b[0m Q 18+94   T 112  \u001b[92m☑\u001b[0m Q 38+704  T 742  \u001b[92m☑\u001b[0m Q 8+398   T 406  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 123\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 4.2753e-04 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 0.9996\n",
      "Q 994+91  T 1085 \u001b[92m☑\u001b[0m Q 82+149  T 231  \u001b[92m☑\u001b[0m Q 9+105   T 114  \u001b[92m☑\u001b[0m Q 5+276   T 281  \u001b[92m☑\u001b[0m Q 629+741 T 1370 \u001b[92m☑\u001b[0m Q 57+98   T 155  \u001b[92m☑\u001b[0m Q 50+81   T 131  \u001b[92m☑\u001b[0m Q 13+9    T 22   \u001b[92m☑\u001b[0m Q 6+48    T 54   \u001b[92m☑\u001b[0m Q 37+363  T 400  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 124\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 5s 101us/step - loss: 3.7567e-04 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9997\n",
      "Q 463+497 T 960  \u001b[92m☑\u001b[0m Q 620+5   T 625  \u001b[92m☑\u001b[0m Q 804+0   T 804  \u001b[92m☑\u001b[0m Q 73+353  T 426  \u001b[92m☑\u001b[0m Q 63+43   T 106  \u001b[92m☑\u001b[0m Q 86+155  T 241  \u001b[92m☑\u001b[0m Q 27+1    T 28   \u001b[92m☑\u001b[0m Q 978+27  T 1005 \u001b[92m☑\u001b[0m Q 400+597 T 997  \u001b[92m☑\u001b[0m Q 85+605  T 690  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 125\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 3.3243e-04 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9997\n",
      "Q 9+800   T 809  \u001b[92m☑\u001b[0m Q 772+860 T 1632 \u001b[92m☑\u001b[0m Q 123+87  T 210  \u001b[92m☑\u001b[0m Q 91+605  T 696  \u001b[92m☑\u001b[0m Q 14+10   T 24   \u001b[92m☑\u001b[0m Q 25+960  T 985  \u001b[92m☑\u001b[0m Q 410+37  T 447  \u001b[92m☑\u001b[0m Q 88+85   T 173  \u001b[92m☑\u001b[0m Q 435+34  T 469  \u001b[92m☑\u001b[0m Q 961+828 T 1789 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 126\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 100us/step - loss: 4.9742e-04 - acc: 0.9999 - val_loss: 0.0023 - val_acc: 0.9994\n",
      "Q 952+2   T 954  \u001b[92m☑\u001b[0m Q 423+491 T 914  \u001b[92m☑\u001b[0m Q 127+153 T 280  \u001b[92m☑\u001b[0m Q 79+18   T 97   \u001b[92m☑\u001b[0m Q 46+911  T 957  \u001b[92m☑\u001b[0m Q 716+915 T 1631 \u001b[92m☑\u001b[0m Q 43+732  T 775  \u001b[92m☑\u001b[0m Q 869+778 T 1647 \u001b[92m☑\u001b[0m Q 93+266  T 359  \u001b[92m☑\u001b[0m Q 485+7   T 492  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 127\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 6.2542e-04 - acc: 0.9999 - val_loss: 0.0038 - val_acc: 0.9990\n",
      "Q 869+272 T 1141 \u001b[92m☑\u001b[0m Q 130+42  T 172  \u001b[92m☑\u001b[0m Q 556+45  T 601  \u001b[92m☑\u001b[0m Q 68+733  T 801  \u001b[92m☑\u001b[0m Q 918+778 T 1696 \u001b[92m☑\u001b[0m Q 23+123  T 146  \u001b[92m☑\u001b[0m Q 638+311 T 949  \u001b[92m☑\u001b[0m Q 173+174 T 347  \u001b[92m☑\u001b[0m Q 40+218  T 258  \u001b[92m☑\u001b[0m Q 2+122   T 124  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 128\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 0.0293 - acc: 0.9918 - val_loss: 0.0051 - val_acc: 0.9987\n",
      "Q 974+7   T 981  \u001b[92m☑\u001b[0m Q 79+465  T 544  \u001b[92m☑\u001b[0m Q 721+317 T 1038 \u001b[92m☑\u001b[0m Q 82+295  T 377  \u001b[92m☑\u001b[0m Q 144+921 T 1065 \u001b[92m☑\u001b[0m Q 392+138 T 530  \u001b[92m☑\u001b[0m Q 35+634  T 669  \u001b[92m☑\u001b[0m Q 60+236  T 296  \u001b[92m☑\u001b[0m Q 551+9   T 560  \u001b[92m☑\u001b[0m Q 958+56  T 1014 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 129\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 100us/step - loss: 8.4501e-04 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 0.9995\n",
      "Q 86+70   T 156  \u001b[92m☑\u001b[0m Q 71+109  T 180  \u001b[92m☑\u001b[0m Q 157+977 T 1134 \u001b[92m☑\u001b[0m Q 4+688   T 692  \u001b[92m☑\u001b[0m Q 57+98   T 155  \u001b[92m☑\u001b[0m Q 349+588 T 937  \u001b[92m☑\u001b[0m Q 997+33  T 1030 \u001b[92m☑\u001b[0m Q 457+3   T 460  \u001b[92m☑\u001b[0m Q 534+821 T 1355 \u001b[92m☑\u001b[0m Q 49+975  T 1024 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 130\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 4.9240e-04 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 0.9994\n",
      "Q 469+789 T 1258 \u001b[92m☑\u001b[0m Q 623+7   T 630  \u001b[92m☑\u001b[0m Q 830+48  T 878  \u001b[92m☑\u001b[0m Q 8+993   T 1001 \u001b[92m☑\u001b[0m Q 679+407 T 1086 \u001b[92m☑\u001b[0m Q 470+8   T 478  \u001b[92m☑\u001b[0m Q 5+39    T 44   \u001b[92m☑\u001b[0m Q 423+491 T 914  \u001b[92m☑\u001b[0m Q 601+120 T 721  \u001b[92m☑\u001b[0m Q 99+55   T 154  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 131\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 100us/step - loss: 4.0165e-04 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 0.9995\n",
      "Q 497+783 T 1280 \u001b[92m☑\u001b[0m Q 91+605  T 696  \u001b[92m☑\u001b[0m Q 433+703 T 1136 \u001b[92m☑\u001b[0m Q 21+26   T 47   \u001b[92m☑\u001b[0m Q 594+87  T 681  \u001b[92m☑\u001b[0m Q 843+779 T 1622 \u001b[92m☑\u001b[0m Q 19+189  T 208  \u001b[92m☑\u001b[0m Q 851+4   T 855  \u001b[92m☑\u001b[0m Q 549+44  T 593  \u001b[92m☑\u001b[0m Q 110+425 T 535  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 132\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 3.4588e-04 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 0.9995\n",
      "Q 12+995  T 1007 \u001b[92m☑\u001b[0m Q 627+89  T 716  \u001b[92m☑\u001b[0m Q 298+99  T 397  \u001b[91m☒\u001b[0m Q 551+74  T 625  \u001b[92m☑\u001b[0m Q 726+672 T 1398 \u001b[92m☑\u001b[0m Q 837+492 T 1329 \u001b[92m☑\u001b[0m Q 858+44  T 902  \u001b[92m☑\u001b[0m Q 57+707  T 764  \u001b[92m☑\u001b[0m Q 126+649 T 775  \u001b[92m☑\u001b[0m Q 972+72  T 1044 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 133\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 3.0550e-04 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9996\n",
      "Q 632+0   T 632  \u001b[92m☑\u001b[0m Q 84+11   T 95   \u001b[92m☑\u001b[0m Q 411+89  T 500  \u001b[92m☑\u001b[0m Q 117+46  T 163  \u001b[92m☑\u001b[0m Q 692+307 T 999  \u001b[92m☑\u001b[0m Q 196+0   T 196  \u001b[92m☑\u001b[0m Q 700+533 T 1233 \u001b[92m☑\u001b[0m Q 825+3   T 828  \u001b[92m☑\u001b[0m Q 737+67  T 804  \u001b[92m☑\u001b[0m Q 104+15  T 119  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 134\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 2.7152e-04 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 0.9995\n",
      "Q 460+902 T 1362 \u001b[92m☑\u001b[0m Q 355+32  T 387  \u001b[92m☑\u001b[0m Q 99+946  T 1045 \u001b[92m☑\u001b[0m Q 481+33  T 514  \u001b[92m☑\u001b[0m Q 74+91   T 165  \u001b[92m☑\u001b[0m Q 581+2   T 583  \u001b[92m☑\u001b[0m Q 623+7   T 630  \u001b[92m☑\u001b[0m Q 112+325 T 437  \u001b[92m☑\u001b[0m Q 594+2   T 596  \u001b[92m☑\u001b[0m Q 310+685 T 995  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 135\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 2.4669e-04 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 0.9996\n",
      "Q 3+125   T 128  \u001b[92m☑\u001b[0m Q 58+491  T 549  \u001b[92m☑\u001b[0m Q 98+484  T 582  \u001b[92m☑\u001b[0m Q 596+483 T 1079 \u001b[92m☑\u001b[0m Q 755+30  T 785  \u001b[92m☑\u001b[0m Q 462+5   T 467  \u001b[92m☑\u001b[0m Q 334+929 T 1263 \u001b[92m☑\u001b[0m Q 451+7   T 458  \u001b[92m☑\u001b[0m Q 45+11   T 56   \u001b[92m☑\u001b[0m Q 12+475  T 487  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 136\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 2.2055e-04 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 0.9996\n",
      "Q 575+86  T 661  \u001b[92m☑\u001b[0m Q 402+300 T 702  \u001b[92m☑\u001b[0m Q 82+20   T 102  \u001b[92m☑\u001b[0m Q 9+166   T 175  \u001b[92m☑\u001b[0m Q 669+94  T 763  \u001b[92m☑\u001b[0m Q 7+753   T 760  \u001b[92m☑\u001b[0m Q 25+825  T 850  \u001b[92m☑\u001b[0m Q 9+47    T 56   \u001b[92m☑\u001b[0m Q 211+2   T 213  \u001b[92m☑\u001b[0m Q 208+65  T 273  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 137\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 100us/step - loss: 2.0157e-04 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 0.9997\n",
      "Q 390+7   T 397  \u001b[92m☑\u001b[0m Q 67+488  T 555  \u001b[92m☑\u001b[0m Q 411+89  T 500  \u001b[92m☑\u001b[0m Q 295+8   T 303  \u001b[92m☑\u001b[0m Q 750+136 T 886  \u001b[92m☑\u001b[0m Q 420+417 T 837  \u001b[92m☑\u001b[0m Q 17+216  T 233  \u001b[92m☑\u001b[0m Q 7+655   T 662  \u001b[92m☑\u001b[0m Q 667+495 T 1162 \u001b[92m☑\u001b[0m Q 3+306   T 309  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 138\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 0.0317 - acc: 0.9914 - val_loss: 0.0231 - val_acc: 0.9933\n",
      "Q 2+394   T 396  \u001b[92m☑\u001b[0m Q 770+26  T 796  \u001b[92m☑\u001b[0m Q 6+587   T 593  \u001b[92m☑\u001b[0m Q 67+972  T 1039 \u001b[92m☑\u001b[0m Q 227+586 T 813  \u001b[92m☑\u001b[0m Q 961+2   T 963  \u001b[92m☑\u001b[0m Q 924+45  T 969  \u001b[92m☑\u001b[0m Q 493+59  T 552  \u001b[92m☑\u001b[0m Q 5+796   T 801  \u001b[92m☑\u001b[0m Q 70+407  T 477  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 139\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 0.0038 - acc: 0.9991 - val_loss: 0.0022 - val_acc: 0.9996\n",
      "Q 330+717 T 1047 \u001b[92m☑\u001b[0m Q 258+13  T 271  \u001b[92m☑\u001b[0m Q 656+72  T 728  \u001b[92m☑\u001b[0m Q 367+56  T 423  \u001b[92m☑\u001b[0m Q 82+911  T 993  \u001b[92m☑\u001b[0m Q 732+55  T 787  \u001b[92m☑\u001b[0m Q 278+479 T 757  \u001b[92m☑\u001b[0m Q 352+167 T 519  \u001b[92m☑\u001b[0m Q 758+271 T 1029 \u001b[92m☑\u001b[0m Q 141+26  T 167  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 140\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 5s 100us/step - loss: 5.7683e-04 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 0.9996\n",
      "Q 275+6   T 281  \u001b[92m☑\u001b[0m Q 72+55   T 127  \u001b[92m☑\u001b[0m Q 453+44  T 497  \u001b[92m☑\u001b[0m Q 12+392  T 404  \u001b[92m☑\u001b[0m Q 30+302  T 332  \u001b[92m☑\u001b[0m Q 350+496 T 846  \u001b[92m☑\u001b[0m Q 588+367 T 955  \u001b[92m☑\u001b[0m Q 81+308  T 389  \u001b[92m☑\u001b[0m Q 300+58  T 358  \u001b[92m☑\u001b[0m Q 669+409 T 1078 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 141\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 100us/step - loss: 6.4655e-04 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9996\n",
      "Q 53+22   T 75   \u001b[92m☑\u001b[0m Q 752+261 T 1013 \u001b[92m☑\u001b[0m Q 679+3   T 682  \u001b[92m☑\u001b[0m Q 650+998 T 1648 \u001b[92m☑\u001b[0m Q 679+192 T 871  \u001b[92m☑\u001b[0m Q 863+601 T 1464 \u001b[92m☑\u001b[0m Q 3+94    T 97   \u001b[92m☑\u001b[0m Q 964+110 T 1074 \u001b[92m☑\u001b[0m Q 171+23  T 194  \u001b[92m☑\u001b[0m Q 107+50  T 157  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 142\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 100us/step - loss: 3.5080e-04 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 0.9997\n",
      "Q 442+66  T 508  \u001b[92m☑\u001b[0m Q 215+6   T 221  \u001b[92m☑\u001b[0m Q 779+50  T 829  \u001b[92m☑\u001b[0m Q 585+973 T 1558 \u001b[92m☑\u001b[0m Q 340+924 T 1264 \u001b[92m☑\u001b[0m Q 906+1   T 907  \u001b[92m☑\u001b[0m Q 48+23   T 71   \u001b[92m☑\u001b[0m Q 3+36    T 39   \u001b[92m☑\u001b[0m Q 742+311 T 1053 \u001b[92m☑\u001b[0m Q 375+515 T 890  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 143\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 2.9650e-04 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 0.9997\n",
      "Q 892+228 T 1120 \u001b[92m☑\u001b[0m Q 902+7   T 909  \u001b[92m☑\u001b[0m Q 640+23  T 663  \u001b[92m☑\u001b[0m Q 68+988  T 1056 \u001b[92m☑\u001b[0m Q 11+957  T 968  \u001b[92m☑\u001b[0m Q 615+741 T 1356 \u001b[92m☑\u001b[0m Q 691+822 T 1513 \u001b[92m☑\u001b[0m Q 89+410  T 499  \u001b[92m☑\u001b[0m Q 665+41  T 706  \u001b[92m☑\u001b[0m Q 603+610 T 1213 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 144\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 100us/step - loss: 2.6126e-04 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 0.9997\n",
      "Q 178+70  T 248  \u001b[92m☑\u001b[0m Q 55+342  T 397  \u001b[92m☑\u001b[0m Q 598+718 T 1316 \u001b[92m☑\u001b[0m Q 3+75    T 78   \u001b[92m☑\u001b[0m Q 572+634 T 1206 \u001b[92m☑\u001b[0m Q 89+576  T 665  \u001b[92m☑\u001b[0m Q 71+298  T 369  \u001b[92m☑\u001b[0m Q 379+233 T 612  \u001b[92m☑\u001b[0m Q 80+52   T 132  \u001b[92m☑\u001b[0m Q 9+811   T 820  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 145\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 2.3367e-04 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 0.9997\n",
      "Q 75+959  T 1034 \u001b[92m☑\u001b[0m Q 83+77   T 160  \u001b[92m☑\u001b[0m Q 146+67  T 213  \u001b[92m☑\u001b[0m Q 52+567  T 619  \u001b[92m☑\u001b[0m Q 214+57  T 271  \u001b[92m☑\u001b[0m Q 40+85   T 125  \u001b[92m☑\u001b[0m Q 66+8    T 74   \u001b[92m☑\u001b[0m Q 29+14   T 43   \u001b[92m☑\u001b[0m Q 42+406  T 448  \u001b[92m☑\u001b[0m Q 926+8   T 934  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 146\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 2.1029e-04 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 0.9997\n",
      "Q 86+35   T 121  \u001b[92m☑\u001b[0m Q 184+81  T 265  \u001b[92m☑\u001b[0m Q 50+199  T 249  \u001b[92m☑\u001b[0m Q 93+78   T 171  \u001b[92m☑\u001b[0m Q 30+990  T 1020 \u001b[92m☑\u001b[0m Q 89+12   T 101  \u001b[92m☑\u001b[0m Q 9+277   T 286  \u001b[92m☑\u001b[0m Q 672+557 T 1229 \u001b[92m☑\u001b[0m Q 575+71  T 646  \u001b[92m☑\u001b[0m Q 66+714  T 780  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 147\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 100us/step - loss: 1.9082e-04 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 0.9998\n",
      "Q 203+91  T 294  \u001b[92m☑\u001b[0m Q 423+491 T 914  \u001b[92m☑\u001b[0m Q 621+556 T 1177 \u001b[92m☑\u001b[0m Q 13+315  T 328  \u001b[92m☑\u001b[0m Q 95+164  T 259  \u001b[92m☑\u001b[0m Q 1+288   T 289  \u001b[92m☑\u001b[0m Q 96+926  T 1022 \u001b[92m☑\u001b[0m Q 954+631 T 1585 \u001b[92m☑\u001b[0m Q 75+147  T 222  \u001b[92m☑\u001b[0m Q 16+597  T 613  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 148\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 100us/step - loss: 1.7249e-04 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 0.9998\n",
      "Q 35+84   T 119  \u001b[92m☑\u001b[0m Q 83+558  T 641  \u001b[92m☑\u001b[0m Q 222+42  T 264  \u001b[92m☑\u001b[0m Q 566+394 T 960  \u001b[92m☑\u001b[0m Q 187+3   T 190  \u001b[92m☑\u001b[0m Q 162+98  T 260  \u001b[92m☑\u001b[0m Q 75+42   T 117  \u001b[92m☑\u001b[0m Q 57+707  T 764  \u001b[92m☑\u001b[0m Q 715+798 T 1513 \u001b[92m☑\u001b[0m Q 842+6   T 848  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 149\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 100us/step - loss: 1.6317e-04 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 0.9997\n",
      "Q 911+5   T 916  \u001b[92m☑\u001b[0m Q 6+641   T 647  \u001b[92m☑\u001b[0m Q 741+3   T 744  \u001b[92m☑\u001b[0m Q 96+152  T 248  \u001b[92m☑\u001b[0m Q 853+621 T 1474 \u001b[92m☑\u001b[0m Q 292+24  T 316  \u001b[92m☑\u001b[0m Q 304+352 T 656  \u001b[92m☑\u001b[0m Q 25+637  T 662  \u001b[92m☑\u001b[0m Q 363+633 T 996  \u001b[92m☑\u001b[0m Q 29+286  T 315  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 150\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 0.0295 - acc: 0.9920 - val_loss: 0.0048 - val_acc: 0.9990\n",
      "Q 39+222  T 261  \u001b[92m☑\u001b[0m Q 208+443 T 651  \u001b[92m☑\u001b[0m Q 999+63  T 1062 \u001b[92m☑\u001b[0m Q 682+74  T 756  \u001b[92m☑\u001b[0m Q 605+80  T 685  \u001b[92m☑\u001b[0m Q 468+2   T 470  \u001b[92m☑\u001b[0m Q 426+351 T 777  \u001b[92m☑\u001b[0m Q 87+328  T 415  \u001b[92m☑\u001b[0m Q 462+5   T 467  \u001b[92m☑\u001b[0m Q 321+10  T 331  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 151\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 100us/step - loss: 0.0013 - acc: 0.9998 - val_loss: 0.0024 - val_acc: 0.9993\n",
      "Q 188+783 T 971  \u001b[92m☑\u001b[0m Q 68+990  T 1058 \u001b[92m☑\u001b[0m Q 802+75  T 877  \u001b[92m☑\u001b[0m Q 94+821  T 915  \u001b[92m☑\u001b[0m Q 210+854 T 1064 \u001b[92m☑\u001b[0m Q 553+740 T 1293 \u001b[92m☑\u001b[0m Q 3+326   T 329  \u001b[92m☑\u001b[0m Q 448+0   T 448  \u001b[92m☑\u001b[0m Q 65+51   T 116  \u001b[92m☑\u001b[0m Q 59+578  T 637  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 152\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 4.1194e-04 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 0.9994\n",
      "Q 632+0   T 632  \u001b[92m☑\u001b[0m Q 50+900  T 950  \u001b[92m☑\u001b[0m Q 633+38  T 671  \u001b[92m☑\u001b[0m Q 54+629  T 683  \u001b[92m☑\u001b[0m Q 871+46  T 917  \u001b[92m☑\u001b[0m Q 266+637 T 903  \u001b[92m☑\u001b[0m Q 22+18   T 40   \u001b[92m☑\u001b[0m Q 764+117 T 881  \u001b[92m☑\u001b[0m Q 39+557  T 596  \u001b[92m☑\u001b[0m Q 75+975  T 1050 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 153\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 100us/step - loss: 3.1279e-04 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9995\n",
      "Q 753+348 T 1101 \u001b[92m☑\u001b[0m Q 73+325  T 398  \u001b[92m☑\u001b[0m Q 9+672   T 681  \u001b[92m☑\u001b[0m Q 256+68  T 324  \u001b[92m☑\u001b[0m Q 72+974  T 1046 \u001b[92m☑\u001b[0m Q 501+47  T 548  \u001b[92m☑\u001b[0m Q 994+9   T 1003 \u001b[92m☑\u001b[0m Q 216+46  T 262  \u001b[92m☑\u001b[0m Q 6+113   T 119  \u001b[92m☑\u001b[0m Q 906+486 T 1392 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 154\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 100us/step - loss: 2.6716e-04 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9996\n",
      "Q 847+358 T 1205 \u001b[92m☑\u001b[0m Q 95+565  T 660  \u001b[92m☑\u001b[0m Q 336+827 T 1163 \u001b[92m☑\u001b[0m Q 986+74  T 1060 \u001b[92m☑\u001b[0m Q 832+81  T 913  \u001b[92m☑\u001b[0m Q 12+535  T 547  \u001b[92m☑\u001b[0m Q 164+0   T 164  \u001b[92m☑\u001b[0m Q 94+911  T 1005 \u001b[92m☑\u001b[0m Q 38+834  T 872  \u001b[92m☑\u001b[0m Q 736+99  T 835  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 155\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 100us/step - loss: 2.3419e-04 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9996\n",
      "Q 73+669  T 742  \u001b[92m☑\u001b[0m Q 30+769  T 799  \u001b[92m☑\u001b[0m Q 91+36   T 127  \u001b[92m☑\u001b[0m Q 17+189  T 206  \u001b[92m☑\u001b[0m Q 846+79  T 925  \u001b[92m☑\u001b[0m Q 842+60  T 902  \u001b[92m☑\u001b[0m Q 151+35  T 186  \u001b[92m☑\u001b[0m Q 152+913 T 1065 \u001b[92m☑\u001b[0m Q 35+25   T 60   \u001b[92m☑\u001b[0m Q 77+29   T 106  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 156\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 4s 100us/step - loss: 2.0895e-04 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 0.9996\n",
      "Q 837+664 T 1501 \u001b[92m☑\u001b[0m Q 6+150   T 156  \u001b[92m☑\u001b[0m Q 90+901  T 991  \u001b[92m☑\u001b[0m Q 2+424   T 426  \u001b[92m☑\u001b[0m Q 113+351 T 464  \u001b[92m☑\u001b[0m Q 6+521   T 527  \u001b[92m☑\u001b[0m Q 178+80  T 258  \u001b[92m☑\u001b[0m Q 87+35   T 122  \u001b[92m☑\u001b[0m Q 290+37  T 327  \u001b[92m☑\u001b[0m Q 3+983   T 986  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 157\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 100us/step - loss: 1.8735e-04 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 0.9995\n",
      "Q 583+62  T 645  \u001b[92m☑\u001b[0m Q 269+860 T 1129 \u001b[92m☑\u001b[0m Q 690+91  T 781  \u001b[92m☑\u001b[0m Q 8+712   T 720  \u001b[92m☑\u001b[0m Q 72+923  T 995  \u001b[92m☑\u001b[0m Q 78+874  T 952  \u001b[92m☑\u001b[0m Q 976+652 T 1628 \u001b[92m☑\u001b[0m Q 221+46  T 267  \u001b[92m☑\u001b[0m Q 888+5   T 893  \u001b[92m☑\u001b[0m Q 99+946  T 1045 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 158\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 100us/step - loss: 1.7021e-04 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 0.9996\n",
      "Q 868+654 T 1522 \u001b[92m☑\u001b[0m Q 9+418   T 427  \u001b[92m☑\u001b[0m Q 70+197  T 267  \u001b[92m☑\u001b[0m Q 270+390 T 660  \u001b[92m☑\u001b[0m Q 789+16  T 805  \u001b[92m☑\u001b[0m Q 148+33  T 181  \u001b[92m☑\u001b[0m Q 11+49   T 60   \u001b[92m☑\u001b[0m Q 66+714  T 780  \u001b[92m☑\u001b[0m Q 9+811   T 820  \u001b[92m☑\u001b[0m Q 714+38  T 752  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 159\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 0.0305 - acc: 0.9915 - val_loss: 0.0292 - val_acc: 0.9900\n",
      "Q 441+98  T 539  \u001b[92m☑\u001b[0m Q 63+618  T 681  \u001b[92m☑\u001b[0m Q 549+44  T 593  \u001b[92m☑\u001b[0m Q 429+70  T 499  \u001b[92m☑\u001b[0m Q 686+753 T 1439 \u001b[92m☑\u001b[0m Q 450+733 T 1183 \u001b[92m☑\u001b[0m Q 296+241 T 537  \u001b[92m☑\u001b[0m Q 39+227  T 266  \u001b[92m☑\u001b[0m Q 42+91   T 133  \u001b[92m☑\u001b[0m Q 22+891  T 913  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 160\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 100us/step - loss: 0.0052 - acc: 0.9987 - val_loss: 0.0048 - val_acc: 0.9984\n",
      "Q 201+66  T 267  \u001b[92m☑\u001b[0m Q 306+78  T 384  \u001b[92m☑\u001b[0m Q 306+78  T 384  \u001b[92m☑\u001b[0m Q 54+412  T 466  \u001b[92m☑\u001b[0m Q 853+395 T 1248 \u001b[92m☑\u001b[0m Q 459+55  T 514  \u001b[92m☑\u001b[0m Q 13+98   T 111  \u001b[92m☑\u001b[0m Q 94+472  T 566  \u001b[92m☑\u001b[0m Q 521+434 T 955  \u001b[92m☑\u001b[0m Q 85+175  T 260  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 161\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 6.2316e-04 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 0.9997\n",
      "Q 230+590 T 820  \u001b[92m☑\u001b[0m Q 316+382 T 698  \u001b[92m☑\u001b[0m Q 2+394   T 396  \u001b[92m☑\u001b[0m Q 603+848 T 1451 \u001b[92m☑\u001b[0m Q 597+375 T 972  \u001b[92m☑\u001b[0m Q 76+141  T 217  \u001b[92m☑\u001b[0m Q 13+98   T 111  \u001b[92m☑\u001b[0m Q 50+35   T 85   \u001b[92m☑\u001b[0m Q 473+468 T 941  \u001b[92m☑\u001b[0m Q 879+211 T 1090 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 162\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 100us/step - loss: 3.7668e-04 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9997\n",
      "Q 40+514  T 554  \u001b[92m☑\u001b[0m Q 116+187 T 303  \u001b[92m☑\u001b[0m Q 169+891 T 1060 \u001b[92m☑\u001b[0m Q 491+3   T 494  \u001b[92m☑\u001b[0m Q 21+323  T 344  \u001b[92m☑\u001b[0m Q 451+52  T 503  \u001b[92m☑\u001b[0m Q 57+98   T 155  \u001b[92m☑\u001b[0m Q 967+7   T 974  \u001b[92m☑\u001b[0m Q 799+539 T 1338 \u001b[92m☑\u001b[0m Q 117+923 T 1040 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 163\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 3.0262e-04 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9997\n",
      "Q 21+837  T 858  \u001b[92m☑\u001b[0m Q 557+0   T 557  \u001b[92m☑\u001b[0m Q 130+89  T 219  \u001b[92m☑\u001b[0m Q 72+842  T 914  \u001b[92m☑\u001b[0m Q 5+333   T 338  \u001b[92m☑\u001b[0m Q 94+827  T 921  \u001b[92m☑\u001b[0m Q 640+23  T 663  \u001b[92m☑\u001b[0m Q 760+157 T 917  \u001b[92m☑\u001b[0m Q 177+3   T 180  \u001b[92m☑\u001b[0m Q 1+627   T 628  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 164\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 2.5776e-04 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 0.9997\n",
      "Q 900+393 T 1293 \u001b[92m☑\u001b[0m Q 841+98  T 939  \u001b[92m☑\u001b[0m Q 61+272  T 333  \u001b[92m☑\u001b[0m Q 668+89  T 757  \u001b[92m☑\u001b[0m Q 685+99  T 784  \u001b[92m☑\u001b[0m Q 9+329   T 338  \u001b[92m☑\u001b[0m Q 88+238  T 326  \u001b[92m☑\u001b[0m Q 661+1   T 662  \u001b[92m☑\u001b[0m Q 708+304 T 1012 \u001b[92m☑\u001b[0m Q 73+201  T 274  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 165\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 100us/step - loss: 2.2600e-04 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 0.9997\n",
      "Q 673+5   T 678  \u001b[92m☑\u001b[0m Q 923+235 T 1158 \u001b[92m☑\u001b[0m Q 916+632 T 1548 \u001b[92m☑\u001b[0m Q 746+48  T 794  \u001b[92m☑\u001b[0m Q 4+420   T 424  \u001b[92m☑\u001b[0m Q 12+439  T 451  \u001b[92m☑\u001b[0m Q 830+538 T 1368 \u001b[92m☑\u001b[0m Q 78+14   T 92   \u001b[92m☑\u001b[0m Q 53+92   T 145  \u001b[92m☑\u001b[0m Q 993+894 T 1887 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 166\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 100us/step - loss: 2.0151e-04 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 0.9997\n",
      "Q 447+331 T 778  \u001b[92m☑\u001b[0m Q 92+51   T 143  \u001b[92m☑\u001b[0m Q 388+74  T 462  \u001b[92m☑\u001b[0m Q 307+2   T 309  \u001b[92m☑\u001b[0m Q 123+71  T 194  \u001b[92m☑\u001b[0m Q 257+75  T 332  \u001b[92m☑\u001b[0m Q 885+838 T 1723 \u001b[92m☑\u001b[0m Q 259+60  T 319  \u001b[92m☑\u001b[0m Q 77+871  T 948  \u001b[92m☑\u001b[0m Q 860+435 T 1295 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 167\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 100us/step - loss: 1.7869e-04 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 0.9997\n",
      "Q 23+275  T 298  \u001b[92m☑\u001b[0m Q 75+824  T 899  \u001b[92m☑\u001b[0m Q 227+72  T 299  \u001b[92m☑\u001b[0m Q 460+77  T 537  \u001b[92m☑\u001b[0m Q 67+174  T 241  \u001b[92m☑\u001b[0m Q 972+52  T 1024 \u001b[92m☑\u001b[0m Q 75+42   T 117  \u001b[92m☑\u001b[0m Q 39+680  T 719  \u001b[92m☑\u001b[0m Q 42+582  T 624  \u001b[92m☑\u001b[0m Q 578+91  T 669  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 168\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 100us/step - loss: 1.6104e-04 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 0.9998\n",
      "Q 960+69  T 1029 \u001b[92m☑\u001b[0m Q 686+3   T 689  \u001b[92m☑\u001b[0m Q 113+81  T 194  \u001b[92m☑\u001b[0m Q 877+11  T 888  \u001b[92m☑\u001b[0m Q 207+90  T 297  \u001b[92m☑\u001b[0m Q 13+495  T 508  \u001b[92m☑\u001b[0m Q 272+211 T 483  \u001b[92m☑\u001b[0m Q 60+178  T 238  \u001b[92m☑\u001b[0m Q 971+20  T 991  \u001b[92m☑\u001b[0m Q 75+727  T 802  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 169\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 1.5625e-04 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 0.9995\n",
      "Q 484+17  T 501  \u001b[92m☑\u001b[0m Q 80+52   T 132  \u001b[92m☑\u001b[0m Q 905+98  T 1003 \u001b[92m☑\u001b[0m Q 90+83   T 173  \u001b[92m☑\u001b[0m Q 28+35   T 63   \u001b[92m☑\u001b[0m Q 549+84  T 633  \u001b[92m☑\u001b[0m Q 409+69  T 478  \u001b[92m☑\u001b[0m Q 181+43  T 224  \u001b[92m☑\u001b[0m Q 24+84   T 108  \u001b[92m☑\u001b[0m Q 686+361 T 1047 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 170\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 0.0295 - acc: 0.9912 - val_loss: 0.0032 - val_acc: 0.9991\n",
      "Q 856+36  T 892  \u001b[92m☑\u001b[0m Q 9+277   T 286  \u001b[92m☑\u001b[0m Q 481+54  T 535  \u001b[92m☑\u001b[0m Q 597+375 T 972  \u001b[92m☑\u001b[0m Q 48+545  T 593  \u001b[92m☑\u001b[0m Q 405+879 T 1284 \u001b[92m☑\u001b[0m Q 154+551 T 705  \u001b[92m☑\u001b[0m Q 7+99    T 106  \u001b[92m☑\u001b[0m Q 74+602  T 676  \u001b[92m☑\u001b[0m Q 352+98  T 450  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 171\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 100us/step - loss: 9.2295e-04 - acc: 0.9999 - val_loss: 0.0020 - val_acc: 0.9996\n",
      "Q 64+607  T 671  \u001b[92m☑\u001b[0m Q 457+8   T 465  \u001b[92m☑\u001b[0m Q 75+727  T 802  \u001b[92m☑\u001b[0m Q 418+23  T 441  \u001b[92m☑\u001b[0m Q 891+33  T 924  \u001b[92m☑\u001b[0m Q 71+97   T 168  \u001b[92m☑\u001b[0m Q 842+4   T 846  \u001b[92m☑\u001b[0m Q 497+970 T 1467 \u001b[92m☑\u001b[0m Q 396+758 T 1154 \u001b[92m☑\u001b[0m Q 46+72   T 118  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 172\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 4s 100us/step - loss: 4.1313e-04 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9996\n",
      "Q 32+237  T 269  \u001b[92m☑\u001b[0m Q 34+254  T 288  \u001b[92m☑\u001b[0m Q 15+35   T 50   \u001b[92m☑\u001b[0m Q 859+814 T 1673 \u001b[92m☑\u001b[0m Q 24+620  T 644  \u001b[92m☑\u001b[0m Q 782+79  T 861  \u001b[92m☑\u001b[0m Q 183+61  T 244  \u001b[92m☑\u001b[0m Q 488+23  T 511  \u001b[92m☑\u001b[0m Q 679+713 T 1392 \u001b[92m☑\u001b[0m Q 520+224 T 744  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 173\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 3.0820e-04 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 0.9997\n",
      "Q 564+696 T 1260 \u001b[92m☑\u001b[0m Q 12+475  T 487  \u001b[92m☑\u001b[0m Q 802+3   T 805  \u001b[92m☑\u001b[0m Q 528+116 T 644  \u001b[92m☑\u001b[0m Q 35+342  T 377  \u001b[92m☑\u001b[0m Q 75+330  T 405  \u001b[92m☑\u001b[0m Q 509+36  T 545  \u001b[92m☑\u001b[0m Q 624+76  T 700  \u001b[92m☑\u001b[0m Q 90+669  T 759  \u001b[92m☑\u001b[0m Q 4+346   T 350  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 174\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 100us/step - loss: 2.5728e-04 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 0.9997\n",
      "Q 30+641  T 671  \u001b[92m☑\u001b[0m Q 861+3   T 864  \u001b[92m☑\u001b[0m Q 560+688 T 1248 \u001b[92m☑\u001b[0m Q 331+14  T 345  \u001b[92m☑\u001b[0m Q 712+49  T 761  \u001b[92m☑\u001b[0m Q 737+77  T 814  \u001b[92m☑\u001b[0m Q 994+5   T 999  \u001b[92m☑\u001b[0m Q 456+6   T 462  \u001b[92m☑\u001b[0m Q 71+938  T 1009 \u001b[92m☑\u001b[0m Q 819+144 T 963  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 175\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 100us/step - loss: 2.2247e-04 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 0.9997\n",
      "Q 29+590  T 619  \u001b[92m☑\u001b[0m Q 288+0   T 288  \u001b[92m☑\u001b[0m Q 43+892  T 935  \u001b[92m☑\u001b[0m Q 497+233 T 730  \u001b[92m☑\u001b[0m Q 488+46  T 534  \u001b[92m☑\u001b[0m Q 73+40   T 113  \u001b[92m☑\u001b[0m Q 78+0    T 78   \u001b[92m☑\u001b[0m Q 101+61  T 162  \u001b[92m☑\u001b[0m Q 340+80  T 420  \u001b[92m☑\u001b[0m Q 79+25   T 104  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 176\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 100us/step - loss: 1.9613e-04 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 0.9997\n",
      "Q 7+642   T 649  \u001b[92m☑\u001b[0m Q 664+3   T 667  \u001b[92m☑\u001b[0m Q 59+46   T 105  \u001b[92m☑\u001b[0m Q 797+830 T 1627 \u001b[92m☑\u001b[0m Q 105+446 T 551  \u001b[92m☑\u001b[0m Q 28+946  T 974  \u001b[92m☑\u001b[0m Q 9+725   T 734  \u001b[92m☑\u001b[0m Q 490+273 T 763  \u001b[92m☑\u001b[0m Q 502+17  T 519  \u001b[92m☑\u001b[0m Q 68+493  T 561  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 177\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 100us/step - loss: 1.7453e-04 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 0.9997\n",
      "Q 154+421 T 575  \u001b[92m☑\u001b[0m Q 836+201 T 1037 \u001b[92m☑\u001b[0m Q 37+409  T 446  \u001b[92m☑\u001b[0m Q 66+365  T 431  \u001b[92m☑\u001b[0m Q 921+311 T 1232 \u001b[92m☑\u001b[0m Q 421+51  T 472  \u001b[92m☑\u001b[0m Q 31+209  T 240  \u001b[92m☑\u001b[0m Q 23+357  T 380  \u001b[92m☑\u001b[0m Q 93+441  T 534  \u001b[92m☑\u001b[0m Q 828+94  T 922  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 178\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 1.5586e-04 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 0.9997\n",
      "Q 61+272  T 333  \u001b[92m☑\u001b[0m Q 229+63  T 292  \u001b[92m☑\u001b[0m Q 38+967  T 1005 \u001b[92m☑\u001b[0m Q 671+416 T 1087 \u001b[92m☑\u001b[0m Q 88+178  T 266  \u001b[92m☑\u001b[0m Q 131+334 T 465  \u001b[92m☑\u001b[0m Q 50+352  T 402  \u001b[92m☑\u001b[0m Q 5+333   T 338  \u001b[92m☑\u001b[0m Q 851+5   T 856  \u001b[92m☑\u001b[0m Q 70+773  T 843  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 179\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 100us/step - loss: 1.4058e-04 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 0.9997\n",
      "Q 223+648 T 871  \u001b[92m☑\u001b[0m Q 871+753 T 1624 \u001b[92m☑\u001b[0m Q 37+94   T 131  \u001b[92m☑\u001b[0m Q 257+75  T 332  \u001b[92m☑\u001b[0m Q 2+972   T 974  \u001b[92m☑\u001b[0m Q 5+872   T 877  \u001b[92m☑\u001b[0m Q 4+464   T 468  \u001b[92m☑\u001b[0m Q 523+883 T 1406 \u001b[92m☑\u001b[0m Q 401+708 T 1109 \u001b[92m☑\u001b[0m Q 961+886 T 1847 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 180\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 100us/step - loss: 1.2806e-04 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 0.9997\n",
      "Q 368+91  T 459  \u001b[92m☑\u001b[0m Q 516+1   T 517  \u001b[92m☑\u001b[0m Q 528+116 T 644  \u001b[92m☑\u001b[0m Q 649+27  T 676  \u001b[92m☑\u001b[0m Q 661+701 T 1362 \u001b[92m☑\u001b[0m Q 1+807   T 808  \u001b[92m☑\u001b[0m Q 189+74  T 263  \u001b[92m☑\u001b[0m Q 6+192   T 198  \u001b[92m☑\u001b[0m Q 250+299 T 549  \u001b[92m☑\u001b[0m Q 243+90  T 333  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 181\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 1.1623e-04 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 0.9997\n",
      "Q 390+538 T 928  \u001b[92m☑\u001b[0m Q 12+535  T 547  \u001b[92m☑\u001b[0m Q 48+759  T 807  \u001b[92m☑\u001b[0m Q 69+593  T 662  \u001b[92m☑\u001b[0m Q 284+980 T 1264 \u001b[92m☑\u001b[0m Q 21+286  T 307  \u001b[92m☑\u001b[0m Q 95+221  T 316  \u001b[92m☑\u001b[0m Q 80+36   T 116  \u001b[92m☑\u001b[0m Q 82+659  T 741  \u001b[92m☑\u001b[0m Q 201+945 T 1146 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 182\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 5s 100us/step - loss: 0.0196 - acc: 0.9951 - val_loss: 0.0924 - val_acc: 0.9712\n",
      "Q 707+782 T 1489 \u001b[92m☑\u001b[0m Q 47+367  T 414  \u001b[92m☑\u001b[0m Q 1+189   T 190  \u001b[92m☑\u001b[0m Q 430+13  T 443  \u001b[92m☑\u001b[0m Q 214+57  T 271  \u001b[92m☑\u001b[0m Q 3+866   T 869  \u001b[92m☑\u001b[0m Q 673+48  T 721  \u001b[92m☑\u001b[0m Q 32+904  T 936  \u001b[92m☑\u001b[0m Q 321+21  T 342  \u001b[92m☑\u001b[0m Q 66+87   T 153  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 183\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 100us/step - loss: 0.0133 - acc: 0.9963 - val_loss: 0.0032 - val_acc: 0.9992\n",
      "Q 46+911  T 957  \u001b[92m☑\u001b[0m Q 402+300 T 702  \u001b[92m☑\u001b[0m Q 818+8   T 826  \u001b[92m☑\u001b[0m Q 616+56  T 672  \u001b[92m☑\u001b[0m Q 666+793 T 1459 \u001b[92m☑\u001b[0m Q 12+409  T 421  \u001b[92m☑\u001b[0m Q 501+14  T 515  \u001b[92m☑\u001b[0m Q 76+505  T 581  \u001b[92m☑\u001b[0m Q 113+81  T 194  \u001b[92m☑\u001b[0m Q 12+310  T 322  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 184\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 99us/step - loss: 5.1385e-04 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 0.9995\n",
      "Q 379+635 T 1014 \u001b[92m☑\u001b[0m Q 82+149  T 231  \u001b[92m☑\u001b[0m Q 933+42  T 975  \u001b[92m☑\u001b[0m Q 257+95  T 352  \u001b[92m☑\u001b[0m Q 0+326   T 326  \u001b[92m☑\u001b[0m Q 41+25   T 66   \u001b[92m☑\u001b[0m Q 511+7   T 518  \u001b[92m☑\u001b[0m Q 769+213 T 982  \u001b[92m☑\u001b[0m Q 49+871  T 920  \u001b[92m☑\u001b[0m Q 905+0   T 905  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 185\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 100us/step - loss: 3.0489e-04 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 0.9996\n",
      "Q 305+1   T 306  \u001b[92m☑\u001b[0m Q 64+982  T 1046 \u001b[92m☑\u001b[0m Q 599+496 T 1095 \u001b[92m☑\u001b[0m Q 1+730   T 731  \u001b[92m☑\u001b[0m Q 923+779 T 1702 \u001b[92m☑\u001b[0m Q 715+695 T 1410 \u001b[92m☑\u001b[0m Q 5+252   T 257  \u001b[92m☑\u001b[0m Q 223+45  T 268  \u001b[92m☑\u001b[0m Q 895+294 T 1189 \u001b[92m☑\u001b[0m Q 79+956  T 1035 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 186\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 100us/step - loss: 2.4762e-04 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9996\n",
      "Q 677+822 T 1499 \u001b[92m☑\u001b[0m Q 717+680 T 1397 \u001b[92m☑\u001b[0m Q 0+756   T 756  \u001b[92m☑\u001b[0m Q 820+14  T 834  \u001b[92m☑\u001b[0m Q 312+82  T 394  \u001b[92m☑\u001b[0m Q 69+295  T 364  \u001b[92m☑\u001b[0m Q 350+50  T 400  \u001b[92m☑\u001b[0m Q 396+704 T 1100 \u001b[92m☑\u001b[0m Q 72+873  T 945  \u001b[92m☑\u001b[0m Q 467+3   T 470  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 187\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 99us/step - loss: 2.1170e-04 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9996\n",
      "Q 924+7   T 931  \u001b[92m☑\u001b[0m Q 8+70    T 78   \u001b[92m☑\u001b[0m Q 78+874  T 952  \u001b[92m☑\u001b[0m Q 66+97   T 163  \u001b[92m☑\u001b[0m Q 94+498  T 592  \u001b[92m☑\u001b[0m Q 22+69   T 91   \u001b[92m☑\u001b[0m Q 46+308  T 354  \u001b[92m☑\u001b[0m Q 40+544  T 584  \u001b[92m☑\u001b[0m Q 475+42  T 517  \u001b[92m☑\u001b[0m Q 699+50  T 749  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 188\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 4s 100us/step - loss: 1.8462e-04 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 0.9996\n",
      "Q 717+42  T 759  \u001b[92m☑\u001b[0m Q 76+49   T 125  \u001b[92m☑\u001b[0m Q 0+606   T 606  \u001b[92m☑\u001b[0m Q 79+934  T 1013 \u001b[92m☑\u001b[0m Q 6+625   T 631  \u001b[92m☑\u001b[0m Q 83+0    T 83   \u001b[92m☑\u001b[0m Q 63+57   T 120  \u001b[92m☑\u001b[0m Q 405+7   T 412  \u001b[92m☑\u001b[0m Q 42+280  T 322  \u001b[92m☑\u001b[0m Q 12+541  T 553  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 189\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 100us/step - loss: 1.6379e-04 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 0.9996\n",
      "Q 59+512  T 571  \u001b[92m☑\u001b[0m Q 72+82   T 154  \u001b[92m☑\u001b[0m Q 21+388  T 409  \u001b[92m☑\u001b[0m Q 16+59   T 75   \u001b[92m☑\u001b[0m Q 326+221 T 547  \u001b[92m☑\u001b[0m Q 803+521 T 1324 \u001b[92m☑\u001b[0m Q 55+737  T 792  \u001b[92m☑\u001b[0m Q 2+548   T 550  \u001b[92m☑\u001b[0m Q 66+591  T 657  \u001b[92m☑\u001b[0m Q 330+681 T 1011 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 190\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 99us/step - loss: 1.4627e-04 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 0.9996\n",
      "Q 884+40  T 924  \u001b[92m☑\u001b[0m Q 45+28   T 73   \u001b[92m☑\u001b[0m Q 57+707  T 764  \u001b[92m☑\u001b[0m Q 936+75  T 1011 \u001b[92m☑\u001b[0m Q 83+618  T 701  \u001b[92m☑\u001b[0m Q 437+2   T 439  \u001b[92m☑\u001b[0m Q 93+92   T 185  \u001b[92m☑\u001b[0m Q 624+6   T 630  \u001b[92m☑\u001b[0m Q 34+776  T 810  \u001b[92m☑\u001b[0m Q 777+787 T 1564 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 191\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 99us/step - loss: 1.3163e-04 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 0.9996\n",
      "Q 551+91  T 642  \u001b[92m☑\u001b[0m Q 618+15  T 633  \u001b[92m☑\u001b[0m Q 606+67  T 673  \u001b[92m☑\u001b[0m Q 135+93  T 228  \u001b[92m☑\u001b[0m Q 81+934  T 1015 \u001b[92m☑\u001b[0m Q 57+81   T 138  \u001b[92m☑\u001b[0m Q 830+22  T 852  \u001b[92m☑\u001b[0m Q 54+629  T 683  \u001b[92m☑\u001b[0m Q 201+296 T 497  \u001b[92m☑\u001b[0m Q 24+686  T 710  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 192\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 99us/step - loss: 1.1936e-04 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 0.9996\n",
      "Q 74+275  T 349  \u001b[92m☑\u001b[0m Q 927+617 T 1544 \u001b[92m☑\u001b[0m Q 65+51   T 116  \u001b[92m☑\u001b[0m Q 885+838 T 1723 \u001b[92m☑\u001b[0m Q 108+37  T 145  \u001b[92m☑\u001b[0m Q 637+400 T 1037 \u001b[92m☑\u001b[0m Q 232+115 T 347  \u001b[92m☑\u001b[0m Q 596+77  T 673  \u001b[92m☑\u001b[0m Q 295+8   T 303  \u001b[92m☑\u001b[0m Q 644+92  T 736  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 193\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 99us/step - loss: 1.0813e-04 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 0.9996\n",
      "Q 544+68  T 612  \u001b[92m☑\u001b[0m Q 652+354 T 1006 \u001b[92m☑\u001b[0m Q 483+0   T 483  \u001b[92m☑\u001b[0m Q 320+30  T 350  \u001b[92m☑\u001b[0m Q 52+8    T 60   \u001b[92m☑\u001b[0m Q 139+810 T 949  \u001b[92m☑\u001b[0m Q 960+65  T 1025 \u001b[92m☑\u001b[0m Q 793+62  T 855  \u001b[92m☑\u001b[0m Q 64+79   T 143  \u001b[92m☑\u001b[0m Q 721+317 T 1038 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 194\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 99us/step - loss: 9.8120e-05 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 0.9997\n",
      "Q 682+74  T 756  \u001b[92m☑\u001b[0m Q 786+787 T 1573 \u001b[92m☑\u001b[0m Q 60+281  T 341  \u001b[92m☑\u001b[0m Q 1+829   T 830  \u001b[92m☑\u001b[0m Q 693+17  T 710  \u001b[92m☑\u001b[0m Q 66+97   T 163  \u001b[92m☑\u001b[0m Q 59+816  T 875  \u001b[92m☑\u001b[0m Q 293+504 T 797  \u001b[92m☑\u001b[0m Q 257+95  T 352  \u001b[92m☑\u001b[0m Q 480+107 T 587  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 195\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 100us/step - loss: 0.0242 - acc: 0.9927 - val_loss: 0.0077 - val_acc: 0.9979\n",
      "Q 581+536 T 1117 \u001b[92m☑\u001b[0m Q 62+49   T 111  \u001b[92m☑\u001b[0m Q 304+1   T 305  \u001b[92m☑\u001b[0m Q 378+8   T 386  \u001b[92m☑\u001b[0m Q 157+49  T 206  \u001b[92m☑\u001b[0m Q 804+51  T 855  \u001b[92m☑\u001b[0m Q 377+548 T 925  \u001b[92m☑\u001b[0m Q 926+6   T 932  \u001b[92m☑\u001b[0m Q 76+151  T 227  \u001b[92m☑\u001b[0m Q 382+17  T 399  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 196\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 100us/step - loss: 0.0016 - acc: 0.9997 - val_loss: 0.0025 - val_acc: 0.9993\n",
      "Q 85+983  T 1068 \u001b[92m☑\u001b[0m Q 165+3   T 168  \u001b[92m☑\u001b[0m Q 61+762  T 823  \u001b[92m☑\u001b[0m Q 299+583 T 882  \u001b[92m☑\u001b[0m Q 669+913 T 1582 \u001b[92m☑\u001b[0m Q 38+12   T 50   \u001b[92m☑\u001b[0m Q 847+23  T 870  \u001b[92m☑\u001b[0m Q 82+911  T 993  \u001b[92m☑\u001b[0m Q 558+95  T 653  \u001b[92m☑\u001b[0m Q 227+70  T 297  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 197\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 100us/step - loss: 3.5839e-04 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 0.9994\n",
      "Q 718+22  T 740  \u001b[92m☑\u001b[0m Q 936+75  T 1011 \u001b[92m☑\u001b[0m Q 806+4   T 810  \u001b[92m☑\u001b[0m Q 171+23  T 194  \u001b[92m☑\u001b[0m Q 1+730   T 731  \u001b[92m☑\u001b[0m Q 983+5   T 988  \u001b[92m☑\u001b[0m Q 979+143 T 1122 \u001b[92m☑\u001b[0m Q 38+872  T 910  \u001b[92m☑\u001b[0m Q 19+895  T 914  \u001b[92m☑\u001b[0m Q 339+624 T 963  \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 198\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 99us/step - loss: 2.4429e-04 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9995\n",
      "Q 14+662  T 676  \u001b[92m☑\u001b[0m Q 595+2   T 597  \u001b[92m☑\u001b[0m Q 171+36  T 207  \u001b[92m☑\u001b[0m Q 50+95   T 145  \u001b[92m☑\u001b[0m Q 12+439  T 451  \u001b[92m☑\u001b[0m Q 50+563  T 613  \u001b[92m☑\u001b[0m Q 572+30  T 602  \u001b[92m☑\u001b[0m Q 351+58  T 409  \u001b[92m☑\u001b[0m Q 452+53  T 505  \u001b[92m☑\u001b[0m Q 492+923 T 1415 \u001b[92m☑\u001b[0m \n",
      "--------------------------------------------------\n",
      "Iteration 199\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 99us/step - loss: 2.0393e-04 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 0.9995\n",
      "Q 0+719   T 719  \u001b[92m☑\u001b[0m Q 33+228  T 261  \u001b[92m☑\u001b[0m Q 47+119  T 166  \u001b[92m☑\u001b[0m Q 530+981 T 1511 \u001b[92m☑\u001b[0m Q 332+996 T 1328 \u001b[92m☑\u001b[0m Q 650+61  T 711  \u001b[92m☑\u001b[0m Q 422+326 T 748  \u001b[92m☑\u001b[0m Q 386+1   T 387  \u001b[92m☑\u001b[0m Q 37+324  T 361  \u001b[92m☑\u001b[0m Q 761+34  T 795  \u001b[92m☑\u001b[0m 795 \n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "'''\n",
    "# An implementation of sequence to sequence learning for performing addition\n",
    "Input: \"535+61\"\n",
    "Output: \"596\"\n",
    "Padding is handled by using a repeated sentinel character (space)\n",
    "Input may optionally be reversed, shown to increase performance in many tasks in:\n",
    "\"Learning to Execute\"\n",
    "http://arxiv.org/abs/1410.4615\n",
    "and\n",
    "\"Sequence to Sequence Learning with Neural Networks\"\n",
    "http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\n",
    "Theoretically it introduces shorter term dependencies between source and target.\n",
    "Two digits reversed:\n",
    "+ One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\n",
    "Three digits reversed:\n",
    "+ One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\n",
    "Four digits reversed:\n",
    "+ One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\n",
    "Five digits reversed:\n",
    "+ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs\n",
    "'''  # noqa\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from six.moves import range\n",
    "\n",
    "\n",
    "class CharacterTable(object):\n",
    "    \"\"\"Given a set of characters:\n",
    "    + Encode them to a one-hot integer representation\n",
    "    + Decode the one-hot or integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    \"\"\"\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize character table.\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One-hot encode given string C.\n",
    "        # Arguments\n",
    "            C: string, to be encoded.\n",
    "            num_rows: Number of rows in the returned one-hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        \"\"\"Decode the given vector or 2D array to their character output.\n",
    "        # Arguments\n",
    "            x: A vector or a 2D array of probabilities or one-hot representations;\n",
    "                or a vector of character indices (used with `calc_argmax=False`).\n",
    "            calc_argmax: Whether to find the character index with maximum\n",
    "                probability, defaults to `True`.\n",
    "        \"\"\"\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return ''.join(self.indices_char[x] for x in x)\n",
    "\n",
    "\n",
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'\n",
    "\n",
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 3\n",
    "REVERSE = True\n",
    "\n",
    "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
    "# int is DIGITS.\n",
    "MAXLEN = DIGITS + 1 + DIGITS\n",
    "\n",
    "# All the numbers, plus sign and space for padding.\n",
    "chars = '0123456789+ '\n",
    "ctable = CharacterTable(chars)\n",
    "\n",
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "print('Generating data...')\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
    "                    for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "    a, b = f(), f()\n",
    "    # Skip any addition questions we've already seen\n",
    "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "    key = tuple(sorted((a, b)))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    # Pad the data with spaces such that it is always MAXLEN.\n",
    "    q = '{}+{}'.format(a, b)\n",
    "    query = q + ' ' * (MAXLEN - len(q))\n",
    "    ans = str(a + b)\n",
    "    # Answers can be of maximum size DIGITS + 1.\n",
    "    ans += ' ' * (DIGITS + 1 - len(ans))\n",
    "    if REVERSE:\n",
    "        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
    "        # space used for padding.)\n",
    "        query = query[::-1]\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print('Total addition questions:', len(questions))\n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
    "\n",
    "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
    "# digits.\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Explicitly set apart 10% for validation data that we never train over.\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]\n",
    "\n",
    "print('Training Data:')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('Validation Data:')\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "# Try replacing GRU, or SimpleRNN.\n",
    "RNN = layers.LSTM\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "LAYERS = 1\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "# \"Encode\" the input sequence using an RNN, producing an output of HIDDEN_SIZE.\n",
    "# Note: In a situation where your input sequences have a variable length,\n",
    "# use input_shape=(None, num_feature).\n",
    "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
    "# As the decoder RNN's input, repeatedly provide with the last output of\n",
    "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
    "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
    "model.add(layers.RepeatVector(DIGITS + 1))\n",
    "# The decoder RNN could be multiple layers stacked or a single layer.\n",
    "for _ in range(LAYERS):\n",
    "    # By setting return_sequences to True, return not only the last output but\n",
    "    # all the outputs so far in the form of (num_samples, timesteps,\n",
    "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
    "    # the first dimension to be the timesteps.\n",
    "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
    "\n",
    "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
    "# of the output sequence, decide which character should be chosen.\n",
    "model.add(layers.TimeDistributed(layers.Dense(len(chars), activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Train the model each generation and show predictions against the validation\n",
    "# dataset.\n",
    "for iteration in range(1, 200):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=1,\n",
    "              validation_data=(x_val, y_val))\n",
    "    # Select 10 samples from the validation set at random so we can visualize\n",
    "    # errors.\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = model.predict_classes(rowx, verbose=0)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        print('Q', q[::-1] if REVERSE else q, end=' ')\n",
    "        print('T', correct, end=' ')\n",
    "        if correct == guess:\n",
    "            print(colors.ok + '☑' + colors.close, end=' ')\n",
    "        else:\n",
    "            print(colors.fail + '☒' + colors.close, end=' ')\n",
    "print(guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN / Embed / Sent / Query = <class 'keras.layers.recurrent.LSTM'>, 50, 100, 100\n",
      "Downloading data from https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz\n",
      "11747328/11745123 [==============================] - 12s 1us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab = ['.', '?', 'Daniel', 'John', 'Mary', 'Sandra', 'Where', 'apple', 'back', 'bathroom', 'bedroom', 'discarded', 'down', 'dropped', 'football', 'garden', 'got', 'grabbed', 'hallway', 'is', 'journeyed', 'kitchen', 'left', 'milk', 'moved', 'office', 'picked', 'put', 'the', 'there', 'to', 'took', 'travelled', 'up', 'went']\n",
      "x.shape = (1000, 552)\n",
      "xq.shape = (1000, 5)\n",
      "y.shape = (1000, 36)\n",
      "story_maxlen, query_maxlen = 552, 5\n",
      "Build model...\n",
      "Training\n",
      "Train on 950 samples, validate on 50 samples\n",
      "Epoch 1/20\n",
      "950/950 [==============================] - 14s 15ms/step - loss: 2.6727 - acc: 0.1989 - val_loss: 1.7922 - val_acc: 0.3000\n",
      "Epoch 2/20\n",
      "950/950 [==============================] - 14s 14ms/step - loss: 1.8014 - acc: 0.2242 - val_loss: 1.7732 - val_acc: 0.3000\n",
      "Epoch 3/20\n",
      "950/950 [==============================] - 14s 14ms/step - loss: 1.7899 - acc: 0.1874 - val_loss: 1.8582 - val_acc: 0.0600\n",
      "Epoch 4/20\n",
      "950/950 [==============================] - 14s 14ms/step - loss: 1.8010 - acc: 0.2042 - val_loss: 1.8299 - val_acc: 0.0600\n",
      "Epoch 5/20\n",
      "950/950 [==============================] - 14s 14ms/step - loss: 1.8024 - acc: 0.2042 - val_loss: 1.8543 - val_acc: 0.0600\n",
      "Epoch 6/20\n",
      "950/950 [==============================] - 14s 15ms/step - loss: 1.7915 - acc: 0.2021 - val_loss: 1.7545 - val_acc: 0.2600\n",
      "Epoch 7/20\n",
      "950/950 [==============================] - 14s 15ms/step - loss: 1.7963 - acc: 0.2021 - val_loss: 1.8071 - val_acc: 0.0600\n",
      "Epoch 8/20\n",
      "950/950 [==============================] - 14s 15ms/step - loss: 1.7880 - acc: 0.2063 - val_loss: 1.8845 - val_acc: 0.0600\n",
      "Epoch 9/20\n",
      "950/950 [==============================] - 14s 14ms/step - loss: 1.7936 - acc: 0.2011 - val_loss: 1.8430 - val_acc: 0.0600\n",
      "Epoch 10/20\n",
      "950/950 [==============================] - 14s 14ms/step - loss: 1.7851 - acc: 0.2200 - val_loss: 1.8020 - val_acc: 0.1600\n",
      "Epoch 11/20\n",
      "950/950 [==============================] - 14s 15ms/step - loss: 1.7805 - acc: 0.2189 - val_loss: 1.7574 - val_acc: 0.3200\n",
      "Epoch 12/20\n",
      "950/950 [==============================] - 14s 14ms/step - loss: 1.7715 - acc: 0.2432 - val_loss: 1.7897 - val_acc: 0.2000\n",
      "Epoch 13/20\n",
      "950/950 [==============================] - 14s 14ms/step - loss: 1.7683 - acc: 0.2358 - val_loss: 1.7844 - val_acc: 0.2000\n",
      "Epoch 14/20\n",
      "950/950 [==============================] - 14s 14ms/step - loss: 1.7615 - acc: 0.2579 - val_loss: 1.8155 - val_acc: 0.2200\n",
      "Epoch 15/20\n",
      "950/950 [==============================] - 14s 14ms/step - loss: 1.7518 - acc: 0.2716 - val_loss: 1.7915 - val_acc: 0.1800\n",
      "Epoch 16/20\n",
      "950/950 [==============================] - 14s 15ms/step - loss: 1.7562 - acc: 0.2611 - val_loss: 1.7278 - val_acc: 0.3000\n",
      "Epoch 17/20\n",
      "950/950 [==============================] - 14s 14ms/step - loss: 1.7311 - acc: 0.2811 - val_loss: 1.7478 - val_acc: 0.2400\n",
      "Epoch 18/20\n",
      "950/950 [==============================] - 14s 15ms/step - loss: 1.7301 - acc: 0.2737 - val_loss: 1.8646 - val_acc: 0.0600\n",
      "Epoch 19/20\n",
      "950/950 [==============================] - 15s 15ms/step - loss: 1.7418 - acc: 0.2737 - val_loss: 1.6838 - val_acc: 0.3800\n",
      "Epoch 20/20\n",
      "950/950 [==============================] - 15s 16ms/step - loss: 1.7312 - acc: 0.2768 - val_loss: 1.7554 - val_acc: 0.2600\n",
      "Evaluation\n",
      "1000/1000 [==============================] - 3s 3ms/step\n",
      "Test loss / test accuracy = 1.7967 / 0.2080\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# Trains two recurrent neural networks based upon a story and a question.\n",
    "The resulting merged vector is then queried to answer a range of bAbI tasks.\n",
    "The results are comparable to those for an LSTM model provided in Weston et al.:\n",
    "\"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\"\n",
    "http://arxiv.org/abs/1502.05698\n",
    "Task Number                  | FB LSTM Baseline | Keras QA\n",
    "---                          | ---              | ---\n",
    "QA1 - Single Supporting Fact | 50               | 52.1\n",
    "QA2 - Two Supporting Facts   | 20               | 37.0\n",
    "QA3 - Three Supporting Facts | 20               | 20.5\n",
    "QA4 - Two Arg. Relations     | 61               | 62.9\n",
    "QA5 - Three Arg. Relations   | 70               | 61.9\n",
    "QA6 - yes/No Questions       | 48               | 50.7\n",
    "QA7 - Counting               | 49               | 78.9\n",
    "QA8 - Lists/Sets             | 45               | 77.2\n",
    "QA9 - Simple Negation        | 64               | 64.0\n",
    "QA10 - Indefinite Knowledge  | 44               | 47.7\n",
    "QA11 - Basic Coreference     | 72               | 74.9\n",
    "QA12 - Conjunction           | 74               | 76.4\n",
    "QA13 - Compound Coreference  | 94               | 94.4\n",
    "QA14 - Time Reasoning        | 27               | 34.8\n",
    "QA15 - Basic Deduction       | 21               | 32.4\n",
    "QA16 - Basic Induction       | 23               | 50.6\n",
    "QA17 - Positional Reasoning  | 51               | 49.1\n",
    "QA18 - Size Reasoning        | 52               | 90.8\n",
    "QA19 - Path Finding          | 8                | 9.0\n",
    "QA20 - Agent's Motivations   | 91               | 90.7\n",
    "For the resources related to the bAbI project, refer to:\n",
    "https://research.facebook.com/researchers/1543934539189348\n",
    "### Notes\n",
    "- With default word, sentence, and query vector sizes, the GRU model achieves:\n",
    "  - 52.1% test accuracy on QA1 in 20 epochs (2 seconds per epoch on CPU)\n",
    "  - 37.0% test accuracy on QA2 in 20 epochs (16 seconds per epoch on CPU)\n",
    "In comparison, the Facebook paper achieves 50% and 20% for the LSTM baseline.\n",
    "- The task does not traditionally parse the question separately. This likely\n",
    "improves accuracy and is a good example of merging two RNNs.\n",
    "- The word vector embeddings are not shared between the story and question RNNs.\n",
    "- See how the accuracy changes given 10,000 training samples (en-10k) instead\n",
    "of only 1000. 1000 was used in order to be comparable to the original paper.\n",
    "- Experiment with GRU, LSTM, and JZS1-3 as they give subtly different results.\n",
    "- The length and noise (i.e. 'useless' story components) impact the ability of\n",
    "LSTMs / GRUs to provide the correct answer. Given only the supporting facts,\n",
    "these RNNs can achieve 100% accuracy on many tasks. Memory networks and neural\n",
    "networks that use attentional processes can efficiently search through this\n",
    "noise to find the relevant statements, improving performance substantially.\n",
    "This becomes especially obvious on QA2 and QA3, both far longer than QA1.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "from functools import reduce\n",
    "import re\n",
    "import tarfile\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras import layers\n",
    "from keras.layers import recurrent\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "def tokenize(sent):\n",
    "    '''Return the tokens of a sentence including punctuation.\n",
    "    >>> tokenize('Bob dropped the apple. Where is the apple?')\n",
    "    ['Bob', 'dropped', 'the', 'apple', '.', 'Where', 'is', 'the', 'apple', '?']\n",
    "    '''\n",
    "    return [x.strip() for x in re.split(r'(\\W+)?', sent) if x.strip()]\n",
    "\n",
    "\n",
    "def parse_stories(lines, only_supporting=False):\n",
    "    '''Parse stories provided in the bAbi tasks format\n",
    "    If only_supporting is true,\n",
    "    only the sentences that support the answer are kept.\n",
    "    '''\n",
    "    data = []\n",
    "    story = []\n",
    "    for line in lines:\n",
    "        line = line.decode('utf-8').strip()\n",
    "        nid, line = line.split(' ', 1)\n",
    "        nid = int(nid)\n",
    "        if nid == 1:\n",
    "            story = []\n",
    "        if '\\t' in line:\n",
    "            q, a, supporting = line.split('\\t')\n",
    "            q = tokenize(q)\n",
    "            if only_supporting:\n",
    "                # Only select the related substory\n",
    "                supporting = map(int, supporting.split())\n",
    "                substory = [story[i - 1] for i in supporting]\n",
    "            else:\n",
    "                # Provide all the substories\n",
    "                substory = [x for x in story if x]\n",
    "            data.append((substory, q, a))\n",
    "            story.append('')\n",
    "        else:\n",
    "            sent = tokenize(line)\n",
    "            story.append(sent)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_stories(f, only_supporting=False, max_length=None):\n",
    "    '''Given a file name, read the file, retrieve the stories,\n",
    "    and then convert the sentences into a single story.\n",
    "    If max_length is supplied,\n",
    "    any stories longer than max_length tokens will be discarded.\n",
    "    '''\n",
    "    data = parse_stories(f.readlines(), only_supporting=only_supporting)\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "    data = [(flatten(story), q, answer) for story, q, answer in data\n",
    "            if not max_length or len(flatten(story)) < max_length]\n",
    "    return data\n",
    "\n",
    "\n",
    "def vectorize_stories(data, word_idx, story_maxlen, query_maxlen):\n",
    "    xs = []\n",
    "    xqs = []\n",
    "    ys = []\n",
    "    for story, query, answer in data:\n",
    "        x = [word_idx[w] for w in story]\n",
    "        xq = [word_idx[w] for w in query]\n",
    "        # let's not forget that index 0 is reserved\n",
    "        y = np.zeros(len(word_idx) + 1)\n",
    "        y[word_idx[answer]] = 1\n",
    "        xs.append(x)\n",
    "        xqs.append(xq)\n",
    "        ys.append(y)\n",
    "    return (pad_sequences(xs, maxlen=story_maxlen),\n",
    "            pad_sequences(xqs, maxlen=query_maxlen), np.array(ys))\n",
    "\n",
    "RNN = recurrent.LSTM\n",
    "EMBED_HIDDEN_SIZE = 50\n",
    "SENT_HIDDEN_SIZE = 100\n",
    "QUERY_HIDDEN_SIZE = 100\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "print('RNN / Embed / Sent / Query = {}, {}, {}, {}'.format(RNN,\n",
    "                                                           EMBED_HIDDEN_SIZE,\n",
    "                                                           SENT_HIDDEN_SIZE,\n",
    "                                                           QUERY_HIDDEN_SIZE))\n",
    "\n",
    "try:\n",
    "    path = get_file('babi-tasks-v1-2.tar.gz',\n",
    "                    origin='https://s3.amazonaws.com/text-datasets/'\n",
    "                           'babi_tasks_1-20_v1-2.tar.gz')\n",
    "except:\n",
    "    print('Error downloading dataset, please download it manually:\\n'\n",
    "          '$ wget http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2'\n",
    "          '.tar.gz\\n'\n",
    "          '$ mv tasks_1-20_v1-2.tar.gz ~/.keras/datasets/babi-tasks-v1-2.tar.gz')\n",
    "    raise\n",
    "\n",
    "# Default QA1 with 1000 samples\n",
    "# challenge = 'tasks_1-20_v1-2/en/qa1_single-supporting-fact_{}.txt'\n",
    "# QA1 with 10,000 samples\n",
    "# challenge = 'tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_{}.txt'\n",
    "# QA2 with 1000 samples\n",
    "challenge = 'tasks_1-20_v1-2/en/qa2_two-supporting-facts_{}.txt'\n",
    "# QA2 with 10,000 samples\n",
    "# challenge = 'tasks_1-20_v1-2/en-10k/qa2_two-supporting-facts_{}.txt'\n",
    "with tarfile.open(path) as tar:\n",
    "    train = get_stories(tar.extractfile(challenge.format('train')))\n",
    "    test = get_stories(tar.extractfile(challenge.format('test')))\n",
    "\n",
    "vocab = set()\n",
    "for story, q, answer in train + test:\n",
    "    vocab |= set(story + q + [answer])\n",
    "vocab = sorted(vocab)\n",
    "\n",
    "# Reserve 0 for masking via pad_sequences\n",
    "vocab_size = len(vocab) + 1\n",
    "word_idx = dict((c, i + 1) for i, c in enumerate(vocab))\n",
    "story_maxlen = max(map(len, (x for x, _, _ in train + test)))\n",
    "query_maxlen = max(map(len, (x for _, x, _ in train + test)))\n",
    "\n",
    "x, xq, y = vectorize_stories(train, word_idx, story_maxlen, query_maxlen)\n",
    "tx, txq, ty = vectorize_stories(test, word_idx, story_maxlen, query_maxlen)\n",
    "\n",
    "print('vocab = {}'.format(vocab))\n",
    "print('x.shape = {}'.format(x.shape))\n",
    "print('xq.shape = {}'.format(xq.shape))\n",
    "print('y.shape = {}'.format(y.shape))\n",
    "print('story_maxlen, query_maxlen = {}, {}'.format(story_maxlen, query_maxlen))\n",
    "\n",
    "print('Build model...')\n",
    "\n",
    "sentence = layers.Input(shape=(story_maxlen,), dtype='int32')\n",
    "encoded_sentence = layers.Embedding(vocab_size, EMBED_HIDDEN_SIZE)(sentence)\n",
    "encoded_sentence = RNN(SENT_HIDDEN_SIZE)(encoded_sentence)\n",
    "\n",
    "question = layers.Input(shape=(query_maxlen,), dtype='int32')\n",
    "encoded_question = layers.Embedding(vocab_size, EMBED_HIDDEN_SIZE)(question)\n",
    "encoded_question = RNN(QUERY_HIDDEN_SIZE)(encoded_question)\n",
    "\n",
    "merged = layers.concatenate([encoded_sentence, encoded_question])\n",
    "preds = layers.Dense(vocab_size, activation='softmax')(merged)\n",
    "\n",
    "model = Model([sentence, question], preds)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Training')\n",
    "model.fit([x, xq], y,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          validation_split=0.05)\n",
    "\n",
    "print('Evaluation')\n",
    "loss, acc = model.evaluate([tx, txq], ty,\n",
    "                           batch_size=BATCH_SIZE)\n",
    "print('Test loss / test accuracy = {:.4f} / {:.4f}'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 400)\n",
      "x_test shape: (25000, 400)\n",
      "Build model...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 5s 207us/step - loss: 0.4117 - acc: 0.7925 - val_loss: 0.2960 - val_acc: 0.8726\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 5s 204us/step - loss: 0.2309 - acc: 0.9072 - val_loss: 0.2960 - val_acc: 0.8762\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 5s 205us/step - loss: 0.1687 - acc: 0.9349 - val_loss: 0.2719 - val_acc: 0.8900\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 5s 203us/step - loss: 0.1195 - acc: 0.9569 - val_loss: 0.3363 - val_acc: 0.8826\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 5s 203us/step - loss: 0.0785 - acc: 0.9716 - val_loss: 0.3456 - val_acc: 0.8856\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 5s 203us/step - loss: 0.0593 - acc: 0.9787 - val_loss: 0.3652 - val_acc: 0.8836\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 5s 204us/step - loss: 0.0470 - acc: 0.9832 - val_loss: 0.4109 - val_acc: 0.8830\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 5s 203us/step - loss: 0.0368 - acc: 0.9870 - val_loss: 0.4949 - val_acc: 0.8764\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 5s 203us/step - loss: 0.0299 - acc: 0.9891 - val_loss: 0.5153 - val_acc: 0.8804\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 5s 203us/step - loss: 0.0316 - acc: 0.9883 - val_loss: 0.5183 - val_acc: 0.8794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f769018c8d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#This example demonstrates the use of Convolution1D for text classification.\n",
    "Gets to 0.89 test accuracy after 2 epochs. </br>\n",
    "90s/epoch on Intel i5 2.4Ghz CPU. </br>\n",
    "10s/epoch on Tesla K40 GPU.\n",
    "'''\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.datasets import imdb\n",
    "\n",
    "# set parameters:\n",
    "max_features = 5000\n",
    "maxlen = 400\n",
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "filters = 250\n",
    "kernel_size = 3\n",
    "hidden_dims = 250\n",
    "epochs = 10\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "# we start off with an efficient embedding layer which maps\n",
    "# our vocab indices into embedding_dims dimensions\n",
    "model.add(Embedding(max_features,\n",
    "                    embedding_dims,\n",
    "                    input_length=maxlen))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# we add a Convolution1D, which will learn filters\n",
    "# word group filters of size filter_length:\n",
    "model.add(Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "# we use max pooling:\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "validation_data=(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
